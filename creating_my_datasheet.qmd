---
title: "Creating my Datasheet"
---

## Prep

```{r load libraries}
# Load required libraries
library(dplyr)
library(lubridate)
library(readxl)
library(leaflet)
library(tidyverse)
library(tidyr)
library(stringr)
```

## Preparing Fish Surveys

```{r add day and night shift differentiation into the fish survey 1}

# Read in the fish survey data
fish_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 1.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_1$date <- as.Date(fish_survey_1$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_1$dateTime_EST <- as.POSIXct(paste(fish_survey_1$date, 
                                               fish_survey_1$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
fish_survey_1 <- fish_survey_1 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_1)

# Write new fish survey csv
write.csv(fish_survey_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 2}

# Read in the fish survey data
fish_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 2.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_2$date <- as.Date(fish_survey_2$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_2$dateTime_EST <- as.POSIXct(paste(fish_survey_2$date, 
                                               fish_survey_2$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
fish_survey_2 <- fish_survey_2 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 10 & hour(dateTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_2)

# Write new fish survey csv
write.csv(fish_survey_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 3}

# Read in the fish survey data
fish_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 3.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_3$date <- as.Date(fish_survey_3$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_3$dateTime_EST <- as.POSIXct(paste(fish_survey_3$date, 
                                               fish_survey_3$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
fish_survey_3 <- fish_survey_3 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_3)

# Write new fish survey csv
write.csv(fish_survey_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 4}

# Read in the fish survey data
fish_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 4.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_4$date <- as.Date(fish_survey_4$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_4$dateTime_EST <- as.POSIXct(paste(fish_survey_4$date, 
                                               fish_survey_4$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
fish_survey_4 <- fish_survey_4 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_4)

# Write new fish survey csv
write.csv(fish_survey_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 5}

# Read in the fish survey data
fish_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 5.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_5$date <- as.Date(fish_survey_5$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_5$dateTime_EST <- as.POSIXct(paste(fish_survey_5$date, 
                                               fish_survey_5$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
fish_survey_5 <- fish_survey_5 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_5)

# Write new fish survey csv
write.csv(fish_survey_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 6}

# Read in the fish survey data
fish_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 6.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_6$date <- as.Date(fish_survey_6$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_6$dateTime_EST <- as.POSIXct(paste(fish_survey_6$date, 
                                               fish_survey_6$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
fish_survey_6 <- fish_survey_6 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_6)

# Write new fish survey csv
write.csv(fish_survey_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 7}

# Read in the fish survey data
fish_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 7.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_7$date <- as.Date(fish_survey_7$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_7$dateTime_EST <- as.POSIXct(paste(fish_survey_7$date, 
                                               fish_survey_7$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
fish_survey_7 <- fish_survey_7 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_7)

# Write new fish survey csv
write.csv(fish_survey_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 8}

# Read in the fish survey data
fish_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 8.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_8$date <- as.Date(fish_survey_8$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_8$dateTime_EST <- as.POSIXct(paste(fish_survey_8$date, 
                                               fish_survey_8$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
fish_survey_8 <- fish_survey_8 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_8)

# Write new fish survey csv
write.csv(fish_survey_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 9}

# Read in the fish survey data
fish_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 9.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_9$date <- as.Date(fish_survey_9$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_9$dateTime_EST <- as.POSIXct(paste(fish_survey_9$date, 
                                               fish_survey_9$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
# Supplementary tracking at Dry on August 5
fish_survey_9 <- fish_survey_9 %>%
  mutate(
    shift = case_when(
      # Define shift for August 5, 2024
      date(dateTime_EST) == ymd("2024-08-05") ~ "day",
      
      # Define shift for regular tracking schedule for week 9
      date(dateTime_EST) >= ymd("2024-08-06") & date(dateTime_EST) <= ymd("2024-08-09") 
      & hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
      
      TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_9)

# Write new stream survey csv
write.csv(fish_survey_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 10}

# Read in the fish survey data
fish_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 10.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_10$date <- as.Date(fish_survey_10$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_10$dateTime_EST <- as.POSIXct(paste(fish_survey_10$date, 
                                                fish_survey_10$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
fish_survey_10 <- fish_survey_10 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 3 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_10)

# Write new fish survey csv
write.csv(fish_survey_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 11}

# Read in the fish survey data
fish_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 11.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_11$date <- as.Date(fish_survey_11$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_11$dateTime_EST <- as.POSIXct(paste(fish_survey_11$date, 
                                                fish_survey_11$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
fish_survey_11 <- fish_survey_11 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(fish_survey_11)

# Write new fish survey csv
write.csv(fish_survey_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 12}

# Read in the fish survey data
fish_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 12.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_12$date <- as.Date(fish_survey_12$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_12$dateTime_EST <- as.POSIXct(paste(fish_survey_12$date, 
                                                fish_survey_12$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
fish_survey_12 <- fish_survey_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(fish_survey_12)

# Write new fish survey csv
write.csv(fish_survey_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_12.csv", 
          row.names = FALSE)

```


```{r processing fish surveys}

# Define the path to the folder where the files are located
fish_survey_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/" 

# Define file names
fish_file_names <- paste0(fish_survey_data, c("fish_survey_1.csv", "fish_survey_2.csv", "fish_survey_3.csv", "fish_survey_4.csv", 
                     "fish_survey_5.csv", "fish_survey_6.csv", "fish_survey_7.csv", "fish_survey_8.csv", 
                     "fish_survey_9.csv", "fish_survey_10.csv", "fish_survey_11.csv", "fish_survey_12.csv"))

# Define a lookup table for stream names
stream_name_lookup <- data.frame(
  abbreviation = c("dcky", "amth", "undh", "dryu"),  # List all abbreviations
  full_name = c("DICKEY", "AMETHYST", "UNDERHILL", "DRY UPPER")  # Corresponding full names
)

# Create an empty list to store the processed datasets
processed_fish_data_list <- list()

# Loop through each fish survey file
for (file_name in fish_file_names) {
  # Read in the fish survey data
  raw_tracking_data <- read.csv(file_name)
  
  # Step 1: Process the data
  tracking_data <- raw_tracking_data %>%
    
    # Step 2: Select specific columns
    select(dateTime_EST, shift, dckyID, amthID, undhID, dryuID, 
           signal, habitat, habitatExtra, position, substrate, substrateExtra, 
           shade, x, y, Notes, brookName) %>%
    
    # Step 3: Pivot longer to create 'river' and 'tagID' columns
    pivot_longer(
      cols = c(dckyID, amthID, undhID, dryuID),  # Columns to combine
      names_to = "river",                        # Create a new column 'river' from column names
      values_to = "tagID",                       # Combine the tag IDs into a new column 'tagID'
      values_drop_na = FALSE                     # Ensure NA values are retained
    ) %>%
    
    # Step 4: Create a new 'riverName' column and extract the river name and ID number
    mutate(
      riverName = river,                                    # Copy the river name
      #tagID = as.numeric(gsub("[^0-9]", "", tagID)),       # Extract the numeric part as tagID
      tagID = ifelse(is.na(tagID), NA, as.numeric(tagID)),  # Convert tagID to numeric, keep NA values
      river = gsub("ID", "", river)                         # Remove 'ID' to keep only the river name
    ) %>%
    
    # Step 5: Join with the lookup table to replace abbreviations with full names
    left_join(stream_name_lookup, by = c("river" = "abbreviation")) %>%
    mutate(
      river = coalesce(full_name, river)  # Replace Brook with full_name, if available
    ) %>%
    select(-full_name) %>%  # Remove the full_name column as it's no longer needed
    
    # Step 6: Combine the river and brookName logic
    mutate(
      river = ifelse(brookName %in% c("BUFFAM", "HARRIS"), brookName, river)  # Override river with brookName if Buffam or Harris
    ) %>%
    
    # Step 7: Rename columns
    rename(
      fishNotes = Notes,
      lon = x,
      lat = y,
      trackedTime_EST = dateTime_EST,
      power = signal
    ) %>%
    
    ##############################################################
    
    # Step 8: Filter data to keep only rows where lat > 1
    filter(lat > 1, !is.na(tagID)) %>%
    
    # Step _: Filter data to keep rows with lat > 1 or lat is NA
    #filter(lat > 1 | is.na(lat)) %>%
    
    #############################################################
    
    # Step _: Remove unnecessary columns
    #select(-c(riverName, brookName)) %>%
    
    # Step 9: Select specific columns
    select(trackedTime_EST, river, shift, tagID, power, habitat, habitatExtra, position, substrate, substrateExtra, shade, lon, lat, fishNotes) %>%
    
    #############################################################
    
    # Step 10: Add a source column
    mutate(source = "iPad")
  
  # Store the processed data in the list
  processed_fish_data_list[[file_name]] <- tracking_data
  
  # Overwrite the original file with the processed data
  write.csv(tracking_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_fish_data_list)) {
  cat("\nData for", fish_file_names[i], ":\n")
  print(head(processed_fish_data_list[[i]]))
}

```



## Making Flow Tracker File Datasets by Week

```{r combine flow tracker files for week 1}

# Define a function to search for files
find_files <- function(week_1_directory) {
  week_1_files <- list.files(path = week_1_directory, recursive = TRUE, full.names = TRUE)
  return(week_1_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  # Rename columns
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_1_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week1"

# Find all files in the week 1 directory
week_1_files <- find_files(week_1_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_1 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_1_files) {
  file_data <- extract_values(file)
  flow_tracker_1 <- bind_rows(flow_tracker_1, file_data)
}

# Standardize site names
flow_tracker_1 <- flow_tracker_1 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_1 <- flow_tracker_1 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_1)

# Write the final CSV file
write.csv(flow_tracker_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_1.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 2}

# Define a function to search for files
find_files <- function(week_2_directory) {
  week_2_files <- list.files(path = week_2_directory, recursive = TRUE, full.names = TRUE)
  return(week_2_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_2_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week2"

# Find all files in the week 2 directory
week_2_files <- find_files(week_2_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_2 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_2_files) {
  file_data <- extract_values(file)
  flow_tracker_2 <- bind_rows(flow_tracker_2, file_data)
}

# Standardize site names
flow_tracker_2 <- flow_tracker_2 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_2 <- flow_tracker_2 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_2)

# Write the final CSV file
write.csv(flow_tracker_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_2.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 3}

# Define a function to search for files
find_files <- function(week_3_directory) {
  week_3_files <- list.files(path = week_3_directory, recursive = TRUE, full.names = TRUE)
  return(week_3_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_3_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week3"

# Find all files in the week 3 directory
week_3_files <- find_files(week_3_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_3 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_3_files) {
  file_data <- extract_values(file)
  flow_tracker_3 <- bind_rows(flow_tracker_3, file_data)
}

# Standardize site names
flow_tracker_3 <- flow_tracker_3 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_3 <- flow_tracker_3 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_3)

# Write the final CSV file
write.csv(flow_tracker_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_3.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 4}

# Define a function to search for files
find_files <- function(week_4_directory) {
  week_4_files <- list.files(path = week_4_directory, recursive = TRUE, full.names = TRUE)
  return(week_4_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_4_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week4"

# Find all files in the week 4 directory
week_4_files <- find_files(week_4_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_4 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_4_files) {
  file_data <- extract_values(file)
  flow_tracker_4 <- bind_rows(flow_tracker_4, file_data)
}

# Standardize site names
flow_tracker_4 <- flow_tracker_4 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_4 <- flow_tracker_4 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_4)

# Write the final CSV file
write.csv(flow_tracker_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_4.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 5}

# Define a function to search for files
find_files <- function(week_5_directory) {
  week_5_files <- list.files(path = week_5_directory, recursive = TRUE, full.names = TRUE)
  return(week_5_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_5_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week5"

# Find all files in the week 5 directory
week_5_files <- find_files(week_5_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_5 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_5_files) {
  file_data <- extract_values(file)
  flow_tracker_5 <- bind_rows(flow_tracker_5, file_data)
}

# Standardize site names
flow_tracker_5 <- flow_tracker_5 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_5 <- flow_tracker_5 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_5)

# Write the final CSV file
write.csv(flow_tracker_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_5.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 6}

# Define a function to search for files
find_files <- function(week_6_directory) {
  week_6_files <- list.files(path = week_6_directory, recursive = TRUE, full.names = TRUE)
  return(week_6_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_6_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week6"

# Find all files in the week 6 directory
week_6_files <- find_files(week_6_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_6 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_6_files) {
  file_data <- extract_values(file)
  flow_tracker_6 <- bind_rows(flow_tracker_6, file_data)
}

# Standardize site names
flow_tracker_6 <- flow_tracker_6 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_6 <- flow_tracker_6 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_6)

# Write the final CSV file
write.csv(flow_tracker_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_6.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 7}

# Define a function to search for files
find_files <- function(week_7_directory) {
  week_7_files <- list.files(path = week_7_directory, recursive = TRUE, full.names = TRUE)
  return(week_7_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_7_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week7"

# Find all files in the week 7 directory
week_7_files <- find_files(week_7_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_7 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_7_files) {
  file_data <- extract_values(file)
  flow_tracker_7 <- bind_rows(flow_tracker_7, file_data)
}

# Standardize site names
flow_tracker_7 <- flow_tracker_7 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_7 <- flow_tracker_7 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_7)

# Write the final CSV file
write.csv(flow_tracker_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_7.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 8}

# Define a function to search for files
find_files <- function(week_8_directory) {
  week_8_files <- list.files(path = week_8_directory, recursive = TRUE, full.names = TRUE)
  return(week_8_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_8_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week8"

# Find all files in the week 8 directory
week_8_files <- find_files(week_8_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_8 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_8_files) {
  file_data <- extract_values(file)
  flow_tracker_8 <- bind_rows(flow_tracker_8, file_data)
}

# Standardize site names
flow_tracker_8 <- flow_tracker_8 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_8 <- flow_tracker_8 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_8)

# Write the final CSV file
write.csv(flow_tracker_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_8.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 9}

# Define a function to search for files
find_files <- function(week_9_directory) {
  week_9_files <- list.files(path = week_9_directory, recursive = TRUE, full.names = TRUE)
  return(week_9_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_9_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week9"

# Find all files in the week 9 directory
week_9_files <- find_files(week_9_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_9 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_9_files) {
  file_data <- extract_values(file)
  flow_tracker_9 <- bind_rows(flow_tracker_9, file_data)
}

# Standardize site names
flow_tracker_9 <- flow_tracker_9 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_9 <- flow_tracker_9 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_9)

# Write the final CSV file
write.csv(flow_tracker_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_9.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 10}

# Define a function to search for files
find_files <- function(week_10_directory) {
  week_10_files <- list.files(path = week_10_directory, recursive = TRUE, full.names = TRUE)
  return(week_10_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_10_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week10"

# Find all files in the week 10 directory
week_10_files <- find_files(week_10_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_10 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_10_files) {
  file_data <- extract_values(file)
  flow_tracker_10 <- bind_rows(flow_tracker_10, file_data)
}

# Standardize site names
flow_tracker_10 <- flow_tracker_10 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_10 <- flow_tracker_10 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_10)

# Write the final CSV file
write.csv(flow_tracker_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_10.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 11}

# Define a function to search for files
find_files <- function(week_11_directory) {
  week_11_files <- list.files(path = week_11_directory, recursive = TRUE, full.names = TRUE)
  return(week_11_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_11_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week11"

# Find all files in the week 11 directory
week_11_files <- find_files(week_11_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_11 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_11_files) {
  file_data <- extract_values(file)
  flow_tracker_11 <- bind_rows(flow_tracker_11, file_data)
}

# Standardize site names
flow_tracker_11 <- flow_tracker_11 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_11 <- flow_tracker_11 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_11)

# Write the final CSV file
write.csv(flow_tracker_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_11.csv",
          row.names = FALSE)

```

```{r combine flow tracker files for week 12}

# Define a function to search for files
find_files <- function(week_12_directory) {
  week_12_files <- list.files(path = week_12_directory, recursive = TRUE, full.names = TRUE)
  return(week_12_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  
  # Extract the temperature value and unit
  #mean_temp_value <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column3) %>% pull()
  #temp_unit <- df %>% filter(Column1 == "Mean_Temp") %>% select(Column2) %>% pull()

  # Convert only if the unit is Fahrenheit ("°F")
  #if (temp_unit == "°F") {
    #mean_temp_value <- (as.numeric(mean_temp_value) - 32) * 5 / 9
  #} else {
    #mean_temp_value <- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA
  #}
  
  # Round values to 2 decimal places
  #mean_temp_value <- round(mean_temp_value, 2)
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type
    #meanTemp = mean_temp_value,  # Already handled as numeric
    stringsAsFactors = FALSE
  )
}

week_12_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week12"

# Find all files in the week 12 directory
week_12_files <- find_files(week_12_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_12 <- data.frame(
  localEndTime = character(),
  river = character(),
  totalDischarge = numeric(),  # Initialize as numeric
  #meanTemp = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_12_files) {
  file_data <- extract_values(file)
  flow_tracker_12 <- bind_rows(flow_tracker_12, file_data)
}

# Standardize site names
flow_tracker_12 <- flow_tracker_12 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_12 <- flow_tracker_12 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_12)

# Write the final CSV file
write.csv(flow_tracker_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_12.csv", 
          row.names = FALSE)

```

## Preparing Flow Tracker Files

```{r add day and night shift differentiation into the flow week 1}

# Read in the flow data
flow_tracker_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_1.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_1$dateTime_EDT <- as.POSIXct(flow_tracker_1$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "America/New_York")

# Force the DateTime column from EDT to EST
flow_tracker_1$dateTime_EST <- as.POSIXct(format(flow_tracker_1$dateTime_EDT, 
                                                  tz = "EST", 
                                                  usetz = TRUE), 
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
flow_tracker_1 <- flow_tracker_1 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_1 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_1 <- bind_rows(flow_tracker_1, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_1)

# Write new flow csv
write.csv(flow_tracker_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 2}

# Read in the flow data
flow_tracker_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_2.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_2$dateTime_EST <- as.POSIXct(flow_tracker_2$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
flow_tracker_2 <- flow_tracker_2 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 10 & hour(dateTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_2 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_2 <- bind_rows(flow_tracker_2, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_2)

# Write new flow csv
write.csv(flow_tracker_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 3}

# Read in the flow data
flow_tracker_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_3.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_3$dateTime_EST <- as.POSIXct(flow_tracker_3$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
flow_tracker_3 <- flow_tracker_3 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_3 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_3 <- bind_rows(flow_tracker_3, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_3)

# Write new flow csv
write.csv(flow_tracker_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 4}

# Read in the flow data
flow_tracker_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_4.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_4$dateTime_EST <- as.POSIXct(flow_tracker_4$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
flow_tracker_4 <- flow_tracker_4 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_4 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_4 <- bind_rows(flow_tracker_4, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_4)

# Write new flow csv
write.csv(flow_tracker_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 5}

# Read in the flow data
flow_tracker_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_5.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_5$dateTime_EST <- as.POSIXct(flow_tracker_5$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_5 <- flow_tracker_5 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_5 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_5 <- bind_rows(flow_tracker_5, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_5)

# Write new flow csv
write.csv(flow_tracker_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 6}

# Read in the flow data
flow_tracker_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_6.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_6$dateTime_EST <- as.POSIXct(flow_tracker_6$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
flow_tracker_6 <- flow_tracker_6 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_6 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_6 <- bind_rows(flow_tracker_6, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_6)

# Write new flow csv
write.csv(flow_tracker_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 7}

# Read in the flow data
flow_tracker_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_7.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_7$dateTime_EST <- as.POSIXct(flow_tracker_7$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_7 <- flow_tracker_7 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_7 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_7 <- bind_rows(flow_tracker_7, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_7)

# Write new flow csv
write.csv(flow_tracker_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 8}

# Read in the flow data
flow_tracker_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_8.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_8$dateTime_EST <- as.POSIXct(flow_tracker_8$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
flow_tracker_8 <- flow_tracker_8 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_8 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_8 <- bind_rows(flow_tracker_8, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_8)

# Write new flow csv
write.csv(flow_tracker_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 9}

# Read in the flow data
flow_tracker_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_9.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_9$dateTime_EST <- as.POSIXct(flow_tracker_9$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_9 <- flow_tracker_9 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_9 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_9 <- bind_rows(flow_tracker_9, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_9)

# Write new flow csv
write.csv(flow_tracker_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 10}

# Read in the flow data
flow_tracker_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_10.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_10$dateTime_EST <- as.POSIXct(flow_tracker_10$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
flow_tracker_10 <- flow_tracker_10 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 3 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_10 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_10 <- bind_rows(flow_tracker_10, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_10)

# Write new flow csv
write.csv(flow_tracker_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 11}

# Read in the flow data
flow_tracker_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_11.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_11$dateTime_EST <- as.POSIXct(flow_tracker_11$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
flow_tracker_11 <- flow_tracker_11 %>%
  mutate(shift = "day")

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_11 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge
    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_11 <- bind_rows(flow_tracker_11, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_11)

# Write new flow csv
write.csv(flow_tracker_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 12}

# Read in the flow data
flow_tracker_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_12.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_12$dateTime_EST <- as.POSIXct(flow_tracker_12$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
flow_tracker_12 <- flow_tracker_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(flow_tracker_12)

# Write new flow csv
write.csv(flow_tracker_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_12.csv", 
          row.names = FALSE)

```

```{r processing flow files}

# Define the path to the folder where the files are located
flow_tracker_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/" 

# Define file names
flow_file_names <- paste0(flow_tracker_data, c("flow_tracker_1.csv", "flow_tracker_2.csv", "flow_tracker_3.csv", "flow_tracker_4.csv", 
                     "flow_tracker_5.csv", "flow_tracker_6.csv", "flow_tracker_7.csv", "flow_tracker_8.csv", 
                     "flow_tracker_9.csv", "flow_tracker_10.csv", "flow_tracker_11.csv", "flow_tracker_12.csv")) 

# Create an empty list to store the processed datasets
processed_flow_data_list <- list()

# Loop through each stream survey file
for (file_name in flow_file_names) {
  # Read in the stream survey data
  raw_flow_data <- read.csv(file_name)
  
  # Step 1: Process the data
  flow_data <- raw_flow_data %>%
    
    # Step 2: Select specific columns
    select(river, totalDischarge, dateTime_EST, shift) %>%

    # Step 3: Rename columns
    rename(flowTime_EST = dateTime_EST) 
  
  # Store the processed data in the list
  processed_flow_data_list[[file_name]] <- flow_data
  
  # Overwrite the original file with the processed data
  write.csv(flow_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_flow_data_list)) {
  cat("\nData for", flow_file_names[i], ":\n")
  print(head(processed_flow_data_list[[i]]))
}

```



## Combine fish survey and flow data

```{r combine fish survey and flow week 1 data}

# Read in the fish survey and flow data for week 1
fish_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_1.csv")
flow_tracker_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_1.csv")

# Combine the datasets by shift and river columns
fish_flow_1 <- left_join(fish_survey_1, flow_tracker_1, 
                                by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_1.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 2 data}

# Read in the fish survey and flow data for week 2
fish_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_2.csv")
flow_tracker_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_2.csv")

# Combine the datasets by shift and river columns
fish_flow_2 <- left_join(fish_survey_2, flow_tracker_2, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_2.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 3 data}

# Read in the fish survey and flow data for week 3
fish_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_3.csv")
flow_tracker_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_3.csv")

# Combine the datasets by shift and river columns
fish_flow_3 <- left_join(fish_survey_3, flow_tracker_3, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_3.csv", 
          row.names = FALSE)

```
```{r combine fish survey and flow week 4 data}

# Read in the fish survey and flow data for week 4
fish_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_4.csv")
flow_tracker_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_4.csv")

# Combine the datasets by shift and river columns
fish_flow_4 <- left_join(fish_survey_4, flow_tracker_4, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_4.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 5 data}

# Read in the fish survey and flow data for week 5
fish_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_5.csv")
flow_tracker_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_5.csv")

# Combine the datasets by shift and river columns
fish_flow_5 <- left_join(fish_survey_5, flow_tracker_5, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_5.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 6 data}

# Read in the fish survey and flow data for week 6
fish_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_6.csv")
flow_tracker_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_6.csv")

# Combine the datasets by shift and river columns
fish_flow_6 <- left_join(fish_survey_6, flow_tracker_6, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_6.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 7 data}

# Read in the fish survey and flow data for week 7
fish_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_7.csv")
flow_tracker_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_7.csv")

# Combine the datasets by shift and river columns
fish_flow_7 <- left_join(fish_survey_7, flow_tracker_7, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_7.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 8 data}

# Read in the fish survey and flow data for week 8
fish_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_8.csv")
flow_tracker_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_8.csv")

# Combine the datasets by shift and river columns
fish_flow_8 <- left_join(fish_survey_8, flow_tracker_8, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_8.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 9 data}

# Read in the fish survey and flow data for week 9
fish_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_9.csv")
flow_tracker_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_9.csv")

# Combine the datasets by shift and river columns
fish_flow_9 <- left_join(fish_survey_9, flow_tracker_9, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_9.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 10 data}

# Read in the fish survey and flow data for week 10
fish_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_10.csv")
flow_tracker_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_10.csv")

# Combine the datasets by shift and river columns
fish_flow_10 <- left_join(fish_survey_10, flow_tracker_10, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_10.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 11 data}

# Read in the fish survey and flow data for week 11
fish_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_11.csv")
flow_tracker_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_11.csv")

# Combine the datasets by shift and river columns
fish_flow_11 <- left_join(fish_survey_11, flow_tracker_11, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_11.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 12 data}

# Read in the fish survey and flow data for week 12
fish_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_data/fish_survey_12.csv")
flow_tracker_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_data/flow_tracker_12.csv")

# Combine the datasets by shift and river columns
fish_flow_12 <- left_join(fish_survey_12, flow_tracker_12, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_12.csv", 
          row.names = FALSE)

```


## Preparing lotek data files for analysis

### Lotek receiver 000900 data

```{r processing the lotek receiver 000900 ID only data}

# ID Only Data ###########################################################

# Read the dataset
receiver_000900_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000900_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID Only Records:" and create a flag
receiver_000900_ID_data <- receiver_000900_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID Only Records:", 1, 0)) 

# Detect the start of row that says "ID + GPS Positions:"
id_gps_row <- which(receiver_000900_raw_data$columnOne == "ID + GPS Positions:")

# If "ID + GPS Positions:" is found, slice until the row before it
if(length(id_gps_row) > 0) {
  id_gps_row <- id_gps_row[1] - 1  # One row before "ID + GPS Positions:"
} else {
  id_gps_row <- nrow(receiver_000900_raw_data)  # If "ID + GPS Positions:" not found, slice till the bottom
}

# Slice out the ID data by detecting the start and extracting relevant rows
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  slice((which(grepl(1, receiver_000900_ID_data$column2)) + 2) : id_gps_row)

receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , 
           c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", 
           sep = "\\s+")
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "Power") 

# Combine the date and time into a DateTime column
receiver_000900_ID_data$dateTime_EST <- as.POSIXct(paste(receiver_000900_ID_data$Date, 
                                                         receiver_000900_ID_data$Time), 
                                                   format="%m/%d/%y %H:%M:%S",
                                                   tz = "EST")
  
#receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Combine Date and Time columns into a single datetime in mdy_hms format
  #mutate(dateTime = mdy_hms(paste(Date, Time))) 
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Rename "Tag ID' column as "tagID"
  rename_with(~ "tagID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) %>%
  
  # Rename "Power' column as "power"
  rename_with(~ "power", .cols = `Power`)
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for further processing
  select("date", "tagID", "power", "dateTime_EST") 

receiver_000900_ID_data <- receiver_000900_ID_data %>%
  # Clean and format the data
  mutate(tagID = as.numeric(tagID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Filter by tagID range
  filter(tagID > 10 & tagID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))


# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", 
                     "2024-07-18", "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", 
                   "2024-08-29", "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(tagID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(tagID_range, ~ tagID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000900_ID_data$date <- ymd(receiver_000900_ID_data$date)

# Apply the function to the data frame
receiver_000900_ID_data <- receiver_000900_ID_data %>%
  mutate(river = mapply(assign_river, tagID, date))

# Remove rows where river is "Unknown"
receiver_000900_ID_data <- receiver_000900_ID_data %>%
  filter(river != "Unknown")

receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for the final dataframe
  select("tagID", "power", "dateTime_EST", "river", "date") 

# View dataframe
head(receiver_000900_ID_data)

```

```{r processing the lotek receiver 000900 ID + GPS data}

# ID + GPS Data ###########################################################

# Read the dataset
receiver_000900_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000900_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID + GPS Positions:" and create a flag
receiver_000900_GPS_data <- receiver_000900_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID + GPS Positions:", 1, 0)) 

# Detect the start of row that says "End of Data" 
end_of_data_row <- which(receiver_000900_raw_data$columnOne == "End of Data")

# If "End of Data" is found, slice until the row before it
if(length(end_of_data_row) > 0) {
  end_of_data_row <- end_of_data_row[1] - 1  # One row before "End of data"
} else {
  end_of_data_row <- nrow(receiver_000900_raw_data)  # If "End of data" not found, slice till the bottom
}

# Slice out the GPS data by detecting the start and extracting relevant rows
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  slice((which(grepl(1, receiver_000900_GPS_data$column2)) + 2) : end_of_data_row)

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", sep = "\\s+")

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Separate the "Power" column into power, latitude, and longitude
  separate(Power, c("power", "lat", "lon"), sep = "\\s+") 
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "power", "lon", "lat") 
  
# Combine the date and time into a DateTime column
receiver_000900_GPS_data$dateTime_EST <- as.POSIXct(paste(receiver_000900_GPS_data$Date, 
                                                          receiver_000900_GPS_data$Time), 
                                                    format="%m/%d/%y %H:%M:%S",
                                                    tz = "EST")
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Rename "Tag ID' column as "tagID"
  rename_with(~ "tagID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) 
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for further processing
  select("date", "tagID", "power","lon", "lat", "dateTime_EST") 

receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  # Clean and format the data
  mutate(lat = as.numeric(lat), 
         lon = as.numeric(lon),
         tagID = as.numeric(tagID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Filter by tagID range
  filter(tagID > 10 & tagID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))

# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", "2024-07-18", 
                         "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", "2024-08-29", 
                       "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(tagID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(tagID_range, ~ tagID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000900_GPS_data$date <- ymd(receiver_000900_GPS_data$date)

# Apply the function to the data frame
receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  mutate(river = mapply(assign_river, tagID, date))

# Remove rows where river is "Unknown"
receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  filter(river != "Unknown")

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for the final dataframe
  select("tagID", "power","lon", "lat", "dateTime_EST", "river", "date")

# View dataframe
head(receiver_000900_GPS_data)

```


```{r combining the lotek receiver 000900 data back into one dataframe}

# Combine back into one dataframe ###########################################################

# Combine the two final dataframes horizontally 
receiver_000900_data <- bind_rows(receiver_000900_ID_data, receiver_000900_GPS_data)

# Clean workspace by removing excess variables
rm(river_date_ranges, receiver_000900_raw_data, receiver_000900_ID_data, receiver_000900_GPS_data)

# View dataframe
head(receiver_000900_data)

```

### Lotek receiver 000517 data
No ID+GPS data on this receiver - No combination needed

```{r processing the lotek receiver 000517 ID only data}

# ID Only Data ###########################################################

# Read the dataset
receiver_000517_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000517/20240912/000517_20240912.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000517_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID Only Records:" and create a flag
receiver_000517_ID_data <- receiver_000517_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID Only Records:", 1, 0)) 

# Detect the start of row that says "End of Data" 
end_of_data_row <- which(receiver_000517_raw_data$columnOne == "End of Data")

# If "End of Data" is found, slice until the row before it
if(length(end_of_data_row) > 0) {
  end_of_data_row <- end_of_data_row[1] - 1  # One row before "End of data"
} else {
  end_of_data_row <- nrow(receiver_000517_raw_data)  # If "End of data" not found, slice till the bottom
}

# Slice out the data by detecting the start and extracting relevant rows
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  slice((which(grepl(1, receiver_000517_ID_data$column2)) + 2) : end_of_data_row)

receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", sep = "\\s+")
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "Power") 
  
# Combine the date and time into a DateTime column
receiver_000517_ID_data$dateTime_EST <- as.POSIXct(paste(receiver_000517_ID_data$Date, 
                                                         receiver_000517_ID_data$Time), 
                                                   format="%m/%d/%y %H:%M:%S",
                                                   tz = "EST") 
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Rename "Tag ID' column as "tagID"
  rename_with(~ "tagID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) %>%
  
  # Rename "Power' column as "power"
  rename_with(~ "power", .cols = `Power`)
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for further processing
  select("date", "tagID", "power", "dateTime_EST") 

receiver_000517_ID_data <- receiver_000517_ID_data %>%
  # Clean and format the data
  mutate(tagID = as.numeric(tagID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Filter by tagID range
  filter(tagID > 10 & tagID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))

# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", "2024-07-18", 
                         "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", "2024-08-29", 
                       "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(tagID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(tagID_range, ~ tagID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000517_ID_data$date <- ymd(receiver_000517_ID_data$date)

# Apply the function to the data frame
receiver_000517_ID_data <- receiver_000517_ID_data %>%
  mutate(river = mapply(assign_river, tagID, date))

# Remove rows where river is "Unknown"
receiver_000517_ID_data <- receiver_000517_ID_data %>%
  filter(river != "Unknown")

receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for the final dataframe
  select("tagID", "power", "dateTime_EST", "river", "date") 

# Clean workspace by removing excess variables
rm(receiver_000517_raw_data, river_date_ranges)

# View dataframe
head(receiver_000517_ID_data)

```
### Combine all data from all receivers

```{r combine data from multiple receivers}

# Combine multiple receivers into one dataframe ########################################

# Combine the two final dataframes horizontally
receiver_data_all <- bind_rows(receiver_000900_data, receiver_000517_ID_data)

# Clean workspace by removing excess variables
rm(receiver_000900_data, receiver_000517_ID_data)

# View dataframe
head(receiver_data_all)

```

### Add day and night shift differentiation into receiver data

```{r add day and night shift differentiation into the receiver data}

receiver_data_all <- receiver_data_all %>%
  mutate(
    shift = case_when(
      # Define shift for week 1
      date(dateTime_EST) >= ymd("2024-06-11") & date(dateTime_EST) <= ymd("2024-06-14") &
      hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
      
      # Define shift for week 2
      date(dateTime_EST) >= ymd("2024-06-17") & date(dateTime_EST) <= ymd("2024-06-20") &
      hour(dateTime_EST) >= 10 & hour(dateTime_EST) < 18 ~ "day",
      
      # Define shift for week 3
      date(dateTime_EST) >= ymd("2024-06-25") & date(dateTime_EST) <= ymd("2024-06-28") &
      hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
      
      # Define shift for week 4
      date(dateTime_EST) >= ymd("2024-06-30") & date(dateTime_EST) <= ymd("2024-07-03") &
      hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
      
      # Define shift for week 5
      date(dateTime_EST) >= ymd("2024-07-09") & date(dateTime_EST) <= ymd("2024-07-12") &
      hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
      
      # Define shift for week 6
      date(dateTime_EST) >= ymd("2024-07-16") & date(dateTime_EST) <= ymd("2024-07-19") &
      hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
      
      # Define shift for week 7
      date(dateTime_EST) >= ymd("2024-07-23") & date(dateTime_EST) <= ymd("2024-07-26") &
      hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
      
      # Define shift for week 8
      date(dateTime_EST) >= ymd("2024-07-30") & date(dateTime_EST) <= ymd("2024-08-02") &
      hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 11 ~ "day",
      
      # Define shift for supplementary tracking on August 5, 2024
      date(dateTime_EST) == ymd("2024-08-05") ~ "day",
      
      # Define shift for week 9
      date(dateTime_EST) >= ymd("2024-08-06") & date(dateTime_EST) <= ymd("2024-08-09") &
      hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
      
      # Define shift for week 10
      date(dateTime_EST) >= ymd("2024-08-13") & date(dateTime_EST) <= ymd("2024-08-16") &
      hour(dateTime_EST) >= 3 & hour(dateTime_EST) < 11 ~ "day",
      
      # Define shift for week 11
      date(dateTime_EST) >= ymd("2024-08-20") & date(dateTime_EST) <= ymd("2024-08-23") ~ "day",
      
      # Define shift for week 12
      date(dateTime_EST) >= ymd("2024-08-26") & date(dateTime_EST) <= ymd("2024-08-29") ~ "day",
      
      # Default to night shift for all other times
      TRUE ~ "night"
    )
  )

receiver_data_all <- receiver_data_all %>%
  # Rename column
  mutate(trackedTime_EST = dateTime_EST,
         source = "receiver")

receiver_data_all <- receiver_data_all %>% 
  # Select the columns for the final dataframe
  select("date", "trackedTime_EST", "river", "shift", "tagID", "power", "lon", "lat", "source")

head(receiver_data_all)

# Write the dataframe into a csv
write.csv(receiver_data_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_all.csv", 
          row.names = FALSE)

```

```{r split receiver data into weekly CSV files}

# Step 1: Define specific date ranges for each week
week_ranges <- data.frame(
  week_name = c("week_1", "week_2", "week_3", "week_4", "week_5", "week_6", "week_7", "week_8", "week_9", "week_10", "week_11", "week_12"),  
  start_date = ymd(c("2024-06-11", "2024-06-17", "2024-06-25", "2024-06-30", "2024-07-09", "2024-07-16", "2024-07-23", "2024-07-30", "2024-08-05", "2024-08-13", "2024-08-20", "2024-08-26")),
  end_date = ymd(c("2024-06-14", "2024-06-20", "2024-06-28", "2024-07-03", "2024-07-12", "2024-07-19", "2024-07-26", "2024-08-02", "2024-08-09", "2024-08-16", "2024-08-23", "2024-08-29"))
)

# Initialize a counter for naming datasets
counter <- 1

# Step 2: Loop through each date range and filter the dataset
for (i in 1:nrow(week_ranges)) {
  # Filter the dataset for each specified date range
  weekly_receiver_data <- receiver_data_all %>%
    filter(date >= week_ranges$start_date[i] & date <= week_ranges$end_date[i]) %>%
    
    # Remove the 'date' column before saving the CSV
    select(-date)
  
  # Dynamically name each week's data (e.g., receiver_data_1, receiver_data_2, ...)
  assign(paste0("receiver_data_", counter), weekly_receiver_data)
  
  # Save the dataset to a CSV file
  receiver_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/"
  file_name <- paste0(receiver_data, "receiver_data_", counter, ".csv")
  write.csv(weekly_receiver_data, file = file_name, row.names = FALSE)
  
  # Display the first few rows of the created datasets
  cat("\nData for", file_name, ":\n")
  print(head(weekly_receiver_data))  # Print the first few rows of each weekly dataset
  
  # Increment the counter
  counter <- counter + 1
}

```

## Combine fish survey and receiver data

```{r combine fish_flow and receiver week 1 data}

# No receiver data for this week yet #########################

# Read in the fish_flow survey and receiver data for week 1
fish_flow_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_1.csv")
receiver_data_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_1.csv")

# Combine the datasets horizontally
#fish_flow_receiver_1 <- bind_rows(fish_flow_1, receiver_data_1)

# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week
fish_flow_receiver_1 <- fish_flow_1

# Display the first few rows of the combined data
head(fish_flow_receiver_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_1.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 2 data}

# No receiver data for this week yet #########################

# Read in the fish_flow survey and receiver data for week 2
fish_flow_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_2.csv")
receiver_data_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_2.csv")

# Combine the datasets horizontally
#fish_flow_receiver_2 <- bind_rows(fish_flow_2, receiver_data_2)

# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week
fish_flow_receiver_2 <- fish_flow_2

# Display the first few rows of the combined data
head(fish_flow_receiver_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_2.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 3 data}

# Read in the fish_flow survey and receiver data for week 3
fish_flow_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_3.csv")
receiver_data_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_3.csv")

# Combine the datasets horizontally
fish_flow_receiver_3 <- bind_rows(fish_flow_3, receiver_data_3)

# Display the first few rows of the combined data
head(fish_flow_receiver_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_3.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 4 data}

# Read in the fish_flow survey and receiver data for week 4
fish_flow_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_4.csv")
receiver_data_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_4.csv")

# Combine the datasets horizontally
fish_flow_receiver_4 <- bind_rows(fish_flow_4, receiver_data_4)

# Display the first few rows of the combined data
head(fish_flow_receiver_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_4.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 5 data}

# Read in the fish_flow survey and receiver data for week 5
fish_flow_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_5.csv")
receiver_data_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_5.csv")

# Combine the datasets horizontally
fish_flow_receiver_5 <- bind_rows(fish_flow_5, receiver_data_5)

# Display the first few rows of the combined data
head(fish_flow_receiver_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_5.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 6 data}

# Read in the fish_flow survey and receiver data for week 6
fish_flow_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_6.csv")
receiver_data_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_6.csv")

# Combine the datasets horizontally
fish_flow_receiver_6 <- bind_rows(fish_flow_6, receiver_data_6)

# Display the first few rows of the combined data
head(fish_flow_receiver_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_6.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 7 data}

# Read in the fish_flow survey and receiver data for week 7
fish_flow_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_7.csv")
receiver_data_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_7.csv")

# Combine the datasets horizontally
fish_flow_receiver_7 <- bind_rows(fish_flow_7, receiver_data_7)

# Display the first few rows of the combined data
head(fish_flow_receiver_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_7.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 8 data}

# Read in the fish_flow survey and receiver data for week 8
fish_flow_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_8.csv")
receiver_data_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_8.csv")

# Combine the datasets horizontally
fish_flow_receiver_8 <- bind_rows(fish_flow_8, receiver_data_8)

# Display the first few rows of the combined data
head(fish_flow_receiver_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_8.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 9 data}

# Read in the fish_flow survey and receiver data for week 9
fish_flow_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_9.csv")
receiver_data_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_9.csv")

# Combine the datasets horizontally
fish_flow_receiver_9 <- bind_rows(fish_flow_9, receiver_data_9)

# Display the first few rows of the combined data
head(fish_flow_receiver_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_9.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 10 data}

# Read in the fish_flow survey and receiver data for week 10
fish_flow_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_10.csv")
receiver_data_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_10.csv")

# Combine the datasets horizontally
fish_flow_receiver_10 <- bind_rows(fish_flow_10, receiver_data_10)

# Display the first few rows of the combined data
head(fish_flow_receiver_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_10.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 11 data}

# Read in the fish_flow survey and receiver data for week 11
fish_flow_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_11.csv")
receiver_data_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_11.csv")

# Combine the datasets horizontally
fish_flow_receiver_11 <- bind_rows(fish_flow_11, receiver_data_11)

# Display the first few rows of the combined data
head(fish_flow_receiver_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_11.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 12 data}

# Read in the fish_flow survey and receiver data for week 12
fish_flow_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_12.csv")
receiver_data_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data/receiver_data_12.csv")

# Combine the datasets horizontally
fish_flow_receiver_12 <- bind_rows(fish_flow_12, receiver_data_12)

# Display the first few rows of the combined data
head(fish_flow_receiver_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_12.csv", 
          row.names = FALSE)

```

## Preparing Stream Surveys

```{r add day and night shift differentiation into the stream survey 1}

# Read in the stream survey data
stream_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 1.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_1$date <- as.Date(stream_survey_1$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_1$dateTime_EST <- as.POSIXct(paste(stream_survey_1$date, 
                                                 stream_survey_1$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
stream_survey_1 <- stream_survey_1 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_1)

# Write new stream survey csv
write.csv(stream_survey_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 2}

# Read in the stream survey data
stream_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 2.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_2$date <- as.Date(stream_survey_2$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_2$dateTime_EST <- as.POSIXct(paste(stream_survey_2$date, 
                                                 stream_survey_2$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
stream_survey_2 <- stream_survey_2 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 10 & hour(dateTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_2)

# Write new stream survey csv
write.csv(stream_survey_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 3}

# Read in the stream survey data
stream_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 3.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_3$date <- as.Date(stream_survey_3$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_3$dateTime_EST <- as.POSIXct(paste(stream_survey_3$date, 
                                                 stream_survey_3$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
stream_survey_3 <- stream_survey_3 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_3)

# Write new stream survey csv
write.csv(stream_survey_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 4}

# Read in the stream survey data
stream_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 4.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_4$date <- as.Date(stream_survey_4$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_4$dateTime_EST <- as.POSIXct(paste(stream_survey_4$date, 
                                                 stream_survey_4$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
stream_survey_4 <- stream_survey_4 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_4)

# Write new stream survey csv
write.csv(stream_survey_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 5}

# Read in the stream survey data
stream_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 5.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_5$date <- as.Date(stream_survey_5$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_5$dateTime_EST <- as.POSIXct(paste(stream_survey_5$date, 
                                                 stream_survey_5$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_5 <- stream_survey_5 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_5)

# Write new stream survey csv
write.csv(stream_survey_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 6}

# Read in the stream survey data
stream_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 6.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_6$date <- as.Date(stream_survey_6$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_6$dateTime_EST <- as.POSIXct(paste(stream_survey_6$date, 
                                                 stream_survey_6$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
stream_survey_6 <- stream_survey_6 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_6)

# Write new stream survey csv
write.csv(stream_survey_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 7}

# Read in the stream survey data
stream_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 7.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_7$date <- as.Date(stream_survey_7$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_7$dateTime_EST <- as.POSIXct(paste(stream_survey_7$date, 
                                                 stream_survey_7$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_7 <- stream_survey_7 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_7)

# Write new stream survey csv
write.csv(stream_survey_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 8}

# Read in the stream survey data
stream_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 8.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_8$date <- as.Date(stream_survey_8$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_8$dateTime_EST <- as.POSIXct(paste(stream_survey_8$date, 
                                                 stream_survey_8$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
stream_survey_8 <- stream_survey_8 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_8)

# Write new stream survey csv
write.csv(stream_survey_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 9}

# Read in the stream survey data
stream_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 9.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_9$date <- as.Date(stream_survey_9$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_9$dateTime_EST <- as.POSIXct(paste(stream_survey_9$date, 
                                                 stream_survey_9$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_9 <- stream_survey_9 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_9)

# Write new stream survey csv
write.csv(stream_survey_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 10}

# Read in the stream survey data
stream_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 10.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_10$date <- as.Date(stream_survey_10$date, 
                                 format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_10$dateTime_EST <- as.POSIXct(paste(stream_survey_10$date, 
                                                  stream_survey_10$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
stream_survey_10 <- stream_survey_10 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 3 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_10)

# Write new stream survey csv
write.csv(stream_survey_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 11}

# Read in the stream survey data
stream_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 11.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_11$date <- as.Date(stream_survey_11$date, 
                                 format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_11$dateTime_EST <- as.POSIXct(paste(stream_survey_11$date, 
                                                  stream_survey_11$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
stream_survey_11 <- stream_survey_11 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(stream_survey_11)

# Write new stream survey csv
write.csv(stream_survey_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 12}

# Read in the stream survey data
stream_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 12.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_12$date <- as.Date(stream_survey_12$date, 
                                 format = "%m/%d/%Y")

# Combining the date and start time into a DateTime column
stream_survey_12$dateTime_EST <- as.POSIXct(paste(stream_survey_12$date, 
                                                  stream_survey_12$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
stream_survey_12 <- stream_survey_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(stream_survey_12)

# Write new stream survey csv
write.csv(stream_survey_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_12.csv", 
          row.names = FALSE)

```

```{r processing stream surveys}

# Define the path to the sub-folder
stream_survey_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/"

# Define file names
stream_file_names <- paste0(stream_survey_data, c("stream_survey_1.csv", "stream_survey_2.csv", "stream_survey_3.csv", "stream_survey_4.csv", 
                       "stream_survey_5.csv", "stream_survey_6.csv", "stream_survey_7.csv", "stream_survey_8.csv", 
                       "stream_survey_9.csv", "stream_survey_10.csv", "stream_survey_11.csv", "stream_survey_12.csv")) 

# Define a lookup table for stream names
stream_name_lookup <- data.frame(
  abbreviation = c("Dickey (DCKY)", "Amethyst (AMTH)", 
                   "Underhill (UNDH)", "Dry (DRYU)"),  # List all abbreviations
  full_name = c("DICKEY", "AMETHYST", 
                "UNDERHILL", "DRY UPPER")  # Corresponding full names
)

# Create an empty list to store the processed datasets
processed_stream_data_list <- list()

# Loop through each stream survey file
for (file_name in stream_file_names) {
  
  # Read in the stream survey data
  raw_stream_data <- read.csv(file_name)
  
  # Step 1: Process the data
  stream_data <- raw_stream_data %>%
    
    # Step 2: Select specific columns
    select(stream, airTemp, cloud, precip, startTime, endTime, iso, Notes, 
           isoTime, downstreamGPS, downstreamGain, upstreamGPS, upstreamGain, shift) %>%

    # Step 3: Rename columns
    rename(
      streamNotes = Notes,
      river = stream,
      startTime_EST = startTime,
      endTime_EST = endTime,
      isoID = iso,
      isoTime_EST = isoTime) %>%
    
    # Step 4: Rewrite stream names
    left_join(stream_name_lookup, by = c("river" = "abbreviation")) %>%
    mutate(
      river = coalesce(full_name, river)  # Replace Brook with full_name, if available
    ) %>%
    select(-full_name)  # Remove the full_name column as it's no longer needed
  
  # Store the processed data in the list
  processed_stream_data_list[[file_name]] <- stream_data
  
  # Overwrite the original file with the processed data
  write.csv(stream_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_stream_data_list)) {
  cat("\nData for", stream_file_names[i], ":\n")
  print(head(processed_stream_data_list[[i]]))
}

```

## Combine fish_flow_receiver and stream survey data

```{r combine fish_flow_receiver and stream week 1 surveys}

# Read in the fish_flow_receiver and stream survey data for week 1
fish_flow_receiver_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_1.csv")
stream_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_1.csv")

# Adjust 'river' in fish_flow_receiver survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_1 <- fish_flow_receiver_1 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_1 <- left_join(fish_flow_receiver_1, 
                           stream_survey_1, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_1 <- fish_flow_receiver_stream_1 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_1.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 2 surveys}

# Read in the fish_flow_receiver and stream survey data for week 2
fish_flow_receiver_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_2.csv")
stream_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_2.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_2 <- fish_flow_receiver_2 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_2 <- left_join(fish_flow_receiver_2, 
                           stream_survey_2, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_2 <- fish_flow_receiver_stream_2 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_2.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 3 surveys}

# Read in the fish_flow_receiver and stream survey data for week 3
fish_flow_receiver_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_3.csv")
stream_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_3.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_3 <- fish_flow_receiver_3 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_3 <- left_join(fish_flow_receiver_3, 
                           stream_survey_3, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_3 <- fish_flow_receiver_stream_3 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_3.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 4 surveys}

# Read in the fish_flow_receiver and stream survey data for week 4
fish_flow_receiver_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_4.csv")
stream_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_4.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_4 <- fish_flow_receiver_4 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_4 <- left_join(fish_flow_receiver_4, 
                           stream_survey_4, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_4 <- fish_flow_receiver_stream_4 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_4.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 5 surveys}

# Read in the fish_flow_receiver and stream survey data for week 5
fish_flow_receiver_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_5.csv")
stream_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_5.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_5 <- fish_flow_receiver_5 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_5 <- left_join(fish_flow_receiver_5, 
                           stream_survey_5, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_5 <- fish_flow_receiver_stream_5 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_5.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 6 surveys}

# Read in the fish_flow_receiver and stream survey data for week 6
fish_flow_receiver_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_6.csv")
stream_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_6.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_6 <- fish_flow_receiver_6 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_6 <- left_join(fish_flow_receiver_6, 
                           stream_survey_6, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_6 <- fish_flow_receiver_stream_6 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_6.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 7 surveys}

# Read in the fish_flow_receiver and stream survey data for week 7
fish_flow_receiver_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_7.csv")
stream_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_7.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_7 <- fish_flow_receiver_7 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_7 <- left_join(fish_flow_receiver_7, 
                           stream_survey_7, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_7 <- fish_flow_receiver_stream_7 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_7.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 8 surveys}

# Read in the fish_flow_receiver and stream survey data for week 8
fish_flow_receiver_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_8.csv")
stream_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_8.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_8 <- fish_flow_receiver_8 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_8 <- left_join(fish_flow_receiver_8, 
                           stream_survey_8, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_8 <- fish_flow_receiver_stream_8 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_8.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 9 surveys}

# Read in the fish_flow_receiver and stream survey data for week 9
fish_flow_receiver_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_9.csv")
stream_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_9.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_9 <- fish_flow_receiver_9 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_9 <- left_join(fish_flow_receiver_9, 
                           stream_survey_9, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_9 <- fish_flow_receiver_stream_9 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_9.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 10 surveys}

# Read in the fish_flow_receiver and stream survey data for week 10
fish_flow_receiver_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_10.csv")
stream_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_10.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_10 <- fish_flow_receiver_10 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_10 <- left_join(fish_flow_receiver_10, 
                            stream_survey_10, 
                            by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_10 <- fish_flow_receiver_stream_10 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_10.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 11 surveys}

# Read in the fish_flow_receiver and stream survey data for week 11
fish_flow_receiver_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_11.csv")
stream_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_11.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_11 <- fish_flow_receiver_11 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_11 <- left_join(fish_flow_receiver_11, 
                            stream_survey_11, 
                            by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_11 <- fish_flow_receiver_stream_11 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_11.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 12 surveys}

# Read in the fish_flow_receiver and stream survey data for week 12
fish_flow_receiver_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_12.csv")
stream_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_data/stream_survey_12.csv")

# Combine the datasets by shift and river columns
fish_flow_receiver_stream_12 <- left_join(fish_flow_receiver_12, 
                            stream_survey_12, 
                            by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_12.csv", 
          row.names = FALSE)

```

## Combine all weekly datasets

```{r combine all weekly datasets (fish, flow, receiver, and stream)}

# Define the path to the folder
combined_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/"

# Define file names
file_names <- paste0(combined_data, c("fish_flow_receiver_stream_1.csv", "fish_flow_receiver_stream_2.csv", "fish_flow_receiver_stream_3.csv", "fish_flow_receiver_stream_4.csv", 
                "fish_flow_receiver_stream_5.csv", "fish_flow_receiver_stream_6.csv", "fish_flow_receiver_stream_7.csv", "fish_flow_receiver_stream_8.csv", 
                "fish_flow_receiver_stream_9.csv", "fish_flow_receiver_stream_10.csv", "fish_flow_receiver_stream_11.csv", "fish_flow_receiver_stream_12.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
fish_flow_receiver_stream_all <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(fish_flow_receiver_stream_all)

# Write the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_all.csv", 
          row.names = FALSE)

```

## Preparing tagging data

```{r processing tagging data}

# Read in the tagging data
tagging_data <- read_excel("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/taggingData.xlsx")

# Select specific columns
tagging_data <- tagging_data %>%
  select(RIVER, DATE, SECTION, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, GENETICSAM, SEX)

# Rename columns
tagging_data <- tagging_data %>%
  rename(
    river = RIVER,
    date = DATE,
    section = SECTION,
    tagID = RADIOTAG,
    tempID = TEMPTAG,
    length = LENGTH,
    weight = WEIGHT,
    geneticSam = GENETICSAM,
    sex = SEX
    )

# Fix column labels and remove first tag 44 since the fish died and was retagged before the study began
tagging_data <- tagging_data %>%
  mutate(river = str_trim(river),
         date = str_trim(date),
         section = str_trim(section),
         tagID = str_trim(tagID),
         tempID = str_trim(tempID),
         length = str_trim(length),
         weight = str_trim(weight),
         geneticSam = str_trim(geneticSam),
         sex = str_trim(sex)) %>%
  filter(!(tagID == "44" & date == as.POSIXct("2024-06-04", format="%Y-%m-%d")))

# Write new tagging data csv
write.csv(tagging_data, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data/tagging_data.csv", 
          row.names = FALSE)

```

## Combine tagging data with fish/stream/flow/receiver data

```{r combine tagging data with fish/stream/flow/receiver data}

# Read in the data
tagging_data = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data/tagging_data.csv")
fish_flow_receiver_stream_all = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_all.csv")

# Create a mapping of radio tag ID to temp tag ID from tagging data
radio_temp_mapping <- tagging_data %>%
  select(tagID, tempID) %>%
  distinct()  # Ensures unique pairings

# Merge this mapping into fish/stream/flow/receiver data
fish_flow_receiver_stream_all <- fish_flow_receiver_stream_all %>%
  left_join(radio_temp_mapping, by = "tagID")

# Create a new column 'date' with just the date part of 'dateTime'
fish_flow_receiver_stream_all <- fish_flow_receiver_stream_all %>%
  mutate(date = as.Date(trackedTime_EST))

# Convert the date column into a matching format as the other dataset
tagging_data <- tagging_data %>%
  mutate(date = as.Date(date))

# Combine the datasets by binding rows horizontally
fish_flow_receiver_stream_tagging_all <- bind_rows(fish_flow_receiver_stream_all, tagging_data)

# Now the combined dataframe should have all tempTagIDs added where appropriate

# Write new tagging data csv
write.csv(fish_flow_receiver_stream_tagging_all, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_tagging_all.csv", 
          row.names = FALSE)

```

## Preparing collection data

```{r processing collection data}

# Read in the collection data
collection_data <- read_excel("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/collectionData.xlsx", 
                              range = cell_rows(1:34))

# Select specific columns
collection_data <- collection_data %>%
  select(RIVER, recoveryDate, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, BLOOD, TYPE, COMMENTS)

# Rename columns
collection_data <- collection_data %>%
  rename(
    river = RIVER,
    date = recoveryDate,
    tagID = RADIOTAG,
    tempID = TEMPTAG,
    length = LENGTH,
    weight = WEIGHT,
    blood = BLOOD,
    type = TYPE,
    collectionNotes = COMMENTS
    )

# Fix column labels
collection_data <- collection_data %>%
  mutate(river = str_trim(river),
         date = str_trim(date),
         tagID = str_trim(tagID),
         tempID = str_trim(tempID),
         length = str_trim(length),
         weight = str_trim(weight),
         blood = str_trim(blood),
         type = str_trim(type),
         collectionNotes = str_trim(collectionNotes))

# Write new tagging data csv
write.csv(collection_data, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data/collection_data.csv", 
          row.names = FALSE)

```

## Combine collection data with fish/stream/flow/receiver/tagging data

```{r combine collection data with fish/stream/flow/receiver/tagging data}

# Read in the data
collection_data = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data/collection_data.csv")
fish_flow_receiver_stream_tagging_all = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/fish_flow_receiver_stream_tagging_all.csv")

# Convert the date column into a matching format as the other dataset
collection_data <- collection_data %>%
  mutate(date = as.Date(date))

# Convert the date column into a matching format as the other dataset
fish_flow_receiver_stream_tagging_all <- fish_flow_receiver_stream_tagging_all %>%
  mutate(date = as.Date(date))

# Combine the datasets by binding rows horizontally
tracking_data_all <- bind_rows(fish_flow_receiver_stream_tagging_all, collection_data)

tracking_data_all <- tracking_data_all %>%
  rename(radioID = tagID)

tracking_data_all <- tracking_data_all %>%
  select(date, trackedTime_EST, river, shift, radioID, tempID, power, source, fishNotes, lon, lat, habitat, habitatExtra, position, substrate, substrateExtra, shade, airTemp, cloud, precip, totalDischarge, flowTime_EST, startTime_EST, endTime_EST, streamNotes, downstreamGPS, downstreamGain, upstreamGPS, upstreamGain, isoID, isoTime_EST, length, weight, sex, type, geneticSam, blood, section, collectionNotes)

# Display the first few rows to check the result
head(tracking_data_all)

# Write new tagging data csv
write.csv(tracking_data_all, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/combined_data/tracking_data_all.csv", 
          row.names = FALSE)

```
