---
title: "Creating my Datasheet"
---

## Prep

```{r load libraries}
# Load required libraries
library(dplyr)
library(lubridate)
library(readxl)
library(leaflet)
library(tidyverse)
library(tidyr)
library(stringr)
```

## Preparing Fish Surveys

```{r add day and night shift differentiation into the fish survey 1}

# Read in the fish survey data
fish_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 1.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_1$date <- as.Date(fish_survey_1$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_1$trackedTime_EST <- as.POSIXct(paste(fish_survey_1$date, 
                                               fish_survey_1$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
fish_survey_1 <- fish_survey_1 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 4 & hour(trackedTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_1)

# Write new fish survey csv
write.csv(fish_survey_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 2}

# Read in the fish survey data
fish_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 2.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_2$date <- as.Date(fish_survey_2$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_2$trackedTime_EST <- as.POSIXct(paste(fish_survey_2$date, 
                                               fish_survey_2$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
fish_survey_2 <- fish_survey_2 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 10 & hour(trackedTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_2)

# Write new fish survey csv
write.csv(fish_survey_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 3}

# Read in the fish survey data
fish_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 3.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_3$date <- as.Date(fish_survey_3$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_3$trackedTime_EST <- as.POSIXct(paste(fish_survey_3$date, 
                                               fish_survey_3$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
fish_survey_3 <- fish_survey_3 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 4 & hour(trackedTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_3)

# Write new fish survey csv
write.csv(fish_survey_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 4}

# Read in the fish survey data
fish_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 4.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_4$date <- as.Date(fish_survey_4$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_4$trackedTime_EST <- as.POSIXct(paste(fish_survey_4$date, 
                                               fish_survey_4$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
fish_survey_4 <- fish_survey_4 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_4)

# Write new fish survey csv
write.csv(fish_survey_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 5}

# Read in the fish survey data
fish_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 5.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_5$date <- as.Date(fish_survey_5$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_5$trackedTime_EST <- as.POSIXct(paste(fish_survey_5$date, 
                                               fish_survey_5$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
fish_survey_5 <- fish_survey_5 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_5)

# Write new fish survey csv
write.csv(fish_survey_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 6}

# Read in the fish survey data
fish_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 6.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_6$date <- as.Date(fish_survey_6$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_6$trackedTime_EST <- as.POSIXct(paste(fish_survey_6$date, 
                                               fish_survey_6$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
fish_survey_6 <- fish_survey_6 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_6)

# Write new fish survey csv
write.csv(fish_survey_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 7}

# Read in the fish survey data
fish_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 7.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_7$date <- as.Date(fish_survey_7$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_7$trackedTime_EST <- as.POSIXct(paste(fish_survey_7$date, 
                                               fish_survey_7$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
fish_survey_7 <- fish_survey_7 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_7)

# Write new fish survey csv
write.csv(fish_survey_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 8}

# Read in the fish survey data
fish_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 8.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_8$date <- as.Date(fish_survey_8$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_8$trackedTime_EST <- as.POSIXct(paste(fish_survey_8$date, 
                                               fish_survey_8$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
fish_survey_8 <- fish_survey_8 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_8)

# Write new fish survey csv
write.csv(fish_survey_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 9}

# Read in the fish survey data
fish_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 9.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_9$date <- as.Date(fish_survey_9$date, 
                              format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_9$trackedTime_EST <- as.POSIXct(paste(fish_survey_9$date, 
                                               fish_survey_9$time), 
                                         format="%Y-%m-%d %H:%M",
                                         tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
# Supplementary tracking at Dry on August 5
fish_survey_9 <- fish_survey_9 %>%
  mutate(
    shift = case_when(
      # Define shift for August 5, 2024
      date(trackedTime_EST) == ymd("2024-08-05") ~ "day",
      
      # Define shift for regular tracking schedule for week 9
      date(trackedTime_EST) >= ymd("2024-08-06") & date(trackedTime_EST) <= ymd("2024-08-09") 
      & hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
      
      TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_9)

# Write new stream survey csv
write.csv(fish_survey_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 10}

# Read in the fish survey data
fish_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 10.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_10$date <- as.Date(fish_survey_10$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_10$trackedTime_EST <- as.POSIXct(paste(fish_survey_10$date, 
                                                fish_survey_10$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
fish_survey_10 <- fish_survey_10 %>%
  mutate(
    shift = case_when(
        hour(trackedTime_EST) >= 3 & hour(trackedTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(fish_survey_10)

# Write new fish survey csv
write.csv(fish_survey_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 11}

# Read in the fish survey data
fish_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 11.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_11$date <- as.Date(fish_survey_11$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_11$trackedTime_EST <- as.POSIXct(paste(fish_survey_11$date, 
                                                fish_survey_11$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
fish_survey_11 <- fish_survey_11 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(fish_survey_11)

# Write new fish survey csv
write.csv(fish_survey_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the fish survey 12}

# Read in the fish survey data
fish_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 12.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
fish_survey_12$date <- as.Date(fish_survey_12$date, 
                               format = "%m/%d/%Y")

# Combine the date and time into a DateTime column
fish_survey_12$trackedTime_EST <- as.POSIXct(paste(fish_survey_12$date, 
                                                fish_survey_12$time), 
                                          format="%Y-%m-%d %H:%M",
                                          tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
fish_survey_12 <- fish_survey_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(fish_survey_12)

# Write new fish survey csv
write.csv(fish_survey_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_12.csv", 
          row.names = FALSE)

```


```{r processing fish surveys}

# Define the path to the folder where the files are located
fish_survey_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/" 

# Define file names
fish_file_names <- paste0(fish_survey_data, c("fish_survey_1.csv", "fish_survey_2.csv", "fish_survey_3.csv", "fish_survey_4.csv", 
                     "fish_survey_5.csv", "fish_survey_6.csv", "fish_survey_7.csv", "fish_survey_8.csv", 
                     "fish_survey_9.csv", "fish_survey_10.csv", "fish_survey_11.csv", "fish_survey_12.csv"))

# Define a lookup table for stream names
stream_name_lookup <- data.frame(
  abbreviation = c("dcky", "amth", "undh", "dryu"),  # List all abbreviations
  full_name = c("DICKEY", "AMETHYST", "UNDERHILL", "DRY UPPER")  # Corresponding full names
)

# Create an empty list to store the processed datasets
processed_fish_data_list <- list()

# Loop through each fish survey file
for (file_name in fish_file_names) {
  # Read in the fish survey data
  raw_tracking_data <- read.csv(file_name)
  
  # Step 1: Process the data
  tracking_data <- raw_tracking_data %>%
    
    # Step 2: Select specific columns
    select(date, trackedTime_EST, shift, dckyID, amthID, undhID, dryuID, 
           signal, habitat, habitatExtra, position, substrate, substrateExtra, 
           shade, x, y, Notes, status, brookName) %>%
    
    # Step 3: Pivot longer to create 'river' and 'tagID' columns
    pivot_longer(
      cols = c(dckyID, amthID, undhID, dryuID),  # Columns to combine
      names_to = "river",                        # Create a new column 'river' from column names
      values_to = "radioID",                       # Combine the tag IDs into a new column 'tagID'
      values_drop_na = FALSE                     # Ensure NA values are retained
    ) %>%
    
    # Step 4: Create a new 'riverName' column and extract the river name and ID number
    mutate(
      riverName = river,                                    # Copy the river name
      #tagID = as.numeric(gsub("[^0-9]", "", tagID)),       # Extract the numeric part as tagID
      radioID = ifelse(is.na(radioID), NA, as.numeric(radioID)),  # Convert tagID to numeric, keep NA values
      river = gsub("ID", "", river)                         # Remove 'ID' to keep only the river name
    ) %>%
    
    # Step 5: Join with the lookup table to replace abbreviations with full names
    left_join(stream_name_lookup, by = c("river" = "abbreviation")) %>%
    mutate(
      river = coalesce(full_name, river)  # Replace Brook with full_name, if available
    ) %>%
    select(-full_name) %>%  # Remove the full_name column as it's no longer needed
    
    # Step 6: Combine the river and brookName logic
    mutate(
      river = ifelse(brookName %in% c("BUFFAM", "HARRIS"), brookName, river)  # Override river with brookName if Buffam or Harris
    ) %>%
    
    # Step 7: Rename columns
    rename(
      fishNotes = Notes,
      lon = x,
      lat = y,
      power = signal
    ) %>%
    
    ##############################################################
    
    # Step 8: Filter data to keep only rows where lat > 1
    filter(lat > 1, !is.na(radioID)) %>%
    
    # Step _: Filter data to keep rows with lat > 1 or lat is NA
    #filter(lat > 1 | is.na(lat)) %>%
    
    #############################################################
    
    # Step 9: Select specific columns
    select(date, trackedTime_EST, river, shift, radioID, power, status, habitat, habitatExtra, position, substrate, substrateExtra, shade, lon, lat, fishNotes) %>%
    
    #############################################################
    
    # Step 10: Add a source column
    mutate(source = "iPad")
  
  # Store the processed data in the list
  processed_fish_data_list[[file_name]] <- tracking_data
  
  # Overwrite the original file with the processed data
  write.csv(tracking_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_fish_data_list)) {
  cat("\nData for", fish_file_names[i], ":\n")
  print(head(processed_fish_data_list[[i]]))
}

```



## Making Flow Tracker File Datasets by Week

```{r combine flow tracker files for week 1}

# Define a function to search for files
find_files <- function(week_1_directory) {
  week_1_files <- list.files(path = week_1_directory, recursive = TRUE, full.names = TRUE)
  return(week_1_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  # Rename columns
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_1_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week1"

# Find all files in the week 1 directory
week_1_files <- find_files(week_1_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_1 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_1_files) {
  file_data <- extract_values(file)
  flow_tracker_1 <- bind_rows(flow_tracker_1, file_data)
}

# Standardize site names
flow_tracker_1 <- flow_tracker_1 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_1 <- flow_tracker_1 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_1)

# Write the final CSV file
write.csv(flow_tracker_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_1.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 2}

# Define a function to search for files
find_files <- function(week_2_directory) {
  week_2_files <- list.files(path = week_2_directory, recursive = TRUE, full.names = TRUE)
  return(week_2_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_2_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week2"

# Find all files in the week 2 directory
week_2_files <- find_files(week_2_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_2 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_2_files) {
  file_data <- extract_values(file)
  flow_tracker_2 <- bind_rows(flow_tracker_2, file_data)
}

# Standardize site names
flow_tracker_2 <- flow_tracker_2 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_2 <- flow_tracker_2 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_2)

# Write the final CSV file
write.csv(flow_tracker_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_2.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 3}

# Define a function to search for files
find_files <- function(week_3_directory) {
  week_3_files <- list.files(path = week_3_directory, recursive = TRUE, full.names = TRUE)
  return(week_3_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_3_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week3"

# Find all files in the week 3 directory
week_3_files <- find_files(week_3_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_3 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_3_files) {
  file_data <- extract_values(file)
  flow_tracker_3 <- bind_rows(flow_tracker_3, file_data)
}

# Standardize site names
flow_tracker_3 <- flow_tracker_3 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_3 <- flow_tracker_3 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_3)

# Write the final CSV file
write.csv(flow_tracker_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_3.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 4}

# Define a function to search for files
find_files <- function(week_4_directory) {
  week_4_files <- list.files(path = week_4_directory, recursive = TRUE, full.names = TRUE)
  return(week_4_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_4_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week4"

# Find all files in the week 4 directory
week_4_files <- find_files(week_4_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_4 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_4_files) {
  file_data <- extract_values(file)
  flow_tracker_4 <- bind_rows(flow_tracker_4, file_data)
}

# Standardize site names
flow_tracker_4 <- flow_tracker_4 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_4 <- flow_tracker_4 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_4)

# Write the final CSV file
write.csv(flow_tracker_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_4.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 5}

# Define a function to search for files
find_files <- function(week_5_directory) {
  week_5_files <- list.files(path = week_5_directory, recursive = TRUE, full.names = TRUE)
  return(week_5_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_5_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week5"

# Find all files in the week 5 directory
week_5_files <- find_files(week_5_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_5 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_5_files) {
  file_data <- extract_values(file)
  flow_tracker_5 <- bind_rows(flow_tracker_5, file_data)
}

# Standardize site names
flow_tracker_5 <- flow_tracker_5 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_5 <- flow_tracker_5 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_5)

# Write the final CSV file
write.csv(flow_tracker_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_5.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 6}

# Define a function to search for files
find_files <- function(week_6_directory) {
  week_6_files <- list.files(path = week_6_directory, recursive = TRUE, full.names = TRUE)
  return(week_6_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_6_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week6"

# Find all files in the week 6 directory
week_6_files <- find_files(week_6_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_6 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_6_files) {
  file_data <- extract_values(file)
  flow_tracker_6 <- bind_rows(flow_tracker_6, file_data)
}

# Standardize site names
flow_tracker_6 <- flow_tracker_6 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_6 <- flow_tracker_6 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_6)

# Write the final CSV file
write.csv(flow_tracker_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_6.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 7}

# Define a function to search for files
find_files <- function(week_7_directory) {
  week_7_files <- list.files(path = week_7_directory, recursive = TRUE, full.names = TRUE)
  return(week_7_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_7_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week7"

# Find all files in the week 7 directory
week_7_files <- find_files(week_7_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_7 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_7_files) {
  file_data <- extract_values(file)
  flow_tracker_7 <- bind_rows(flow_tracker_7, file_data)
}

# Standardize site names
flow_tracker_7 <- flow_tracker_7 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_7 <- flow_tracker_7 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_7)

# Write the final CSV file
write.csv(flow_tracker_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_7.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 8}

# Define a function to search for files
find_files <- function(week_8_directory) {
  week_8_files <- list.files(path = week_8_directory, recursive = TRUE, full.names = TRUE)
  return(week_8_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_8_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week8"

# Find all files in the week 8 directory
week_8_files <- find_files(week_8_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_8 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_8_files) {
  file_data <- extract_values(file)
  flow_tracker_8 <- bind_rows(flow_tracker_8, file_data)
}

# Standardize site names
flow_tracker_8 <- flow_tracker_8 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_8 <- flow_tracker_8 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_8)

# Write the final CSV file
write.csv(flow_tracker_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_8.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 9}

# Define a function to search for files
find_files <- function(week_9_directory) {
  week_9_files <- list.files(path = week_9_directory, recursive = TRUE, full.names = TRUE)
  return(week_9_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_9_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week9"

# Find all files in the week 9 directory
week_9_files <- find_files(week_9_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_9 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_9_files) {
  file_data <- extract_values(file)
  flow_tracker_9 <- bind_rows(flow_tracker_9, file_data)
}

# Standardize site names
flow_tracker_9 <- flow_tracker_9 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_9 <- flow_tracker_9 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_9)

# Write the final CSV file
write.csv(flow_tracker_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_9.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 10}

# Define a function to search for files
find_files <- function(week_10_directory) {
  week_10_files <- list.files(path = week_10_directory, recursive = TRUE, full.names = TRUE)
  return(week_10_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_10_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week10"

# Find all files in the week 10 directory
week_10_files <- find_files(week_10_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_10 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_10_files) {
  file_data <- extract_values(file)
  flow_tracker_10 <- bind_rows(flow_tracker_10, file_data)
}

# Standardize site names
flow_tracker_10 <- flow_tracker_10 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_10 <- flow_tracker_10 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_10)

# Write the final CSV file
write.csv(flow_tracker_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_10.csv", 
          row.names = FALSE)

```

```{r combine flow tracker files for week 11}

# Define a function to search for files
find_files <- function(week_11_directory) {
  week_11_files <- list.files(path = week_11_directory, recursive = TRUE, full.names = TRUE)
  return(week_11_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_11_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week11"

# Find all files in the week 11 directory
week_11_files <- find_files(week_11_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_11 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_11_files) {
  file_data <- extract_values(file)
  flow_tracker_11 <- bind_rows(flow_tracker_11, file_data)
}

# Standardize site names
flow_tracker_11 <- flow_tracker_11 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_11 <- flow_tracker_11 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_11)

# Write the final CSV file
write.csv(flow_tracker_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_11.csv",
          row.names = FALSE)

```

```{r combine flow tracker files for week 12}

# Define a function to search for files
find_files <- function(week_12_directory) {
  week_12_files <- list.files(path = week_12_directory, recursive = TRUE, full.names = TRUE)
  return(week_12_files)
}

# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius
extract_values <- function(file_path) {
  
  # Read the csv file
  df <- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(df) <- c("Column1", "Column2", "Column3")
  
  # Extract values
  local_end_time <- df %>% filter(Column1 == "Local_End_Time") %>% select(Column3) %>% pull()
  site_name <- df %>% filter(Column1 == "Site_Name") %>% select(Column3) %>% pull()
  total_discharge <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column3) %>% pull()
  discharge_unit <- df %>% filter(Column1 == "Total_Discharge") %>% select(Column2) %>% pull()
  
  # Convert to cubic feet per second only if the unit is cubic meters per second
  if (discharge_unit == "m³/s") {
    total_discharge <- as.numeric(total_discharge) * 35.3147
  } else {
    total_discharge <- as.numeric(total_discharge)
  }
  
  # Round values to 2 decimal places
  total_discharge <- round(as.numeric(total_discharge), 2)
  
  data.frame(
    localEndTime = local_end_time,
    river = site_name,
    ftDischarge_cfs = as.numeric(total_discharge),  # Ensure numeric type
    stringsAsFactors = FALSE
  )
}

week_12_directory <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week12"

# Find all files in the week 12 directory
week_12_files <- find_files(week_12_directory)

# Initialize the result dataframe with the correct data types
flow_tracker_12 <- data.frame(
  localEndTime = character(),
  river = character(),
  ftDischarge_cfs = numeric(),  # Initialize as numeric
  stringsAsFactors = FALSE
)

# Loop through all files and extract values
for (file in week_12_files) {
  file_data <- extract_values(file)
  flow_tracker_12 <- bind_rows(flow_tracker_12, file_data)
}

# Standardize site names
flow_tracker_12 <- flow_tracker_12 %>%
  mutate(river = ifelse(grepl("buff", river, ignore.case = TRUE), "BUFFAM", river)) %>%
  mutate(river = ifelse(grepl("dryu", river, ignore.case = TRUE), "DRY UPPER", river)) %>%
  mutate(river = ifelse(grepl("harr", river, ignore.case = TRUE), "HARRIS", river)) %>%
  mutate(river = ifelse(grepl("undh", river, ignore.case = TRUE), "UNDERHILL", river)) %>%
  mutate(river = ifelse(grepl("dcky", river, ignore.case = TRUE), "DICKEY", river))

#####################################################################################

# Remove rows with repeating Total_Discharge values
flow_tracker_12 <- flow_tracker_12 %>% 
  distinct(localEndTime, .keep_all = TRUE)

#####################################################################################

# Display the first few rows to check the result
head(flow_tracker_12)

# Write the final CSV file
write.csv(flow_tracker_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_12.csv", 
          row.names = FALSE)

```

## Preparing Flow Tracker Files

```{r add day and night shift differentiation into the flow week 1}

# Read in the flow data
flow_tracker_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_1.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_1$ftTime_EDT <- as.POSIXct(flow_tracker_1$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "America/New_York")

# Force the DateTime column from EDT to EST
flow_tracker_1$ftTime_EST <- as.POSIXct(format(flow_tracker_1$ftTime_EDT, 
                                                  tz = "EST", 
                                                  usetz = TRUE), 
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
flow_tracker_1 <- flow_tracker_1 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 4 & hour(ftTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_1 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_1 <- bind_rows(flow_tracker_1, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_1)

# Write new flow csv
write.csv(flow_tracker_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 2}

# Read in the flow data
flow_tracker_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_2.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_2$ftTime_EST <- as.POSIXct(flow_tracker_2$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
flow_tracker_2 <- flow_tracker_2 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 10 & hour(ftTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_2 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_2 <- bind_rows(flow_tracker_2, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_2)

# Write new flow csv
write.csv(flow_tracker_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 3}

# Read in the flow data
flow_tracker_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_3.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_3$ftTime_EST <- as.POSIXct(flow_tracker_3$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
flow_tracker_3 <- flow_tracker_3 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 4 & hour(ftTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_3 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_3 <- bind_rows(flow_tracker_3, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_3)

# Write new flow csv
write.csv(flow_tracker_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 4}

# Read in the flow data
flow_tracker_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_4.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_4$ftTime_EST <- as.POSIXct(flow_tracker_4$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
flow_tracker_4 <- flow_tracker_4 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 2 & hour(ftTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_4 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_4 <- bind_rows(flow_tracker_4, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_4)

# Write new flow csv
write.csv(flow_tracker_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 5}

# Read in the flow data
flow_tracker_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_5.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_5$ftTime_EST <- as.POSIXct(flow_tracker_5$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_5 <- flow_tracker_5 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 6 & hour(ftTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_5 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_5 <- bind_rows(flow_tracker_5, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_5)

# Write new flow csv
write.csv(flow_tracker_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 6}

# Read in the flow data
flow_tracker_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_6.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_6$ftTime_EST <- as.POSIXct(flow_tracker_6$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
flow_tracker_6 <- flow_tracker_6 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 2 & hour(ftTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_6 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_6 <- bind_rows(flow_tracker_6, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_6)

# Write new flow csv
write.csv(flow_tracker_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 7}

# Read in the flow data
flow_tracker_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_7.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_7$ftTime_EST <- as.POSIXct(flow_tracker_7$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_7 <- flow_tracker_7 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 6 & hour(ftTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_7 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_7 <- bind_rows(flow_tracker_7, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_7)

# Write new flow csv
write.csv(flow_tracker_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 8}

# Read in the flow data
flow_tracker_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_8.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_8$ftTime_EST <- as.POSIXct(flow_tracker_8$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
flow_tracker_8 <- flow_tracker_8 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 2 & hour(ftTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_8 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_8 <- bind_rows(flow_tracker_8, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_8)

# Write new flow csv
write.csv(flow_tracker_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 9}

# Read in the flow data
flow_tracker_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_9.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_9$ftTime_EST <- as.POSIXct(flow_tracker_9$localEndTime, 
                                          format = "%Y-%m-%d %H:%M:%S",
                                          tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
flow_tracker_9 <- flow_tracker_9 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 6 & hour(ftTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_9 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_9 <- bind_rows(flow_tracker_9, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_9)

# Write new flow csv
write.csv(flow_tracker_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 10}

# Read in the flow data
flow_tracker_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_10.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_10$ftTime_EST <- as.POSIXct(flow_tracker_10$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
flow_tracker_10 <- flow_tracker_10 %>%
  mutate(
    shift = case_when(
        hour(ftTime_EST) >= 3 & hour(ftTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_10 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_10 <- bind_rows(flow_tracker_10, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_10)

# Write new flow csv
write.csv(flow_tracker_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 11}

# Read in the flow data
flow_tracker_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_11.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_11$ftTime_EST <- as.POSIXct(flow_tracker_11$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
flow_tracker_11 <- flow_tracker_11 %>%
  mutate(shift = "day")

# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift
amethyst_combined <- flow_tracker_11 %>%
  filter(river %in% c("BUFFAM", "HARRIS")) %>%   # Filter BUFFAM and HARRIS
  group_by(shift) %>%                            # Group by shift (day/night)
  summarise(
    river = "AMETHYST",                          # Set river to AMETHYST
    ftDischarge_cfs = sum(ftDischarge_cfs, na.rm = TRUE) # Sum ftDischarge_cfs
  )

# Bind the AMETHYST rows to the original dataset
flow_tracker_11 <- bind_rows(flow_tracker_11, amethyst_combined)

# Display the first few rows to check the result
head(flow_tracker_11)

# Write new flow csv
write.csv(flow_tracker_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the flow week 12}

# Read in the flow data
flow_tracker_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_12.csv")

# Convert the localEndTime column into a DateTime column
flow_tracker_12$ftTime_EST <- as.POSIXct(flow_tracker_12$localEndTime, 
                                           format = "%Y-%m-%d %H:%M:%S",
                                           tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
flow_tracker_12 <- flow_tracker_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(flow_tracker_12)

# Write new flow csv
write.csv(flow_tracker_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_12.csv", 
          row.names = FALSE)

```

```{r processing flow files}

# Define the path to the folder where the files are located
flow_tracker_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/" 

# Define file names
flow_file_names <- paste0(flow_tracker_data, c("flow_tracker_1.csv", "flow_tracker_2.csv", "flow_tracker_3.csv", "flow_tracker_4.csv", 
                     "flow_tracker_5.csv", "flow_tracker_6.csv", "flow_tracker_7.csv", "flow_tracker_8.csv", 
                     "flow_tracker_9.csv", "flow_tracker_10.csv", "flow_tracker_11.csv", "flow_tracker_12.csv")) 

# Create an empty list to store the processed datasets
processed_flow_data_list <- list()

# Loop through each flow file
for (file_name in flow_file_names) {
  # Read in the flow data
  raw_flow_data <- read.csv(file_name)
  
  # Process the data
  flow_data <- raw_flow_data %>%
    
    # Loop through each dataset and apply the transformations
    group_by(shift, river) %>%
    mutate(row_count = n()) %>%  # Count rows per group
    summarize(
      ftDischarge_cfs = round(mean(ftDischarge_cfs, na.rm = TRUE), 2),
      ftTime_EST = ifelse(first(row_count) > 1, NA, first(ftTime_EST)),  # Keep time if only 1 row
      .groups = "drop"
    ) %>%
    
    # Select specific columns
    select(river, ftDischarge_cfs, ftTime_EST, shift) 
    
    
  
  # Store the processed data in the list
  processed_flow_data_list[[file_name]] <- flow_data
  
  # Overwrite the original file with the processed data
  write.csv(flow_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_flow_data_list)) {
  cat("\nData for", flow_file_names[i], ":\n")
  print(head(processed_flow_data_list[[i]]))
}

```


## Combine fish survey and flow data

```{r combine fish survey and flow week 1 data}

# Read in the fish survey and flow data for week 1
fish_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_1.csv")
flow_tracker_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_1.csv")

# Combine the datasets by shift and river columns
fish_flow_1 <- left_join(fish_survey_1, flow_tracker_1, 
                                by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_1.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 2 data}

# Read in the fish survey and flow data for week 2
fish_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_2.csv")
flow_tracker_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_2.csv")

# Combine the datasets by shift and river columns
fish_flow_2 <- left_join(fish_survey_2, flow_tracker_2, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_2.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 3 data}

# Read in the fish survey and flow data for week 3
fish_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_3.csv")
flow_tracker_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_3.csv")

# Combine the datasets by shift and river columns
fish_flow_3 <- left_join(fish_survey_3, flow_tracker_3, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_3.csv", 
          row.names = FALSE)

```
```{r combine fish survey and flow week 4 data}

# Read in the fish survey and flow data for week 4
fish_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_4.csv")
flow_tracker_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_4.csv")

# Combine the datasets by shift and river columns
fish_flow_4 <- left_join(fish_survey_4, flow_tracker_4, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_4.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 5 data}

# Read in the fish survey and flow data for week 5
fish_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_5.csv")
flow_tracker_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_5.csv")

# Combine the datasets by shift and river columns
fish_flow_5 <- left_join(fish_survey_5, flow_tracker_5, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_5.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 6 data}

# Read in the fish survey and flow data for week 6
fish_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_6.csv")
flow_tracker_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_6.csv")

# Combine the datasets by shift and river columns
fish_flow_6 <- left_join(fish_survey_6, flow_tracker_6, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_6.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 7 data}

# Read in the fish survey and flow data for week 7
fish_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_7.csv")
flow_tracker_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_7.csv")

# Combine the datasets by shift and river columns
fish_flow_7 <- left_join(fish_survey_7, flow_tracker_7, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_7.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 8 data}

# Read in the fish survey and flow data for week 8
fish_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_8.csv")
flow_tracker_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_8.csv")

# Combine the datasets by shift and river columns
fish_flow_8 <- left_join(fish_survey_8, flow_tracker_8, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_8.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 9 data}

# Read in the fish survey and flow data for week 9
fish_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_9.csv")
flow_tracker_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_9.csv")

# Combine the datasets by shift and river columns
fish_flow_9 <- left_join(fish_survey_9, flow_tracker_9, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_9.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 10 data}

# Read in the fish survey and flow data for week 10
fish_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_10.csv")
flow_tracker_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_10.csv")

# Combine the datasets by shift and river columns
fish_flow_10 <- left_join(fish_survey_10, flow_tracker_10, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_10.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 11 data}

# Read in the fish survey and flow data for week 11
fish_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_11.csv")
flow_tracker_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_11.csv")

# Combine the datasets by shift and river columns
fish_flow_11 <- left_join(fish_survey_11, flow_tracker_11, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_11.csv", 
          row.names = FALSE)

```

```{r combine fish survey and flow week 12 data}

# Read in the fish survey and flow data for week 12
fish_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/fish_survey_data/fish_survey_12.csv")
flow_tracker_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/flow_tracker_data/flow_tracker_12.csv")

# Combine the datasets by shift and river columns
fish_flow_12 <- left_join(fish_survey_12, flow_tracker_12, by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_12.csv", 
          row.names = FALSE)

```


## Preparing lotek data files for analysis

### Lotek receiver 000900 data

```{r processing the lotek receiver 000900 ID only data}

# ID Only Data ###########################################################

# Read the dataset
receiver_000900_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000900_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID Only Records:" and create a flag
receiver_000900_ID_data <- receiver_000900_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID Only Records:", 1, 0)) 

# Detect the start of row that says "ID + GPS Positions:"
id_gps_row <- which(receiver_000900_raw_data$columnOne == "ID + GPS Positions:")

# If "ID + GPS Positions:" is found, slice until the row before it
if(length(id_gps_row) > 0) {
  id_gps_row <- id_gps_row[1] - 1  # One row before "ID + GPS Positions:"
} else {
  id_gps_row <- nrow(receiver_000900_raw_data)  # If "ID + GPS Positions:" not found, slice till the bottom
}

# Slice out the ID data by detecting the start and extracting relevant rows
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  slice((which(grepl(1, receiver_000900_ID_data$column2)) + 2) : id_gps_row)

receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , 
           c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", 
           sep = "\\s+")
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "Power") 

# Combine the date and time into a DateTime column
receiver_000900_ID_data$trackedTime_EST <- as.POSIXct(paste(receiver_000900_ID_data$Date, 
                                                         receiver_000900_ID_data$Time), 
                                                   format="%m/%d/%y %H:%M:%S",
                                                   tz = "EST")
  
#receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Combine Date and Time columns into a single datetime in mdy_hms format
  #mutate(dateTime = mdy_hms(paste(Date, Time))) 
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Rename "Tag ID' column as "radioID"
  rename_with(~ "radioID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) %>%
  
  # Rename "Power' column as "power"
  rename_with(~ "power", .cols = `Power`)
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for further processing
  select("date", "radioID", "power", "trackedTime_EST") 

receiver_000900_ID_data <- receiver_000900_ID_data %>%
  # Clean and format the data
  mutate(radioID = as.numeric(radioID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Filter by tagID range
  filter(radioID > 10 & radioID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))


# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  radioID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", 
                     "2024-07-18", "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", 
                   "2024-08-29", "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(radioID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(radioID_range, ~ radioID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000900_ID_data$date <- ymd(receiver_000900_ID_data$date)

# Apply the function to the data frame
receiver_000900_ID_data <- receiver_000900_ID_data %>%
  mutate(river = mapply(assign_river, radioID, date))

# Remove rows where river is "Unknown"
receiver_000900_ID_data <- receiver_000900_ID_data %>%
  filter(river != "Unknown")

receiver_000900_ID_data <- receiver_000900_ID_data %>% 
  # Select the columns for the final dataframe
  select("radioID", "power", "trackedTime_EST", "river", "date") 

# View dataframe
head(receiver_000900_ID_data)

```

```{r processing the lotek receiver 000900 ID + GPS data}

# ID + GPS Data ###########################################################

# Read the dataset
receiver_000900_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000900_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID + GPS Positions:" and create a flag
receiver_000900_GPS_data <- receiver_000900_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID + GPS Positions:", 1, 0)) 

# Detect the start of row that says "End of Data" 
end_of_data_row <- which(receiver_000900_raw_data$columnOne == "End of Data")

# If "End of Data" is found, slice until the row before it
if(length(end_of_data_row) > 0) {
  end_of_data_row <- end_of_data_row[1] - 1  # One row before "End of data"
} else {
  end_of_data_row <- nrow(receiver_000900_raw_data)  # If "End of data" not found, slice till the bottom
}

# Slice out the GPS data by detecting the start and extracting relevant rows
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  slice((which(grepl(1, receiver_000900_GPS_data$column2)) + 2) : end_of_data_row)

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", sep = "\\s+")

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Separate the "Power" column into power, latitude, and longitude
  separate(Power, c("power", "lat", "lon"), sep = "\\s+") 
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "power", "lon", "lat") 
  
# Combine the date and time into a DateTime column
receiver_000900_GPS_data$trackedTime_EST <- as.POSIXct(paste(receiver_000900_GPS_data$Date, 
                                                          receiver_000900_GPS_data$Time), 
                                                    format="%m/%d/%y %H:%M:%S",
                                                    tz = "EST")
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Rename "Tag ID' column as "radioID"
  rename_with(~ "radioID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) 
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for further processing
  select("date", "radioID", "power","lon", "lat", "trackedTime_EST") 

receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  # Clean and format the data
  mutate(lat = as.numeric(lat), 
         radioID = as.numeric(radioID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Filter by tagID range
  filter(radioID > 10 & radioID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))

# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  radioID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", "2024-07-18", 
                         "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", "2024-08-29", 
                       "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(radioID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(radioID_range, ~ radioID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000900_GPS_data$date <- ymd(receiver_000900_GPS_data$date)

# Apply the function to the data frame
receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  mutate(river = mapply(assign_river, radioID, date))

# Remove rows where river is "Unknown"
receiver_000900_GPS_data <- receiver_000900_GPS_data %>%
  filter(river != "Unknown")

receiver_000900_GPS_data <- receiver_000900_GPS_data %>% 
  # Select the columns for the final dataframe
  select("radioID", "power","lon", "lat", "trackedTime_EST", "river", "date")

# View dataframe
head(receiver_000900_GPS_data)

```


```{r combining the lotek receiver 000900 data back into one dataframe}

# Combine the two final dataframes horizontally 
receiver_000900_data <- bind_rows(receiver_000900_ID_data, receiver_000900_GPS_data)

# Clean workspace by removing excess variables
rm(river_date_ranges, receiver_000900_raw_data, receiver_000900_ID_data, receiver_000900_GPS_data)

# View dataframe
head(receiver_000900_data)

```

### Lotek receiver 000517 data
No ID+GPS data on this receiver - No combination needed

```{r processing the lotek receiver 000517 ID only data}

# ID Only Data ###########################################################

# Read the dataset
receiver_000517_raw_data <- read.delim("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000517/20240912/000517_20240912.txt")

# Rename the single column in the dataset as "columnOne"
names(receiver_000517_raw_data) <- c("columnOne")

# Detect the start of the row that says "ID Only Records:" and create a flag
receiver_000517_ID_data <- receiver_000517_raw_data %>% 
  mutate(column2 = ifelse(columnOne == "ID Only Records:", 1, 0)) 

# Detect the start of row that says "End of Data" 
end_of_data_row <- which(receiver_000517_raw_data$columnOne == "End of Data")

# If "End of Data" is found, slice until the row before it
if(length(end_of_data_row) > 0) {
  end_of_data_row <- end_of_data_row[1] - 1  # One row before "End of data"
} else {
  end_of_data_row <- nrow(receiver_000517_raw_data)  # If "End of data" not found, slice till the bottom
}

# Slice out the data by detecting the start and extracting relevant rows
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  slice((which(grepl(1, receiver_000517_ID_data$column2)) + 2) : end_of_data_row)

receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Split the initial columns based on space separation
  separate(columnOne , c("Date", "Time", "Channel", "Tag ID", "Antenna", "Power"), 
           extra = "merge", sep = "\\s+")
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for further processing
  select("Date", "Time", "Tag ID", "Power") 
  
# Combine the date and time into a DateTime column
receiver_000517_ID_data$trackedTime_EST <- as.POSIXct(paste(receiver_000517_ID_data$Date, 
                                                         receiver_000517_ID_data$Time), 
                                                   format="%m/%d/%y %H:%M:%S",
                                                   tz = "EST") 
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Rename "Tag ID' column as "radioID"
  rename_with(~ "radioID", .cols = `Tag ID`) %>%
  
  # Rename "Date' column as "date"
  rename_with(~ "date", .cols = `Date`) %>%
  
  # Rename "Power' column as "power"
  rename_with(~ "power", .cols = `Power`)
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for further processing
  select("date", "radioID", "power", "trackedTime_EST") 

receiver_000517_ID_data <- receiver_000517_ID_data %>%
  # Clean and format the data
  mutate(radioID = as.numeric(radioID),
         power = as.numeric(power),
         date = mdy(date),
         source = "lotek")

# Define the date range
start_date <- ymd("2024-06-11")  
end_date <- ymd("2024-08-29")   

# Define specific days to filter out based on the non-tracking days on the calendar
days_to_exclude <- ymd(c("2024-06-21", "2024-06-24", "2024-07-04", "2024-07-05", 
                         "2024-07-08", "2024-07-15", "2024-07-22", "2024-07-29", 
                         "2024-08-12","2024-08-19", "2024-08-28"))
  
receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Filter by tagID range
  filter(radioID > 10 & radioID < 63) %>%
  
  # Filter by the date range
  filter(date >= start_date & date <= end_date) %>%
  
  # Filter out the specified days
  filter(!(date %in% days_to_exclude))

# Define the date ranges for different rivers to account for retagging
river_date_ranges <- tibble(
  river = c("AMETHYST", "UNDERHILL", "DICKEY", "DICKEY", 
            "DRY UPPER", "DRY UPPER"),
  radioID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, 
                       13, 57, 19, 62, 11, 58, 18), 
                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), 
                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),
                     c(50, 37, 38, 26, 28, 51, 32, 31),
                     c(42, 49, 55, 16, 52, 21, 47, 24, 
                       48, 22, 17, 25, 54, 23, 53),
                     c(29, 30, 46, 39)),
  start_date = ymd(c("2024-06-11", "2024-06-11", "2024-06-11", "2024-07-18", 
                         "2024-06-11", "2024-07-18")),
  end_date = ymd(c("2024-08-29", "2024-08-29", "2024-07-17", "2024-08-29", 
                       "2024-08-29", "2024-08-29"))
)

# Function to determine river based on tagID and date
assign_river <- function(radioID, date) {
  # Filter the river_date_ranges for matching tagID and date range
  river_info <- river_date_ranges %>%
    filter(map_lgl(radioID_range, ~ radioID %in% .) & date >= start_date & date <= end_date)
  
  if (nrow(river_info) > 0) {
    return(river_info$river[1])  # Return the matching river
  } else {
    return("Unknown")  # Default for no match
  }
}

# Ensure the 'date' column is in Date format
receiver_000517_ID_data$date <- ymd(receiver_000517_ID_data$date)

# Apply the function to the data frame
receiver_000517_ID_data <- receiver_000517_ID_data %>%
  mutate(river = mapply(assign_river, radioID, date))

# Remove rows where river is "Unknown"
receiver_000517_ID_data <- receiver_000517_ID_data %>%
  filter(river != "Unknown")

receiver_000517_ID_data <- receiver_000517_ID_data %>% 
  # Select the columns for the final dataframe
  select("radioID", "power", "trackedTime_EST", "river", "date") 

# Clean workspace by removing excess variables
rm(receiver_000517_raw_data, river_date_ranges)

# View dataframe
head(receiver_000517_ID_data)

```
### Combine all data from all receivers

```{r combine data from multiple receivers}

# Combine multiple receivers into one dataframe ########################################

# Combine the two final dataframes horizontally
receiver_data_all <- bind_rows(receiver_000900_data, receiver_000517_ID_data)

# Clean workspace by removing excess variables
rm(receiver_000900_data, receiver_000517_ID_data)

# View dataframe
head(receiver_data_all)

```

### Clean the radio tag ID receiver data to account for retagging

```{r clean the tag ID data}

# Specify the cutoff date
cutoff_date <- ymd("2024-07-18")  

receiver_data_all <- receiver_data_all %>%
  mutate(
    radioID = case_when(
      radioID == 30 & date >= cutoff_date ~ 30.1,
      radioID == 39 & date >= cutoff_date ~ 39.1,
      radioID == 46 & date >= cutoff_date ~ 46.1,
      radioID == 29 & date >= cutoff_date ~ 29.1,
      TRUE ~ as.numeric(radioID)  # Keep the original radioID for other cases
    )
  )

# Check if the tagID values were updated correctly
print(receiver_data_all %>% filter(date >= cutoff_date))

```

### Add day and night shift differentiation into receiver data

```{r add day and night shift differentiation into the receiver data}

receiver_data_all <- receiver_data_all %>%
  mutate(
    shift = case_when(
      # Define shift for week 1
      date(trackedTime_EST) >= ymd("2024-06-11") & 
        date(trackedTime_EST) <= ymd("2024-06-14") &
        hour(trackedTime_EST) >= 4 & hour(trackedTime_EST) < 12 ~ "day",
      
      # Define shift for week 2
      date(trackedTime_EST) >= ymd("2024-06-17") & 
        date(trackedTime_EST) <= ymd("2024-06-20") &
      hour(trackedTime_EST) >= 10 & hour(trackedTime_EST) < 18 ~ "day",
      
      # Define shift for week 3
      date(trackedTime_EST) >= ymd("2024-06-25") & 
        date(trackedTime_EST) <= ymd("2024-06-28") &
      hour(trackedTime_EST) >= 4 & hour(trackedTime_EST) < 12 ~ "day",
      
      # Define shift for week 4
      date(trackedTime_EST) >= ymd("2024-06-30") & 
        date(trackedTime_EST) <= ymd("2024-07-03") &
      hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 10 ~ "day",
      
      # Define shift for week 5
      date(trackedTime_EST) >= ymd("2024-07-09") & 
        date(trackedTime_EST) <= ymd("2024-07-12") &
      hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
      
      # Define shift for week 6
      date(trackedTime_EST) >= ymd("2024-07-16") & 
        date(trackedTime_EST) <= ymd("2024-07-19") &
      hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 10 ~ "day",
      
      # Define shift for week 7
      date(trackedTime_EST) >= ymd("2024-07-23") & 
        date(trackedTime_EST) <= ymd("2024-07-26") &
      hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
      
      # Define shift for week 8
      date(trackedTime_EST) >= ymd("2024-07-30") & 
        date(trackedTime_EST) <= ymd("2024-08-02") &
      hour(trackedTime_EST) >= 2 & hour(trackedTime_EST) < 11 ~ "day",
      
      # Define shift for supplementary tracking on August 5, 2024
      date(trackedTime_EST) == ymd("2024-08-05") ~ "day",
      
      # Define shift for week 9
      date(trackedTime_EST) >= ymd("2024-08-06") & 
        date(trackedTime_EST) <= ymd("2024-08-09") &
      hour(trackedTime_EST) >= 6 & hour(trackedTime_EST) < 14 ~ "day",
      
      # Define shift for week 10
      date(trackedTime_EST) >= ymd("2024-08-13") & 
        date(trackedTime_EST) <= ymd("2024-08-16") &
      hour(trackedTime_EST) >= 3 & hour(trackedTime_EST) < 11 ~ "day",
      
      # Define shift for week 11
      date(trackedTime_EST) >= ymd("2024-08-20") & 
        date(trackedTime_EST) <= ymd("2024-08-23") ~ "day",
      
      # Define shift for week 12
      date(trackedTime_EST) >= ymd("2024-08-26") & 
        date(trackedTime_EST) <= ymd("2024-08-29") ~ "day",
      
      # Default to night shift for all other times
      TRUE ~ "night"
    )
  )

receiver_data_all <- receiver_data_all %>%
  # Add source column
  mutate(source = "receiver")

receiver_data_all <- receiver_data_all %>% 
  # Select the columns for the final dataframe
  select("date", "trackedTime_EST", "river", "shift", "radioID", "power", "lon", "lat", "source")

head(receiver_data_all)

# Write the dataframe into a csv
write.csv(receiver_data_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_all.csv", 
          row.names = FALSE)

```

```{r split receiver data into weekly CSV files}

# Step 1: Define specific date ranges for each week
week_ranges <- data.frame(
  week_name = c("week_1", "week_2", "week_3", "week_4", "week_5", "week_6", "week_7", "week_8", "week_9", "week_10", "week_11", "week_12"),  
  start_date = ymd(c("2024-06-11", "2024-06-17", "2024-06-25", "2024-06-30", "2024-07-09", "2024-07-16", "2024-07-23", "2024-07-30", "2024-08-05", "2024-08-13", "2024-08-20", "2024-08-26")),
  end_date = ymd(c("2024-06-14", "2024-06-20", "2024-06-28", "2024-07-03", "2024-07-12", "2024-07-19", "2024-07-26", "2024-08-02", "2024-08-09", "2024-08-16", "2024-08-23", "2024-08-29"))
)

# Initialize a counter for naming datasets
counter <- 1

# Step 2: Loop through each date range and filter the dataset
for (i in 1:nrow(week_ranges)) {
  # Filter the dataset for each specified date range
  weekly_receiver_data <- receiver_data_all %>%
    filter(date >= week_ranges$start_date[i] & date <= week_ranges$end_date[i])
  
  # Dynamically name each week's data (e.g., receiver_data_1, receiver_data_2, ...)
  assign(paste0("receiver_data_", counter), weekly_receiver_data)
  
  # Save the dataset to a CSV file
  receiver_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/"
  file_name <- paste0(receiver_data, "receiver_data_", counter, ".csv")
  write.csv(weekly_receiver_data, file = file_name, row.names = FALSE)
  
  # Display the first few rows of the created datasets
  cat("\nData for", file_name, ":\n")
  print(head(weekly_receiver_data))  # Print the first few rows of each weekly dataset
  
  # Increment the counter
  counter <- counter + 1
}

```

## Combine fish survey and receiver data

```{r combine fish_flow and receiver week 1 data}

# No receiver data for this week yet #########################

# Read in the fish_flow survey and receiver data for week 1
fish_flow_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_1.csv")
receiver_data_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_1.csv")

# Combine the datasets horizontally
#fish_flow_receiver_1 <- bind_rows(fish_flow_1, receiver_data_1)

# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week
fish_flow_receiver_1 <- fish_flow_1

# Display the first few rows of the combined data
head(fish_flow_receiver_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_1.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 2 data}

# No receiver data for this week yet #########################

# Read in the fish_flow survey and receiver data for week 2
fish_flow_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_2.csv")
receiver_data_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_2.csv")

# Combine the datasets horizontally
#fish_flow_receiver_2 <- bind_rows(fish_flow_2, receiver_data_2)

# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week
fish_flow_receiver_2 <- fish_flow_2

# Display the first few rows of the combined data
head(fish_flow_receiver_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_2.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 3 data}

# Read in the fish_flow survey and receiver data for week 3
fish_flow_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_3.csv")
receiver_data_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_3.csv")

# Combine the datasets horizontally
fish_flow_receiver_3 <- bind_rows(fish_flow_3, receiver_data_3)

# Display the first few rows of the combined data
head(fish_flow_receiver_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_3.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 4 data}

# Read in the fish_flow survey and receiver data for week 4
fish_flow_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_4.csv")
receiver_data_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_4.csv")

# Combine the datasets horizontally
fish_flow_receiver_4 <- bind_rows(fish_flow_4, receiver_data_4)

# Display the first few rows of the combined data
head(fish_flow_receiver_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_4.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 5 data}

# Read in the fish_flow survey and receiver data for week 5
fish_flow_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_5.csv")
receiver_data_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_5.csv")

# Combine the datasets horizontally
fish_flow_receiver_5 <- bind_rows(fish_flow_5, receiver_data_5)

# Display the first few rows of the combined data
head(fish_flow_receiver_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_5.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 6 data}

# Read in the fish_flow survey and receiver data for week 6
fish_flow_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_6.csv")
receiver_data_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_6.csv")

# Combine the datasets horizontally
fish_flow_receiver_6 <- bind_rows(fish_flow_6, receiver_data_6)

# Display the first few rows of the combined data
head(fish_flow_receiver_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_6.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 7 data}

# Read in the fish_flow survey and receiver data for week 7
fish_flow_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_7.csv")
receiver_data_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_7.csv")

# Combine the datasets horizontally
fish_flow_receiver_7 <- bind_rows(fish_flow_7, receiver_data_7)

# Display the first few rows of the combined data
head(fish_flow_receiver_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_7.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 8 data}

# Read in the fish_flow survey and receiver data for week 8
fish_flow_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_8.csv")
receiver_data_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_8.csv")

# Combine the datasets horizontally
fish_flow_receiver_8 <- bind_rows(fish_flow_8, receiver_data_8)

# Display the first few rows of the combined data
head(fish_flow_receiver_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_8.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 9 data}

# Read in the fish_flow survey and receiver data for week 9
fish_flow_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_9.csv")
receiver_data_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_9.csv")

# Combine the datasets horizontally
fish_flow_receiver_9 <- bind_rows(fish_flow_9, receiver_data_9)

# Display the first few rows of the combined data
head(fish_flow_receiver_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_9.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 10 data}

# Read in the fish_flow survey and receiver data for week 10
fish_flow_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_10.csv")
receiver_data_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_10.csv")

# Combine the datasets horizontally
fish_flow_receiver_10 <- bind_rows(fish_flow_10, receiver_data_10)

# Display the first few rows of the combined data
head(fish_flow_receiver_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_10.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 11 data}

# Read in the fish_flow survey and receiver data for week 11
fish_flow_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_11.csv")
receiver_data_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_11.csv")

# Combine the datasets horizontally
fish_flow_receiver_11 <- bind_rows(fish_flow_11, receiver_data_11)

# Display the first few rows of the combined data
head(fish_flow_receiver_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_11.csv", 
          row.names = FALSE)

```

```{r combine fish_flow and receiver week 12 data}

# Read in the fish_flow survey and receiver data for week 12
fish_flow_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_12.csv")
receiver_data_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/receiver_data/receiver_data_12.csv")

# Combine the datasets horizontally
fish_flow_receiver_12 <- bind_rows(fish_flow_12, receiver_data_12)

# Display the first few rows of the combined data
head(fish_flow_receiver_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_12.csv", 
          row.names = FALSE)

```

## Preparing Stream Surveys

```{r add day and night shift differentiation into the stream survey 1}

# Read in the stream survey data
stream_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 1.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_1$date <- as.Date(stream_survey_1$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_1$dateTime_EST <- as.POSIXct(paste(stream_survey_1$date, 
                                                 stream_survey_1$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
stream_survey_1 <- stream_survey_1 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_1)

# Write new stream survey csv
write.csv(stream_survey_1, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_1.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 2}

# Read in the stream survey data
stream_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 2.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_2$date <- as.Date(stream_survey_2$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_2$dateTime_EST <- as.POSIXct(paste(stream_survey_2$date, 
                                                 stream_survey_2$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 11:00 EST to 17:00 EST
stream_survey_2 <- stream_survey_2 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 10 & hour(dateTime_EST) < 18 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_2)

# Write new stream survey csv
write.csv(stream_survey_2, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_2.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 3}

# Read in the stream survey data
stream_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 3.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_3$date <- as.Date(stream_survey_3$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_3$dateTime_EST <- as.POSIXct(paste(stream_survey_3$date, 
                                                 stream_survey_3$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 5:00 EST to 11:00 EST
stream_survey_3 <- stream_survey_3 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 4 & hour(dateTime_EST) < 12 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_3)

# Write new stream survey csv
write.csv(stream_survey_3, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_3.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 4}

# Read in the stream survey data
stream_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 4.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_4$date <- as.Date(stream_survey_4$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_4$dateTime_EST <- as.POSIXct(paste(stream_survey_4$date, 
                                                 stream_survey_4$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
stream_survey_4 <- stream_survey_4 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_4)

# Write new stream survey csv
write.csv(stream_survey_4, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_4.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 5}

# Read in the stream survey data
stream_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 5.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_5$date <- as.Date(stream_survey_5$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_5$dateTime_EST <- as.POSIXct(paste(stream_survey_5$date, 
                                                 stream_survey_5$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_5 <- stream_survey_5 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_5)

# Write new stream survey csv
write.csv(stream_survey_5, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_5.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 6}

# Read in the stream survey data
stream_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 6.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_6$date <- as.Date(stream_survey_6$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_6$dateTime_EST <- as.POSIXct(paste(stream_survey_6$date, 
                                                 stream_survey_6$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:00 EST to 9:00 EST
stream_survey_6 <- stream_survey_6 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 10 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_6)

# Write new stream survey csv
write.csv(stream_survey_6, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_6.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 7}

# Read in the stream survey data
stream_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 7.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_7$date <- as.Date(stream_survey_7$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_7$dateTime_EST <- as.POSIXct(paste(stream_survey_7$date, 
                                                 stream_survey_7$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_7 <- stream_survey_7 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_7)

# Write new stream survey csv
write.csv(stream_survey_7, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_7.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 8}

# Read in the stream survey data
stream_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 8.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_8$date <- as.Date(stream_survey_8$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_8$dateTime_EST <- as.POSIXct(paste(stream_survey_8$date, 
                                                 stream_survey_8$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 3:30 EST to 9:30 EST
stream_survey_8 <- stream_survey_8 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 2 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_8)

# Write new stream survey csv
write.csv(stream_survey_8, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_8.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 9}

# Read in the stream survey data
stream_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 9.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_9$date <- as.Date(stream_survey_9$date, 
                                format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_9$dateTime_EST <- as.POSIXct(paste(stream_survey_9$date, 
                                                 stream_survey_9$startTime), 
                                           format="%Y-%m-%d %H:%M",
                                           tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 7:00 EST to 13:00 EST
stream_survey_9 <- stream_survey_9 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 6 & hour(dateTime_EST) < 14 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_9)

# Write new stream survey csv
write.csv(stream_survey_9, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_9.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 10}

# Read in the stream survey data
stream_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 10.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_10$date <- as.Date(stream_survey_10$date, 
                                 format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_10$dateTime_EST <- as.POSIXct(paste(stream_survey_10$date, 
                                                  stream_survey_10$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column based on the time ranges
# Day shifts were from 4:00 EST to 10:00 EST
stream_survey_10 <- stream_survey_10 %>%
  mutate(
    shift = case_when(
        hour(dateTime_EST) >= 3 & hour(dateTime_EST) < 11 ~ "day",
        TRUE ~ "night"  # Any other time is night shift
    )
  )

# Display the first few rows to check the result
head(stream_survey_10)

# Write new stream survey csv
write.csv(stream_survey_10, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_10.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 11}

# Read in the stream survey data
stream_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 11.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_11$date <- as.Date(stream_survey_11$date, 
                                 format = "%m/%d/%Y")

# Combine the date and start time into a DateTime column
stream_survey_11$dateTime_EST <- as.POSIXct(paste(stream_survey_11$date, 
                                                  stream_survey_11$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column 
# All shifts in week 11 were day shifts
stream_survey_11 <- stream_survey_11 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(stream_survey_11)

# Write new stream survey csv
write.csv(stream_survey_11, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_11.csv", 
          row.names = FALSE)

```
```{r add day and night shift differentiation into the stream survey 12}

# Read in the stream survey data
stream_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawStreamData/Stream Survey Week 12.csv")

# Convert date to remove the incorrect associated time and keep only the date 
# Adjust date into the correct format
stream_survey_12$date <- as.Date(stream_survey_12$date, 
                                 format = "%m/%d/%Y")

# Combining the date and start time into a DateTime column
stream_survey_12$dateTime_EST <- as.POSIXct(paste(stream_survey_12$date, 
                                                  stream_survey_12$startTime), 
                                            format="%Y-%m-%d %H:%M",
                                            tz = "EST")

# Add Shift column
# All shifts in week 12 were day shifts
stream_survey_12 <- stream_survey_12 %>%
  mutate(shift = "day")

# Display the first few rows to check the result
head(stream_survey_12)

# Write new stream survey csv
write.csv(stream_survey_12, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_12.csv", 
          row.names = FALSE)

```

```{r processing stream surveys}

# Define the path to the sub-folder
stream_survey_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/"

# Define file names
stream_file_names <- paste0(stream_survey_data, c("stream_survey_1.csv", "stream_survey_2.csv", "stream_survey_3.csv", "stream_survey_4.csv", 
                       "stream_survey_5.csv", "stream_survey_6.csv", "stream_survey_7.csv", "stream_survey_8.csv", 
                       "stream_survey_9.csv", "stream_survey_10.csv", "stream_survey_11.csv", "stream_survey_12.csv")) 

# Define a lookup table for stream names
stream_name_lookup <- data.frame(
  abbreviation = c("Dickey (DCKY)", "Amethyst (AMTH)", 
                   "Underhill (UNDH)", "Dry (DRYU)"),  # List all abbreviations
  full_name = c("DICKEY", "AMETHYST", 
                "UNDERHILL", "DRY UPPER")  # Corresponding full names
)

# Create an empty list to store the processed datasets
processed_stream_data_list <- list()

# Loop through each stream survey file
for (file_name in stream_file_names) {
  
  # Read in the stream survey data
  raw_stream_data <- read.csv(file_name)
  
  # Step 1: Process the data
  stream_data <- raw_stream_data %>%
    
    # Step 2: Select specific columns
    select(stream, airTemp, cloud, precip, startTime, endTime, iso, Notes, 
           isoTime, downstreamGPS, downstreamGain, upstreamGPS, upstreamGain, shift) %>%

    # Step 3: Rename columns
    rename(
      streamNotes = Notes,
      river = stream,
      startTime_EST = startTime,
      endTime_EST = endTime,
      isoID = iso,
      isoTime_EST = isoTime,
      airTemp_F = airTemp) %>%
    
    # Step 4: Rewrite stream names
    left_join(stream_name_lookup, by = c("river" = "abbreviation")) %>%
    mutate(
      river = coalesce(full_name, river)  # Replace Brook with full_name, if available
    ) %>%
    select(-full_name)  # Remove the full_name column as it's no longer needed
  
  # Store the processed data in the list
  processed_stream_data_list[[file_name]] <- stream_data
  
  # Overwrite the original file with the processed data
  write.csv(stream_data, file_name, row.names = FALSE)
}

# Display the first few rows of each processed dataset
for (i in 1:length(processed_stream_data_list)) {
  cat("\nData for", stream_file_names[i], ":\n")
  print(head(processed_stream_data_list[[i]]))
}

```

## Combine fish_flow_receiver and stream survey data

```{r combine fish_flow_receiver and stream week 1 surveys}

# Read in the fish_flow_receiver and stream survey data for week 1
fish_flow_receiver_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_1.csv")
stream_survey_1 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_1.csv")

# Adjust 'river' in fish_flow_receiver survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_1 <- fish_flow_receiver_1 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_1 <- left_join(fish_flow_receiver_1, 
                           stream_survey_1, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_1 <- fish_flow_receiver_stream_1 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_1)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_1, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_1.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 2 surveys}

# Read in the fish_flow_receiver and stream survey data for week 2
fish_flow_receiver_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_2.csv")
stream_survey_2 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_2.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_2 <- fish_flow_receiver_2 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_2 <- left_join(fish_flow_receiver_2, 
                           stream_survey_2, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_2 <- fish_flow_receiver_stream_2 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_2)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_2, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_2.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 3 surveys}

# Read in the fish_flow_receiver and stream survey data for week 3
fish_flow_receiver_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_3.csv")
stream_survey_3 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_3.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_3 <- fish_flow_receiver_3 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_3 <- left_join(fish_flow_receiver_3, 
                           stream_survey_3, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_3 <- fish_flow_receiver_stream_3 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_3)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_3, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_3.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 4 surveys}

# Read in the fish_flow_receiver and stream survey data for week 4
fish_flow_receiver_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_4.csv")
stream_survey_4 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_4.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_4 <- fish_flow_receiver_4 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_4 <- left_join(fish_flow_receiver_4, 
                           stream_survey_4, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_4 <- fish_flow_receiver_stream_4 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_4)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_4, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_4.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 5 surveys}

# Read in the fish_flow_receiver and stream survey data for week 5
fish_flow_receiver_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_5.csv")
stream_survey_5 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_5.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_5 <- fish_flow_receiver_5 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_5 <- left_join(fish_flow_receiver_5, 
                           stream_survey_5, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_5 <- fish_flow_receiver_stream_5 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_5)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_5, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_5.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 6 surveys}

# Read in the fish_flow_receiver and stream survey data for week 6
fish_flow_receiver_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_6.csv")
stream_survey_6 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_6.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_6 <- fish_flow_receiver_6 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_6 <- left_join(fish_flow_receiver_6, 
                           stream_survey_6, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_6 <- fish_flow_receiver_stream_6 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_6)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_6, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_6.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 7 surveys}

# Read in the fish_flow_receiver and stream survey data for week 7
fish_flow_receiver_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_7.csv")
stream_survey_7 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_7.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_7 <- fish_flow_receiver_7 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_7 <- left_join(fish_flow_receiver_7, 
                           stream_survey_7, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_7 <- fish_flow_receiver_stream_7 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_7)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_7, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_7.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 8 surveys}

# Read in the fish_flow_receiver and stream survey data for week 8
fish_flow_receiver_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_8.csv")
stream_survey_8 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_8.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_8 <- fish_flow_receiver_8 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_8 <- left_join(fish_flow_receiver_8, 
                           stream_survey_8, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_8 <- fish_flow_receiver_stream_8 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_8)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_8, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_8.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 9 surveys}

# Read in the fish_flow_receiver and stream survey data for week 9
fish_flow_receiver_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_9.csv")
stream_survey_9 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_9.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_9 <- fish_flow_receiver_9 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_9 <- left_join(fish_flow_receiver_9, 
                           stream_survey_9, 
                           by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_9 <- fish_flow_receiver_stream_9 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_9)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_9, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_9.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 10 surveys}

# Read in the fish_flow_receiver and stream survey data for week 10
fish_flow_receiver_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_10.csv")
stream_survey_10 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_10.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_10 <- fish_flow_receiver_10 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_10 <- left_join(fish_flow_receiver_10, 
                            stream_survey_10, 
                            by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_10 <- fish_flow_receiver_stream_10 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_10)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_10, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_10.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 11 surveys}

# Read in the fish_flow_receiver and stream survey data for week 11
fish_flow_receiver_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_11.csv")
stream_survey_11 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_11.csv")

# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst
fish_flow_receiver_11 <- fish_flow_receiver_11 %>%
  mutate(
    # Create a new 'riverMatch' column for the join
    riverMatch = ifelse(river %in% c("BUFFAM", "HARRIS"), "AMETHYST", river)
  )

# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey
fish_flow_receiver_stream_11 <- left_join(fish_flow_receiver_11, 
                            stream_survey_11, 
                            by = c("shift", "riverMatch" = "river"))

# Remove the 'riverMatch' column from the result
fish_flow_receiver_stream_11 <- fish_flow_receiver_stream_11 %>% 
  select(-riverMatch)

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_11)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_11, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_11.csv", 
          row.names = FALSE)

```

```{r combine fish_flow_receiver and stream week 12 surveys}

# Read in the fish_flow_receiver and stream survey data for week 12
fish_flow_receiver_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_12.csv")
stream_survey_12 <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/stream_survey_data/stream_survey_12.csv")

# Combine the datasets by shift and river columns
fish_flow_receiver_stream_12 <- left_join(fish_flow_receiver_12, 
                            stream_survey_12, 
                            by = c("shift", "river"))

# Display the first few rows of the combined data
head(fish_flow_receiver_stream_12)

# Save the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_12, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_12.csv", 
          row.names = FALSE)

```

## Combine all weekly datasets

```{r combine all weekly datasets (fish, flow, receiver, and stream)}

# Define the path to the folder
combined_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/"

# Define file names
file_names <- paste0(combined_data, c("fish_flow_receiver_stream_1.csv", "fish_flow_receiver_stream_2.csv", "fish_flow_receiver_stream_3.csv", "fish_flow_receiver_stream_4.csv", 
                "fish_flow_receiver_stream_5.csv", "fish_flow_receiver_stream_6.csv", "fish_flow_receiver_stream_7.csv", "fish_flow_receiver_stream_8.csv", 
                "fish_flow_receiver_stream_9.csv", "fish_flow_receiver_stream_10.csv", "fish_flow_receiver_stream_11.csv", "fish_flow_receiver_stream_12.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
fish_flow_receiver_stream_all <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(fish_flow_receiver_stream_all)

# Write the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_all.csv", 
          row.names = FALSE)

```
## Filter combined dataset

```#{r filter tracking data by radioID}

# Read in the data
fish_flow_receiver_stream_all = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_all.csv")

# Reference table with end dates and correct streams
reference_table <- data.frame(
  radioID = c("27", "33", "34", "35", "36", 
              "40", "41", "43", "44", "45",
              "26", "28", "29", "31", "32",
              "37", "38", "46", "50", "51",
              "29.1", "30.1", "39.1", "46.1",
              "16", "17", "21", "22", "23",
              "24", "25", "42", "47", "48",
              "49", "52", "53", "54", "55",
              "11", "12",
              "13", "14",
              "15", "18",
              "19", "20",
              "56", "57",
              "58", "59",
              "60", "61",
              "62"),
  end_date = as.Date(c("2024-07-26", "2024-08-21", "2024-08-01", "2024-08-30", "2024-07-19",
                       "2024-07-26", "2024-08-30", "2024-08-21", "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-07-24", "2024-06-17", "2024-08-15", "2024-07-30",
                       "2024-08-09", "2024-08-15", "2024-06-28", "2024-08-30", "2024-08-30",
                       "2024-08-22", "2024-08-22", "2024-08-22", "2024-07-23",
                       "2024-08-22", "2024-08-30", "2024-08-22", "2024-07-18", "2024-07-23",
                       "2024-07-12", "2024-08-30", "2024-07-12", "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-06-30", "2024-06-30", "2024-08-22", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-23", "2024-08-23",
                       "2024-08-30", "2024-07-31",
                       "2024-08-30", "2024-08-30",
                       "2024-08-20", "2024-08-30",
                       "2024-08-23")),
  allowed_streams = c("UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", 
                     "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", 
                     "DICKEY", "DICKEY", "DICKEY", "DICKEY", "DICKEY", 
                     "DICKEY", "DICKEY", "DICKEY", "DICKEY", "DICKEY",
                     "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
                     "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
                     "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
                     "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS", "AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS","AMETHYST,BUFFAM,HARRIS",
                     "AMETHYST,BUFFAM,HARRIS")
)

# Ensure `radioID` in the reference table is numeric
reference_table$radioID <- as.numeric(reference_table$radioID)

# Join the reference table to add the filtering criteria
fish_flow_receiver_stream_corrected <- fish_flow_receiver_stream_all %>%
  left_join(reference_table, by = "radioID") %>%
  # Split allowed_streams into a list column for matching
  mutate(allowed_streams = strsplit(as.character(allowed_streams), ",")) %>%
  # Use rowwise to evaluate stream match for each row
  rowwise() %>%
  filter(
    date <= end_date,                                # Keep rows within the end date
    any(river %in% allowed_streams)                # Check if stream is in the allowed list
  ) %>%
  ungroup() %>% # Return to a non-rowwise data frame
  select(-end_date, -allowed_streams) # Drop unnecessary columns

# View the filtered dataset
head(fish_flow_receiver_stream_corrected)

# Write the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_corrected, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_corrected.csv", 
          row.names = FALSE)

```

```{r filter tracking data by radioID}

# Read in the data
fish_flow_receiver_stream_all = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_all.csv")

# Reference table with end dates
reference_table <- data.frame(
  radioID = c("27", "33", "34", "35", "36", 
              "40", "41", "43", "44", "45",
              "26", "28", "29", "31", "32",
              "37", "38", "46", "50", "51",
              "29.1", "30.1", "39.1", "46.1",
              "16", "17", "21", "22", "23",
              "24", "25", "42", "47", "48",
              "49", "52", "53", "54", "55",
              "11", "12",
              "13", "14",
              "15", "18",
              "19", "20",
              "56", "57",
              "58", "59",
              "60", "61",
              "62"),
  end_date = as.Date(c("2024-07-26", "2024-08-21", "2024-08-01", "2024-08-30", "2024-07-19",
                       "2024-07-26", "2024-08-30", "2024-08-21", "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-07-24", "2024-07-01", "2024-08-15", "2024-07-30",
                       "2024-08-09", "2024-08-15", "2024-06-28", "2024-08-30", "2024-08-30",
                       "2024-08-22", "2024-08-22", "2024-08-22", "2024-07-23",
                       "2024-08-22", "2024-08-30", "2024-08-22", "2024-07-18", "2024-07-23",
                       "2024-07-12", "2024-08-30", "2024-07-12", "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-08-02", "2024-07-23", "2024-08-22", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-30", "2024-08-30",
                       "2024-08-23", "2024-08-23",
                       "2024-08-30", "2024-07-31",
                       "2024-08-30", "2024-08-30",
                       "2024-08-20", "2024-08-30",
                       "2024-08-23"))
)

# Ensure `radioID` in the reference table is numeric
reference_table$radioID <- as.numeric(reference_table$radioID)

# Stream visit table: specify which streams were visited on which dates
stream_visits <- data.frame(
  river = c("DICKEY", "DICKEY", "DICKEY", "DICKEY", "DICKEY",
             "DICKEY", "DICKEY", "DICKEY", "DICKEY", "DICKEY",
             "DICKEY", "DICKEY", "DICKEY",
             "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL",
             "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL", "UNDERHILL",
             "UNDERHILL", "UNDERHILL", "UNDERHILL",
             "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
             "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
             "DRY UPPER", "DRY UPPER", "DRY UPPER", "DRY UPPER",
             "AMETHYST", "AMETHYST", "AMETHYST", "AMETHYST", "AMETHYST",
             "AMETHYST", "AMETHYST", "AMETHYST", "AMETHYST", "AMETHYST",
             "AMETHYST", "AMETHYST", "AMETHYST",
             "BUFFAM", "BUFFAM", "BUFFAM", "BUFFAM", "BUFFAM",
             "BUFFAM", "BUFFAM", "BUFFAM", "BUFFAM", "BUFFAM",
             "BUFFAM", "BUFFAM", "BUFFAM",
             "HARRIS", "HARRIS", "HARRIS", "HARRIS", "HARRIS",
             "HARRIS", "HARRIS", "HARRIS", "HARRIS", "HARRIS",
             "HARRIS", "HARRIS", "HARRIS"),
  valid_date = as.Date(c("2024-06-13", "2024-06-17", "2024-06-18", "2024-06-28", "2024-07-01",
                         "2024-07-10", "2024-07-16", "2024-07-24", "2024-07-30", "2024-08-09",
                         "2024-08-15", "2024-08-29", "2024-06-21",
                         "2024-06-12", "2024-06-20", "2024-06-21", "2024-06-27", "2024-07-03",
                         "2024-07-09", "2024-07-19", "2024-07-26", "2024-08-01", "2024-08-06",
                         "2024-08-14", "2024-08-21", "2024-08-27",
                         "2024-06-14", "2024-06-19", "2024-06-20", "2024-06-25", "2024-06-30",
                         "2024-07-12", "2024-07-18", "2024-07-23", "2024-08-02", "2024-08-05",
                         "2024-08-07", "2024-08-16", "2024-08-22", "2024-08-26",
                         "2024-06-11", "2024-06-18", "2024-06-19", "2024-06-26", "2024-07-02",
                         "2024-07-11", "2024-07-17", "2024-07-25", "2024-07-31", "2024-08-08",
                         "2024-08-13", "2024-08-20", "2024-08-23",
                         "2024-06-11", "2024-06-18", "2024-06-19", "2024-06-26", "2024-07-02",
                         "2024-07-11", "2024-07-17", "2024-07-25", "2024-07-31", "2024-08-08",
                         "2024-08-13", "2024-08-20", "2024-08-23",
                         "2024-06-11", "2024-06-18", "2024-06-19", "2024-06-26", "2024-07-02",
                         "2024-07-11", "2024-07-17", "2024-07-25", "2024-07-31", "2024-08-08",
                         "2024-08-13", "2024-08-20", "2024-08-23"))
)

# Convert `date` column in `fish_flow_receiver_stream_all` to Date type
fish_flow_receiver_stream_all <- fish_flow_receiver_stream_all %>%
  mutate(date = as.Date(date)) # Ensure it's in the correct format

# Convert `trackedTime_EST` to POSIXct format
fish_flow_receiver_stream_all <- fish_flow_receiver_stream_all %>%
  mutate(trackedTime_EST = as.POSIXct(trackedTime_EST, format = "%Y-%m-%d %H:%M:%S"))

# Find the first "RECOVERED" time for each radioID
recovered_times <- fish_flow_receiver_stream_all %>%
  filter(status == "RECOVERED") %>%
  group_by(radioID) %>%
  summarize(recovered_time = min(trackedTime_EST), .groups = "drop")

# Join the reference table to add the filtering criteria
fish_flow_receiver_stream_corrected <- fish_flow_receiver_stream_all %>%
  left_join(reference_table, by = "radioID") %>%
  rowwise() %>%
  filter(
    date <= end_date                                # Keep rows within the end date
  ) %>%
  ungroup() %>% # Return to a non-rowwise data frame
  # Join with the stream_visits table to check valid dates
  inner_join(stream_visits, by = c("river", "date" = "valid_date")) %>%
  select(-end_date) %>% # Drop unnecessary columns
  left_join(recovered_times, by = "radioID") %>%
  # Filter out points after recovery
  filter(is.na(recovered_time) | trackedTime_EST <= recovered_time) %>%
  select(-recovered_time)  # Remove extra column after filtering

# View the filtered dataset
head(fish_flow_receiver_stream_corrected)

# Come back and double check these are the values I want #############################
fish_flow_receiver_stream_corrected <- fish_flow_receiver_stream_corrected %>%
  mutate(
    lat = ifelse(lat < 40, NA, lat),
    lon = ifelse(lon > -70, NA, lon)
  )

# Write the combined data to a new CSV file
write.csv(fish_flow_receiver_stream_corrected, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_corrected.csv", 
          row.names = FALSE)

```



## Preparing tagging data

```{r processing tagging data}

# Read in the tagging data
tagging_data <- read_excel("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/taggingData.xlsx")

# Select specific columns
tagging_data <- tagging_data %>%
  select(RIVER, DATE, SECTION, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, GENETICSAM, SEX)

# Rename columns
tagging_data <- tagging_data %>%
  rename(
    river = RIVER,
    date = DATE,
    section = SECTION,
    radioID = RADIOTAG,
    tempID = TEMPTAG,
    length_mm = LENGTH,
    weight_g = WEIGHT,
    geneticSam = GENETICSAM,
    sex = SEX
    )

# Fix column labels and remove first tag 44 since the fish died and was retagged before the study began
tagging_data <- tagging_data %>%
  mutate(river = str_trim(river),
         date = str_trim(date),
         section = str_trim(section),
         radioID = str_trim(radioID),
         tempID = str_trim(tempID),
         length_mm = str_trim(length_mm),
         weight_g = str_trim(weight_g),
         geneticSam = str_trim(geneticSam),
         sex = str_trim(sex)) %>%
  filter(!(radioID == "44" & date == as.POSIXct("2024-06-04", format="%Y-%m-%d")))

# Display the first few rows of the dataset
head(tagging_data)

# Write new tagging data csv
write.csv(tagging_data, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/tagging_data/tagging_data.csv", 
          row.names = FALSE)

```

## Combine tagging data with fish/stream/flow/receiver data

```{r combine tagging data with fish/stream/flow/receiver data}

# Read in the data
tagging_data = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/tagging_data/tagging_data.csv")
fish_flow_receiver_stream_corrected = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_corrected.csv")

# Create a mapping of radio tag ID to temp tag ID from tagging data
radio_temp_mapping <- tagging_data %>%
  select(radioID, tempID) %>%
  distinct()  # Ensures unique pairings

# Merge this mapping into fish/stream/flow/receiver data
fish_flow_receiver_stream_corrected <- fish_flow_receiver_stream_corrected %>%
  left_join(radio_temp_mapping, by = "radioID")

# Convert the date column into date format
fish_flow_receiver_stream_corrected <- fish_flow_receiver_stream_corrected %>%
  mutate(date = as.Date(date))

# Convert the date column into date format
tagging_data <- tagging_data %>%
  mutate(date = as.Date(date))

# Combine the datasets by binding rows horizontally
fish_flow_receiver_stream_tagging_all <- bind_rows(fish_flow_receiver_stream_corrected, tagging_data)

# Now the combined dataframe should have all tempTagIDs added where appropriate

# Display the first few rows of the dataset
head(fish_flow_receiver_stream_tagging_all)

# Write new tagging data csv
write.csv(fish_flow_receiver_stream_tagging_all, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_tagging_all.csv", 
          row.names = FALSE)

```

## Preparing collection data

```{r processing collection data}

# Read in the collection data
collection_data <- read_excel("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/collectionData.xlsx")

# Select specific columns
collection_data <- collection_data %>%
  select(RIVER, recoveryDate, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, BLOOD, TYPE, SEX, COMMENTS)

# Rename columns
collection_data <- collection_data %>%
  rename(
    river = RIVER,
    date = recoveryDate,
    radioID = RADIOTAG,
    tempID = TEMPTAG,
    length_mm = LENGTH,
    weight_g = WEIGHT,
    blood = BLOOD,
    type = TYPE,
    sex = SEX,
    collectionNotes = COMMENTS
    )

# Fix column labels
collection_data <- collection_data %>%
  mutate(river = str_trim(river),
         date = str_trim(date),
         radioID = str_trim(radioID),
         tempID = str_trim(tempID),
         length_mm = str_trim(length_mm),
         weight_g = str_trim(weight_g),
         blood = str_trim(blood),
         type = str_trim(type),
         sex = str_trim(sex),
         collectionNotes = str_trim(collectionNotes))

# Display the first few rows of the dataset
head(collection_data)

# Write new tagging data csv
write.csv(collection_data, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/tagging_data/collection_data.csv", 
          row.names = FALSE)

```

## Combine collection data with fish/stream/flow/receiver/tagging data

```{r combine collection data with fish/stream/flow/receiver/tagging data}

# Read in the data
collection_data = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/tagging_data/collection_data.csv")
fish_flow_receiver_stream_tagging_all = read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/fish_flow_receiver_stream_tagging_all.csv")

# Convert the date column into date format
collection_data <- collection_data %>%
  mutate(date = as.Date(date))

# Convert the date column into date format
fish_flow_receiver_stream_tagging_all <- fish_flow_receiver_stream_tagging_all %>%
  mutate(date = as.Date(date))

# Convert the radioID column into character format
collection_data <- collection_data %>%
  mutate(radioID = as.character(radioID))

# Convert the radioID column into character format
fish_flow_receiver_stream_tagging_all <- fish_flow_receiver_stream_tagging_all %>%
  mutate(radioID = as.character(radioID))

# Convert the tempID column into character format
collection_data <- collection_data %>%
  mutate(tempID = as.character(tempID))

# Convert the tempID column into character format
fish_flow_receiver_stream_tagging_all <- fish_flow_receiver_stream_tagging_all %>%
  mutate(tempID = as.character(tempID))

# Combine the datasets by binding rows horizontally
tracking_data_all <- bind_rows(fish_flow_receiver_stream_tagging_all, collection_data)

# Display the first few rows to check the result
head(tracking_data_all)

```

## Finalize dataset

```{r organize and finalize dataset}

# Select columns to keep
tracking_data_all <- tracking_data_all %>%
  select(date, trackedTime_EST, river, shift, radioID, tempID, status, power, source, fishNotes, lon, lat, habitat, habitatExtra, position, substrate, substrateExtra, shade, airTemp_F, cloud, precip, ftDischarge_cfs, ftTime_EST, startTime_EST, endTime_EST, streamNotes, downstreamGPS, downstreamGain, upstreamGPS, upstreamGain, isoID, isoTime_EST, length_mm, weight_g, sex, type, geneticSam, blood, section, collectionNotes)

# Replace all blank ("") or whitespace-only values with NA
tracking_data_all <- tracking_data_all %>%
  mutate(across(everything(), ~ na_if(trimws(.), "")))

# Check for any odd values still remaining as "NA"
problematic_rows <- tracking_data_all %>%
  filter(if_any(everything(), ~ . == ""))

# View problematic rows if any
print(problematic_rows)

# Display the first few rows to check the result
head(tracking_data_all)

# Write new tagging data csv
write.csv(tracking_data_all, 
          file = "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/combined_data/tracking_data_all.csv", 
          row.names = FALSE)
```



## Preparing HOBO Logger Files

```{r combine all underhill files}

# Define the path to the folder
UNDH_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/UNDH/"

# Define file names
file_names <- paste0(UNDH_logger_data, c("UNDH_1.csv", "UNDH_2.csv", 
                                          "UNDH_3.csv", "UNDH_4.csv", 
                                          "UNDH_5.csv", "UNDH_trib.csv", 
                                          "UNDH_6.csv", "UNDH_7.csv", 
                                          "UNDH_8.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
UNDH_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(UNDH_logger_data)

# Write the combined data to a new CSV file
write.csv(UNDH_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/UNDH_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all harris files}

# Define the path to the folder
HARR_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/HARR/"

# Define file names
file_names <- paste0(HARR_logger_data, c("HARR_1.csv", "HARR_2.csv", 
                                          "HARR_3.csv", "HARR_4.csv", 
                                          "HARR_5.csv", "HARR_6.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
HARR_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(HARR_logger_data)

# Write the combined data to a new CSV file
write.csv(HARR_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/HARR_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all buffam files}

# Define the path to the folder
BUFF_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/BUFF/"

# Define file names
file_names <- paste0(BUFF_logger_data, c("BUFF_1.csv", "BUFF_2.csv", 
                                          "BUFF_3.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
BUFF_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(BUFF_logger_data)

# Write the combined data to a new CSV file
write.csv(BUFF_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/BUFF_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all amethyst files}

# Define the path to the folder
AMTH_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/AMTH/"

# Define file names
file_names <- paste0(AMTH_logger_data, c("AMTH_1.csv", "AMTH_2.csv", 
                                          "AMTH_3.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
AMTH_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(AMTH_logger_data)

# Write the combined data to a new CSV file
write.csv(AMTH_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/AMTH_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all dickey files}

# Define the path to the folder
DCKY_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/DCKY/"

# Define file names
file_names <- paste0(DCKY_logger_data, c("DCKY_1.csv", "DCKY_2.csv", 
                                          "DCKY_3.csv", "DCKY_4.csv", 
                                          "DCKY_5.csv", "DCKY_6.csv", 
                                          "DCKY_7.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
DCKY_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(DCKY_logger_data)

# Write the combined data to a new CSV file
write.csv(DCKY_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DCKY_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all dry upper files}

# Define the path to the folder
DRYU_logger_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Temperature/DRYU/"

# Define file names
file_names <- paste0(DRYU_logger_data, c("DRYU_1.csv", "DRYU_2.csv", 
                                          "DRYU_3.csv", "DRYU_4.csv", 
                                          "DRYU_5.csv", "DRYU_6.csv", 
                                          "DRYU_7.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
DRYU_logger_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(DRYU_logger_data)

# Write the combined data to a new CSV file
write.csv(DRYU_logger_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DRYU_logger_data.csv", 
          row.names = FALSE)

```

```{r combine all logger data}

# Read in the logger data
DRYU_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DRYU_logger_data.csv")
HARR_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/HARR_logger_data.csv")
BUFF_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/BUFF_logger_data.csv")
AMTH_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/AMTH_logger_data.csv")
DCKY_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DCKY_logger_data.csv")
UNDH_logger_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/UNDH_logger_data.csv")

# Combine the data frames by rows
logger_data_all <- bind_rows(DRYU_logger_data, HARR_logger_data, BUFF_logger_data, AMTH_logger_data, DCKY_logger_data, UNDH_logger_data)

# Display the first few rows of the combined dataset
head(logger_data_all)

# Write the combined data to a new CSV file
write.csv(logger_data_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/logger_data_all.csv", 
          row.names = FALSE)

```

```{r filter logger data}

logger_data_all <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/logger_data_all.csv")

# Remove rows where `flagged` is TRUE
logger_data_filtered <- logger_data_all %>%
  filter(flagged != TRUE)

# Write the combined data to a new CSV file
write.csv(logger_data_filtered, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/logger_data_filtered.csv", 
          row.names = FALSE)

logger_data_filtered$date <- as.Date(logger_data_filtered$datetime, format = "%m/%d/%Y %H:%M")

# Define date range
start_date <- as.Date("2024-06-11")
end_date <- as.Date("2024-08-29")

# Filter dataset to within the date range
logger_data_summer <- logger_data_filtered %>%
  filter(date >= start_date & date <= end_date)

# Display the first few rows of the combined dataset
head(logger_data_summer)

# Write the combined data to a new CSV file
write.csv(logger_data_summer, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/logger_data_summer.csv", 
          row.names = FALSE)

```







## Preparing Pressure Transducer Files

```{r combine all underhill pressure files}

# Define the path to the folder
UNDH_pressure_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Pressure/UNDH/"

# Define file names
file_names <- paste0(UNDH_pressure_data, c("UNDH_20240604_to_20240801.csv",
                                           "UNDH_20240801_to_20240905.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
UNDH_pressure_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(UNDH_pressure_data)

# Write the combined data to a new CSV file
write.csv(UNDH_pressure_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/UNDH_pressure_data.csv", 
          row.names = FALSE)

```

```{r combine all harris pressure files}
# Edit this code since I don't need binding ##########################

# Define the path to the folder
HARR_pressure_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Pressure/HARR/"

# Define file names
file_names <- paste0(HARR_pressure_data, c("HARR_1.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
HARR_pressure_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(HARR_pressure_data)

# Write the combined data to a new CSV file
write.csv(HARR_pressure_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/HARR_pressure_data.csv", 
          row.names = FALSE)

```

```{r combine all buffam pressure files}

# Define the path to the folder
BUFF_pressure_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Pressure/BUFF/"

# Define file names
file_names <- paste0(BUFF_pressure_data, c("BUFF_20240610_to_20240618.csv", 
                                           "BUFF_20240618_to_20240825.csv", 
                                           "BUFF_20240825_to_20240905.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
BUFF_pressure_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(BUFF_pressure_data)

# Write the combined data to a new CSV file
write.csv(BUFF_pressure_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/BUFF_pressure_data.csv", 
          row.names = FALSE)

```

```{r combine all dickey pressure files}

# Define the path to the folder
DCKY_pressure_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Pressure/DCKY/"

# Define file names
file_names <- paste0(DCKY_pressure_data, c("DCKY_20240604_to_20240724.csv", 
                                           "DCKY_20240724_to_20240905.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
DCKY_pressure_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(DCKY_pressure_data)

# Write the combined data to a new CSV file
write.csv(DCKY_pressure_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DCKY_pressure_data.csv", 
          row.names = FALSE)

```

```{r combine all dry upper pressure files}

# Define the path to the folder
DRYU_pressure_data <- "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLoggerData/Pressure/DRYU/"

# Define file names
file_names <- paste0(DRYU_pressure_data, c("DRYU_20240605_to_20240802.csv", 
                                           "DRYU_20240802_to_20240905.csv")) 

# Create an empty list to store the data from each file
full_data_list <- list()

# Loop through each file and read the data into the list
for (file_name in file_names) {
  all_data <- read.csv(file_name, stringsAsFactors = FALSE)
  full_data_list[[file_name]] <- all_data
}

# Combine all datasets into a single data frame by stacking rows
DRYU_pressure_data <- bind_rows(full_data_list)

# Display the first few rows of the combined dataset
head(DRYU_pressure_data)

# Write the combined data to a new CSV file
write.csv(DRYU_pressure_data, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DRYU_pressure_data.csv", 
          row.names = FALSE)

```

```{r combine all pressure data}

# Read in the pressure data
DRYU_pressure_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DRYU_pressure_data.csv")
#HARR_pressure_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/HARR_pressure_data.csv")
BUFF_pressure_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/BUFF_pressure_data.csv")
DCKY_pressure_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/DCKY_pressure_data.csv")
UNDH_pressure_data <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/UNDH_pressure_data.csv")

# Combine the data frames by rows
pressure_data_all <- bind_rows(DRYU_pressure_data, BUFF_pressure_data, DCKY_pressure_data, UNDH_pressure_data) #, HARR_logger_data)

# Display the first few rows of the combined dataset
head(pressure_data_all)

# Write the combined data to a new CSV file
write.csv(pressure_data_all, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/pressure_data_all.csv", 
          row.names = FALSE)

```

```{r filter pressure data}

# Edit this code so that the column names are in proper format and datetime is formatted correctly ######################

pressure_data_all <- read.csv("C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/pressure_data_all.csv")

# Create a date column
pressure_data_all$date <- as.Date(pressure_data_all$datetime, format = "%m/%d/%Y %H:%M")

# Define date range
start_date <- as.Date("2024-06-11")
end_date <- as.Date("2024-08-29")

# Filter dataset to within the date range
pressure_data_summer <- pressure_data_all %>%
  filter(date >= start_date & date <= end_date)

# Display the first few rows of the combined dataset
head(pressure_data_summer)

# Write the combined data to a new CSV file
write.csv(pressure_data_summer, 
          "C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/data/logger_data/pressure_data_summer.csv", 
          row.names = FALSE)

```