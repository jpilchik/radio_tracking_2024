[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Radio Tracking 2024",
    "section": "",
    "text": "1 Introduction\nGuide to building a book in Quarto and publishing on github.io for Conte ecohydrology crew.\n\n\nSession Information\n\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.3 (2024-02-29 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.3    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.3       htmltools_0.5.8.1 rstudioapi_0.16.0 rmarkdown_2.28   \n [9] knitr_1.48        jsonlite_1.8.8    xfun_0.47         digest_0.6.35    \n[13] rlang_1.1.3       evaluate_0.24.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html",
    "href": "creatingMyDatasheet.html",
    "title": "2  Creating my Datasheet",
    "section": "",
    "text": "2.1 Prep\nCode\n# Load required libraries\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(readxl)\nlibrary(leaflet)\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(stringr)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-fish-surveys",
    "href": "creatingMyDatasheet.html#preparing-fish-surveys",
    "title": "2  Creating my Datasheet",
    "section": "2.2 Preparing Fish Surveys",
    "text": "2.2 Preparing Fish Surveys\n\n\nCode\n# Read in the fish survey data\nfish_survey_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 1.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_1$date &lt;- as.Date(fish_survey_1$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_1$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_1$date, \n                                               fish_survey_1$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nfish_survey_1 &lt;- fish_survey_1 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_1)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       16 d0a3b6b5-3d34-4e15-a2b5-01e3a329b214 6/11/2024 8:58:55 PM\n2       17 de178623-dad7-4dcf-a0f7-d5619cd48759 6/11/2024 8:58:56 PM\n3       18 ddeedd3d-937f-46c1-8eef-b77c5ca1a85b 6/11/2024 8:58:56 PM\n4       19 08bdb6c4-4237-4193-ab3c-a349a64db4d9 6/11/2024 8:58:57 PM\n5       20 c77027d3-8811-4a1b-a676-a2843c7f9b07 6/11/2024 8:58:57 PM\n6       21 e3016d54-bffe-431e-b4e6-16bd78bab6f3 6/11/2024 8:58:58 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS  9/6/2024 6:03:52 PM\n2 jpilchik@contractor.usgs.gov_USGS 9/10/2024 6:18:09 PM\n3 jpilchik@contractor.usgs.gov_USGS 9/10/2024 6:18:04 PM\n4 jpilchik@contractor.usgs.gov_USGS  9/6/2024 6:06:48 PM\n5 jpilchik@contractor.usgs.gov_USGS  9/6/2024 6:07:31 PM\n6 jpilchik@contractor.usgs.gov_USGS  9/6/2024 6:07:48 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 05:57       NA  Riffle   Center\n2 jpilchik@contractor.usgs.gov_USGS     NA 06:08       NA  Riffle   Center\n3 jpilchik@contractor.usgs.gov_USGS     NA 06:15       NA  Riffle   Center\n4 jpilchik@contractor.usgs.gov_USGS     NA 06:19       NA     Run     Left\n5 jpilchik@contractor.usgs.gov_USGS     NA 06:28       NA     Run     Left\n6 jpilchik@contractor.usgs.gov_USGS     NA 06:34       NA   Glide   Center\n  substrate cover         shade Notes amthID undhID dryuID habitatExtra signal\n1      Rock    NA  Fully shaded           59     NA     NA                  NA\n2      Rock    NA  Fully shaded           60     NA     NA                  NA\n3      Rock    NA  Fully shaded           19     NA     NA                  NA\n4    Pebble    NA Mostly shaded           20     NA     NA                  NA\n5      Rock    NA Mostly shaded           57     NA     NA                  NA\n6      Rock    NA  Fully shaded           12     NA     NA                  NA\n  substrateExtra       date brookName         x        y        dateTime_EST\n1             NA 2024-06-11  AMETHYST -72.46038 42.38162 2024-06-11 05:57:00\n2             NA 2024-06-11  AMETHYST -72.46030 42.38136 2024-06-11 06:08:00\n3             NA 2024-06-11    BUFFAM -72.46023 42.38139 2024-06-11 06:15:00\n4             NA 2024-06-11    HARRIS -72.46015 42.38095 2024-06-11 06:19:00\n5             NA 2024-06-11    HARRIS -72.46034 42.38105 2024-06-11 06:28:00\n6             NA 2024-06-11    HARRIS -72.46009 42.38094 2024-06-11 06:34:00\n  shift\n1   day\n2   day\n3   day\n4   day\n5   day\n6   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_1, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 2.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_2$date &lt;- as.Date(fish_survey_2$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_2$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_2$date, \n                                               fish_survey_2$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 11:00 EST to 17:00 EST\nfish_survey_2 &lt;- fish_survey_2 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 10 & hour(dateTime_EST) &lt; 18 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_2)\n\n\n  ObjectID                             GlobalID         CreationDate\n1      256 d0100699-a73b-4604-8b3f-70443dadab8e 6/18/2024 2:57:58 AM\n2      257 068e3aa6-8857-49c0-84b3-d67ec9bfe7f0 6/18/2024 2:57:59 AM\n3      258 02c92d7b-0f87-41c2-bc53-7e4e33755392 6/18/2024 2:57:59 AM\n4      259 b2fbed47-28d9-47e3-bfda-db3835bcd5d3 6/18/2024 2:58:00 AM\n5      260 23aec077-27c1-4b76-a5ff-64de3b608de9 6/18/2024 2:58:01 AM\n6      261 f1545e22-1078-41bb-985c-4240cd1f895a 6/18/2024 2:58:02 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:46:44 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:46:50 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:46:56 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:47:02 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:47:11 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/19/2024 6:47:17 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     31 11:33       NA    Pool   Center\n2 jpilchik@contractor.usgs.gov_USGS     46 11:57       NA     Run    Right\n3 jpilchik@contractor.usgs.gov_USGS     29 11:59       NA  Riffle     Left\n4 jpilchik@contractor.usgs.gov_USGS     26 12:10       NA     Run    Right\n5 jpilchik@contractor.usgs.gov_USGS     28 12:47       NA    Pool     Left\n6 jpilchik@contractor.usgs.gov_USGS     37 12:49       NA    Pool    Right\n  substrate cover          shade Notes amthID undhID dryuID  habitatExtra\n1      Rock    NA  Mostly shaded           NA     NA     NA              \n2    Pebble    NA Lightly shaded           NA     NA     NA              \n3      Rock    NA   Fully shaded           NA     NA     NA  Woody_debris\n4      Rock    NA Lightly shaded           NA     NA     NA Undercut_bank\n5   Boulder    NA  Mostly shaded           NA     NA     NA              \n6      Rock    NA  Mostly shaded           NA     NA     NA              \n  signal substrateExtra       date brookName         x        y\n1     NA             NA 2024-06-17           -72.37084 42.44394\n2     NA             NA 2024-06-17           -72.37173 42.44421\n3     NA             NA 2024-06-17           -72.37194 42.44430\n4     NA             NA 2024-06-17           -72.37344 42.44421\n5     NA             NA 2024-06-17           -72.37040 42.44369\n6     NA             NA 2024-06-17           -72.37038 42.44377\n         dateTime_EST shift\n1 2024-06-17 11:33:00   day\n2 2024-06-17 11:57:00   day\n3 2024-06-17 11:59:00   day\n4 2024-06-17 12:10:00   day\n5 2024-06-17 12:47:00   day\n6 2024-06-17 12:49:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_2, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 3.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_3$date &lt;- as.Date(fish_survey_3$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_3$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_3$date, \n                                               fish_survey_3$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nfish_survey_3 &lt;- fish_survey_3 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_3)\n\n\n  ObjectID                             GlobalID         CreationDate\n1      474 dcdf8b62-1775-4cb7-8202-8c79ccfbb1dc 6/25/2024 9:27:07 PM\n2      475 088da717-10d6-4219-b333-9a8252bd1dbc 6/25/2024 9:27:14 PM\n3      476 11e7984e-2002-4141-bcd8-f127808c5e9f 6/25/2024 9:27:20 PM\n4      477 0e0a30fc-e57d-4d45-8696-a99edff05c5b 6/25/2024 9:27:29 PM\n5      478 a43d361e-469b-496b-aca1-b1b46a851eb0 6/25/2024 9:27:35 PM\n6      479 72a85c5a-1fd3-4330-a5a8-0b1713d36b7a 6/25/2024 9:27:41 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:39:38 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:39:46 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:40:01 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:40:18 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:40:27 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/30/2024 1:40:42 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 05:59       NA    Pool   Center\n2 jpilchik@contractor.usgs.gov_USGS     NA 06:02       NA    Pool    Right\n3 jpilchik@contractor.usgs.gov_USGS     NA 06:07       NA    Pool    Right\n4 jpilchik@contractor.usgs.gov_USGS     NA 06:11       NA    Pool     Left\n5 jpilchik@contractor.usgs.gov_USGS     NA 06:20       NA    Pool    Right\n6 jpilchik@contractor.usgs.gov_USGS     NA 06:21       NA    Pool    Right\n  substrate cover          shade Notes amthID undhID dryuID\n1      Rock    NA  Mostly shaded           NA     NA     55\n2       Mud    NA  Mostly shaded           NA     NA     16\n3       Mud    NA  Mostly shaded           NA     NA     53\n4       Mud    NA Lightly shaded           NA     NA     22\n5      Rock    NA  Mostly shaded           NA     NA     21\n6      Rock    NA  Mostly shaded           NA     NA     25\n                habitatExtra signal substrateExtra       date brookName\n1               Woody_debris     NA             NA 2024-06-25          \n2               Woody_debris     NA             NA 2024-06-25          \n3               Woody_debris     NA             NA 2024-06-25          \n4   Root_bundle,Woody_debris     NA             NA 2024-06-25          \n5 Woody_debris,Undercut_bank     NA             NA 2024-06-25          \n6 Undercut_bank,Woody_debris     NA             NA 2024-06-25          \n          x        y        dateTime_EST shift\n1 -72.50451 42.66767 2024-06-25 05:59:00   day\n2 -72.50455 42.66774 2024-06-25 06:02:00   day\n3 -72.50451 42.66761 2024-06-25 06:07:00   day\n4 -72.50445 42.66767 2024-06-25 06:11:00   day\n5 -72.50506 42.66704 2024-06-25 06:20:00   day\n6 -72.50507 42.66704 2024-06-25 06:21:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_3, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 4.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_4$date &lt;- as.Date(fish_survey_4$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_4$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_4$date, \n                                               fish_survey_4$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nfish_survey_4 &lt;- fish_survey_4 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_4)\n\n\n  ObjectID                             GlobalID         CreationDate\n1      732 ee800694-c1c8-4a3b-86b1-af3afb8ee18d 6/30/2024 2:30:32 PM\n2      733 7c526efd-64a2-4bbf-a10d-3beb9e5f35e0 6/30/2024 2:30:42 PM\n3      734 8c935231-1d8b-4c99-bcc4-7bca77d37945 6/30/2024 2:30:55 PM\n4      735 c094b7d7-a650-41eb-893f-59b0d7fae278 6/30/2024 2:31:09 PM\n5      736 41fc1d32-bfe3-4196-b284-f7cf5b9ad2ac 6/30/2024 2:31:21 PM\n6      737 f38f6884-dab6-4b42-8856-cf560d793cfc 6/30/2024 2:33:37 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:19:27 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:19:45 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:19:52 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:19:57 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:20:05 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:20:08 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 04:39       NA    Pool     Left\n2 jpilchik@contractor.usgs.gov_USGS     NA 04:42       NA    Pool    Right\n3 jpilchik@contractor.usgs.gov_USGS     NA 04:43       NA    Pool    Right\n4 jpilchik@contractor.usgs.gov_USGS     NA 04:50       NA    Pool    Right\n5 jpilchik@contractor.usgs.gov_USGS     NA 04:51       NA    Pool    Right\n6 jpilchik@contractor.usgs.gov_USGS     NA 04:51       NA    Pool    Right\n  substrate cover         shade Notes amthID undhID dryuID\n1        NA    NA         Night           NA     NA     22\n2        NA    NA  Fully shaded           NA     NA     16\n3        NA    NA  Fully shaded           NA     NA     55\n4        NA    NA Mostly shaded           NA     NA     21\n5        NA    NA  Fully shaded           NA     NA     25\n6        NA    NA  Fully shaded           NA     NA     24\n                habitatExtra signal substrateExtra       date brookName\n1                Root_bundle     NA       Rock,Mud 2024-06-30          \n2               Woody_debris     NA            Mud 2024-06-30          \n3               Woody_debris     NA            Mud 2024-06-30          \n4 Woody_debris,Undercut_bank     NA            Mud 2024-06-30          \n5 Undercut_bank,Woody_debris     NA            Mud 2024-06-30          \n6 Undercut_bank,Woody_debris     NA            Mud 2024-06-30          \n          x        y        dateTime_EST shift\n1 -72.50457 42.66769 2024-06-30 04:39:00   day\n2 -72.50448 42.66760 2024-06-30 04:42:00   day\n3 -72.50453 42.66762 2024-06-30 04:43:00   day\n4 -72.50514 42.66698 2024-06-30 04:50:00   day\n5 -72.50509 42.66699 2024-06-30 04:51:00   day\n6 -72.50508 42.66702 2024-06-30 04:51:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_4, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 5.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_5$date &lt;- as.Date(fish_survey_5$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_5$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_5$date, \n                                               fish_survey_5$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nfish_survey_5 &lt;- fish_survey_5 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_5)\n\n\n  ObjectID                             GlobalID        CreationDate\n1      992 1866894c-536f-4b75-b0e5-8ce536b1b525 7/9/2024 9:02:05 PM\n2      993 ff14c15a-ea7e-4852-bbb3-40d6c56f4aa8 7/9/2024 9:02:27 PM\n3      994 76f66dbb-c637-4eec-9e6e-979ce0abd679 7/9/2024 9:02:40 PM\n4      995 0117651c-d940-4b69-a695-a2d9af2b802a 7/9/2024 9:02:53 PM\n5      996 016e5763-108f-43a3-b375-d897498f96ef 7/9/2024 9:03:06 PM\n6      997 481842cb-1df5-4af5-baf9-90904594d7df 7/9/2024 9:03:25 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:49:30 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:49:50 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:50:01 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:50:08 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:52:14 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/30/2024 2:52:09 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 07:30       NA  Riffle   Center\n2 jpilchik@contractor.usgs.gov_USGS     NA 07:49       NA  Riffle         \n3 jpilchik@contractor.usgs.gov_USGS     NA 07:57       NA  Riffle   Center\n4 jpilchik@contractor.usgs.gov_USGS     NA 08:08       NA  Riffle    Right\n5 jpilchik@contractor.usgs.gov_USGS     NA 08:18       NA    Pool   Center\n6 jpilchik@contractor.usgs.gov_USGS     NA 08:25       NA  Riffle   Center\n  substrate cover         shade\n1        NA    NA  Fully shaded\n2        NA    NA Mostly shaded\n3        NA    NA              \n4        NA    NA Mostly shaded\n5        NA    NA Mostly shaded\n6        NA    NA Mostly shaded\n                                               Notes amthID undhID dryuID\n1                                                        NA     41     NA\n2                                                        NA     40     NA\n3                                                        NA     34     NA\n4                                                        NA     33     NA\n5 Moved up from where we thought it might have died.     NA     36     NA\n6                                                        NA     27     NA\n   habitatExtra signal   substrateExtra       date brookName         x        y\n1                   NA             Rock 2024-07-09           -72.32447 42.44488\n2  Woody_debris     NA      Rock,Pebble 2024-07-09           -72.32513 42.44510\n3                   NA             Rock 2024-07-09           -72.32645 42.44537\n4 Undercut_bank     NA             Rock 2024-07-09           -72.32624 42.44533\n5                   NA Rock,Pebble,Sand 2024-07-09           -72.32752 42.44626\n6                   NA             Rock 2024-07-09           -72.32780 42.44521\n         dateTime_EST shift\n1 2024-07-09 07:30:00   day\n2 2024-07-09 07:49:00   day\n3 2024-07-09 07:57:00   day\n4 2024-07-09 08:08:00   day\n5 2024-07-09 08:18:00   day\n6 2024-07-09 08:25:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_5, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 6.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_6$date &lt;- as.Date(fish_survey_6$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_6$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_6$date, \n                                               fish_survey_6$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nfish_survey_6 &lt;- fish_survey_6 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_6)\n\n\n  ObjectID                             GlobalID         CreationDate\n1     1212 439f0847-2e86-4422-8f9a-48ab5a182eb4 7/16/2024 2:48:01 PM\n2     1213 7783a0c3-7f49-46f6-ac2f-c1921e3a91ee 7/16/2024 2:48:40 PM\n3     1214 185d4b7c-32bb-4623-a702-721213b76dd1 7/16/2024 2:48:51 PM\n4     1215 f2cc6831-e71a-4cc8-8994-dbbddc6271fe 7/16/2024 2:49:27 PM\n5     1216 15b750cb-30d8-4b84-9d28-0e14f7de132e 7/16/2024 2:51:06 PM\n6     1217 8d5e63b8-6507-45d1-8530-e3a745cf7bf5 7/16/2024 2:53:14 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:27:34 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:27:40 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:27:55 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:28:02 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:34:15 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:34:05 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     31 03:49       NA  Riffle   Center\n2 jpilchik@contractor.usgs.gov_USGS     28 03:58       NA    Pool   Center\n3 jpilchik@contractor.usgs.gov_USGS     26 04:04       NA  Riffle   Center\n4 jpilchik@contractor.usgs.gov_USGS     37 04:05       NA  Riffle   Center\n5 jpilchik@contractor.usgs.gov_USGS     31 05:17       NA  Riffle   Center\n6 jpilchik@contractor.usgs.gov_USGS     28 05:21       NA    Pool   Center\n  substrate cover        shade Notes amthID undhID dryuID habitatExtra signal\n1        NA    NA        Night           NA     NA     NA                  NA\n2        NA    NA        Night           NA     NA     NA                  NA\n3        NA    NA        Night           NA     NA     NA                  NA\n4        NA    NA Fully shaded           NA     NA     NA                  NA\n5        NA    NA Fully shaded           NA     NA     NA                  NA\n6        NA    NA Fully shaded           NA     NA     NA                  NA\n    substrateExtra       date brookName         x        y        dateTime_EST\n1             Rock 2024-07-16           -72.37121 42.44408 2024-07-16 03:49:00\n2         Sand,Mud 2024-07-16           -72.37056 42.44364 2024-07-16 03:58:00\n3             Rock 2024-07-16           -72.37030 42.44345 2024-07-16 04:04:00\n4             Rock 2024-07-16           -72.37018 42.44342 2024-07-16 04:05:00\n5        Rock,Sand 2024-07-16           -72.37132 42.44393 2024-07-16 05:17:00\n6 Rock,Pebble,Sand 2024-07-16           -72.37059 42.44357 2024-07-16 05:21:00\n  shift\n1   day\n2   day\n3   day\n4   day\n5   day\n6   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_6, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 7.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_7$date &lt;- as.Date(fish_survey_7$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_7$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_7$date, \n                                               fish_survey_7$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nfish_survey_7 &lt;- fish_survey_7 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_7)\n\n\n  ObjectID                             GlobalID         CreationDate\n1     1437 f507a07d-bd5d-45ef-a627-b616a46f41cb 7/23/2024 9:37:31 PM\n2     1438 27daf1f4-76e8-41be-839f-5d3acb7af6d4 7/23/2024 9:37:40 PM\n3     1439 73f2f0aa-663a-4e52-a574-570960128ca4 7/23/2024 9:37:52 PM\n4     1440 f9c9dbd5-8ed6-4fb9-9b7e-935f197b14a2 7/23/2024 9:38:01 PM\n5     1441 e9ccf897-54d0-4aa0-abbb-13ede4b69ead 7/23/2024 9:38:11 PM\n6     1442 cc32f645-8242-4a61-b90c-3e8aa387ba2f 7/23/2024 9:41:19 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:37:31 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:37:40 PM\n3 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:37:52 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:38:01 PM\n5 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:38:11 PM\n6 jpilchik@contractor.usgs.gov_USGS 7/23/2024 9:41:19 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 07:28       NA    Pool    Right\n2 jpilchik@contractor.usgs.gov_USGS     NA 07:56       NA                 \n3 jpilchik@contractor.usgs.gov_USGS     NA 08:07       NA  Riffle     Left\n4 jpilchik@contractor.usgs.gov_USGS     NA 08:44       NA    Pool     Left\n5 jpilchik@contractor.usgs.gov_USGS     NA 08:52       NA    Pool    Right\n6 jpilchik@contractor.usgs.gov_USGS     NA 09:06       NA    Pool         \n  substrate cover         shade                                      Notes\n1        NA    NA Mostly shaded                                           \n2        NA    NA                                                     Dead\n3        NA    NA Mostly shaded Very shallow water. Can’t see fish or tag.\n4        NA    NA Mostly shaded                                           \n5        NA    NA  Fully shaded                          Up under cutback.\n6        NA    NA Mostly shaded                              Dead have tag\n  amthID undhID dryuID               habitatExtra signal substrateExtra\n1     NA     NA   39.1               Woody_debris     NA      Rock,Sand\n2     NA     NA   46.1                                NA               \n3     NA     NA   29.1                                NA               \n4     NA     NA   30.1               Woody_debris     NA            Mud\n5     NA     NA   16.0 Woody_debris,Undercut_bank     NA       Mud,Sand\n6     NA     NA   55.0               Woody_debris     NA      Rock,Sand\n        date brookName         x        y        dateTime_EST shift\n1 2024-07-23           -72.50687 42.66812 2024-07-23 07:28:00   day\n2 2024-07-23           -72.50700 42.66827 2024-07-23 07:56:00   day\n3 2024-07-23           -72.50598 42.66837 2024-07-23 08:07:00   day\n4 2024-07-23           -72.50495 42.66817 2024-07-23 08:44:00   day\n5 2024-07-23           -72.50460 42.66775 2024-07-23 08:52:00   day\n6 2024-07-23           -72.50408 42.66603 2024-07-23 09:06:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_7, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 8.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_8$date &lt;- as.Date(fish_survey_8$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_8$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_8$date, \n                                               fish_survey_8$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:30 EST to 9:30 EST\nfish_survey_8 &lt;- fish_survey_8 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_8)\n\n\n  ObjectID                             GlobalID         CreationDate\n1     1668 e6f4c6ce-9cfc-4b76-b760-2b53014e29d4 7/30/2024 2:43:39 PM\n2     1669 8a320870-da39-498d-9ef1-9fe535798efd 7/30/2024 2:43:43 PM\n3     1670 ee332466-79ac-4a50-ab15-caf4b6ed514f 7/30/2024 2:43:47 PM\n4     1671 8fc4d493-8287-4c6c-81c2-52f953e81447 7/30/2024 2:43:50 PM\n5     1672 b1bfebff-03af-4762-826a-559e2e198497 7/30/2024 2:43:54 PM\n6     1673 78b11090-9466-403f-8435-34c832161513 7/30/2024 2:43:57 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:39 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:43 PM\n3 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:47 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:50 PM\n5 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:54 PM\n6 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:57 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     31 04:07       NA  Riffle    Right\n2 jpilchik@contractor.usgs.gov_USGS     26 04:15       NA  Riffle   Center\n3 jpilchik@contractor.usgs.gov_USGS     37 04:16       NA  Riffle   Center\n4 jpilchik@contractor.usgs.gov_USGS     38 04:38       NA     Run    Right\n5 jpilchik@contractor.usgs.gov_USGS     32 04:42       NA    Pool     Left\n6 jpilchik@contractor.usgs.gov_USGS     38 05:25       NA  Riffle     Left\n  substrate cover          shade\n1        NA    NA          Night\n2        NA    NA          Night\n3        NA    NA          Night\n4        NA    NA          Night\n5        NA    NA          Night\n6        NA    NA Lightly shaded\n                                                   Notes amthID undhID dryuID\n1                                                            NA     NA     NA\n2                                                            NA     NA     NA\n3                                                            NA     NA     NA\n4                                                            NA     NA     NA\n5 Dead.found on river left side of pool buried n gravel.     NA     NA     NA\n6                                           May be dead      NA     NA     NA\n  habitatExtra signal substrateExtra       date brookName         x        y\n1                  NA    Pebble,Rock 2024-07-30           -72.37116 42.44418\n2                  NA    Rock,Pebble 2024-07-30           -72.37034 42.44352\n3                  NA    Rock,Pebble 2024-07-30           -72.37032 42.44350\n4                  NA    Rock,Pebble 2024-07-30           -72.37335 42.44441\n5                  NA         Pebble 2024-07-30           -72.37354 42.44406\n6                  NA    Rock,Pebble 2024-07-30           -72.37340 42.44449\n         dateTime_EST shift\n1 2024-07-30 04:07:00   day\n2 2024-07-30 04:15:00   day\n3 2024-07-30 04:16:00   day\n4 2024-07-30 04:38:00   day\n5 2024-07-30 04:42:00   day\n6 2024-07-30 05:25:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_8, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 9.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_9$date &lt;- as.Date(fish_survey_9$date, \n                              format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_9$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_9$date, \n                                               fish_survey_9$time), \n                                         format=\"%Y-%m-%d %H:%M\",\n                                         tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\n# Supplementary tracking at Dry on August 5\nfish_survey_9 &lt;- fish_survey_9 %&gt;%\n  mutate(\n    shift = case_when(\n      # Define shift for August 5, 2024\n      date(dateTime_EST) == ymd(\"2024-08-05\") ~ \"day\",\n      \n      # Define shift for regular tracking schedule for week 9\n      date(dateTime_EST) &gt;= ymd(\"2024-08-06\") & date(dateTime_EST) &lt;= ymd(\"2024-08-09\") \n      & hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n      \n      TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_9)\n\n\n  ObjectID                             GlobalID        CreationDate\n1     1816 d9d2d00f-65d0-4398-8581-11039eb1898b 8/5/2024 6:01:11 PM\n2     1817 68c70af2-6327-436e-acb0-3d50ec8c1916 8/5/2024 6:01:12 PM\n3     1818 3fc8c4e1-6e80-41c3-bd65-a1a5ba023646 8/5/2024 6:01:13 PM\n4     1819 665d4573-6b34-4616-823f-7c93dff46d14 8/6/2024 6:25:20 PM\n5     1820 243151b8-490c-47bd-a3e8-a0ed499da68a 8/6/2024 6:25:27 PM\n6     1821 9665a799-cf88-4052-95e7-6ba5854624af 8/6/2024 6:25:34 PM\n                            Creator            EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/5/2024 6:01:11 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/5/2024 6:01:12 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/5/2024 6:01:13 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/6/2024 6:25:20 PM\n5 jpilchik@contractor.usgs.gov_USGS 8/6/2024 6:25:27 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/6/2024 6:25:34 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 11:06       NA    Pool         \n2 jpilchik@contractor.usgs.gov_USGS     NA 11:35       NA                 \n3 jpilchik@contractor.usgs.gov_USGS     NA 11:37       NA                 \n4 jpilchik@contractor.usgs.gov_USGS     NA 07:41       NA  Riffle   Center\n5 jpilchik@contractor.usgs.gov_USGS     NA 07:47       NA    Pool   Center\n6 jpilchik@contractor.usgs.gov_USGS     NA 07:53       NA    Pool   Center\n  substrate cover          shade\n1        NA    NA Lightly shaded\n2        NA    NA               \n3        NA    NA               \n4        NA    NA  Mostly shaded\n5        NA    NA  Mostly shaded\n6        NA    NA  Mostly shaded\n                                                                             Notes\n1              Bunch of fish swimming around, moving too much to get a good signal\n2 Lost signal, signal was strongest (74) back at the clearing with the pine trees \n3                                                                                 \n4                                                            Same so as last week.\n5                                                                                 \n6                                                                                 \n  amthID undhID dryuID               habitatExtra signal      substrateExtra\n1     NA     NA     49 Woody_debris,Undercut_bank    174 Granule,Pebble,Sand\n2     NA     NA     47                                NA                    \n3     NA     NA     47                                54                    \n4     NA     33     NA               Woody_debris     NA         Pebble,Rock\n5     NA     45     NA                                NA      Pebble,Granule\n6     NA     44     NA               Woody_debris     NA           Rock,Sand\n        date brookName         x        y        dateTime_EST shift\n1 2024-08-05           -72.50352 42.65114 2024-08-05 11:06:00   day\n2 2024-08-05           -72.50353 42.65375 2024-08-05 11:35:00   day\n3 2024-08-05           -72.50367 42.65407 2024-08-05 11:37:00   day\n4 2024-08-06           -72.32640 42.44531 2024-08-06 07:41:00   day\n5 2024-08-06           -72.32773 42.44515 2024-08-06 07:47:00   day\n6 2024-08-06           -72.32803 42.44488 2024-08-06 07:53:00   day\n\n\nCode\n# Write new stream survey csv\nwrite.csv(fish_survey_9, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 10.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_10$date &lt;- as.Date(fish_survey_10$date, \n                               format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_10$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_10$date, \n                                                fish_survey_10$time), \n                                          format=\"%Y-%m-%d %H:%M\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 4:00 EST to 10:00 EST\nfish_survey_10 &lt;- fish_survey_10 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 3 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(fish_survey_10)\n\n\n  ObjectID                             GlobalID          CreationDate\n1     1972 b72ac679-3d32-424a-bdec-33918a8b57a9 8/13/2024 12:20:52 PM\n2     1973 79da97ca-1319-40b9-abcc-1b4c9bbc0d6a 8/13/2024 12:21:18 PM\n3     1974 7e258e2f-2651-455e-8dcd-d12c77ee4db3 8/13/2024 12:21:42 PM\n4     1975 64b7754b-39e1-4748-908f-ad939e74aec0 8/13/2024 12:21:57 PM\n5     1976 d51069c6-45b1-4d05-9e57-d7f894452de7 8/13/2024 12:22:18 PM\n6     1977 e1b92531-a7a3-4dd2-878a-6392228b5911 8/13/2024 12:22:33 PM\n                            Creator            EditDate\n1 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:30:20 PM\n2 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:30:48 PM\n3 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:31:11 PM\n4 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:31:42 PM\n5 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:32:26 PM\n6 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:33:21 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 04:25       NA     Run   Center\n2 jpilchik@contractor.usgs.gov_USGS     NA 04:31       NA     Run   Center\n3 jpilchik@contractor.usgs.gov_USGS     NA 04:32       NA  Riffle   Center\n4 jpilchik@contractor.usgs.gov_USGS     NA 04:34       NA     Run   Center\n5 jpilchik@contractor.usgs.gov_USGS     NA 04:41       NA  Riffle   Center\n6 jpilchik@contractor.usgs.gov_USGS     NA 05:15       NA     Run   Center\n  substrate cover        shade Notes amthID undhID dryuID habitatExtra signal\n1        NA    NA        Night           60     NA     NA                  NA\n2        NA    NA        Night           18     NA     NA                  NA\n3        NA    NA        Night           14     NA     NA                  NA\n4        NA    NA        Night           20     NA     NA Woody_debris     NA\n5        NA    NA        Night           19     NA     NA                  NA\n6        NA    NA Fully shaded           60     NA     NA                  NA\n     substrateExtra       date brookName         x        y        dateTime_EST\n1         Sand,Rock 2024-08-13    BUFFAM -72.45838 42.38205 2024-08-13 04:25:00\n2 Sand,Boulder,Rock 2024-08-13    BUFFAM -72.45979 42.38119 2024-08-13 04:31:00\n3      Rock,Boulder 2024-08-13    BUFFAM -72.46000 42.38136 2024-08-13 04:32:00\n4           Boulder 2024-08-13    HARRIS -72.46033 42.38118 2024-08-13 04:34:00\n5              Rock 2024-08-13  AMETHYST -72.46088 42.38150 2024-08-13 04:41:00\n6         Sand,Rock 2024-08-13    BUFFAM -72.45866 42.38218 2024-08-13 05:15:00\n  shift\n1   day\n2   day\n3   day\n4   day\n5   day\n6   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_10, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 11.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_11$date &lt;- as.Date(fish_survey_11$date, \n                               format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_11$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_11$date, \n                                                fish_survey_11$time), \n                                          format=\"%Y-%m-%d %H:%M\",\n                                          tz = \"EST\")\n\n# Add Shift column \n# All shifts in week 11 were day shifts\nfish_survey_11 &lt;- fish_survey_11 %&gt;%\n  mutate(shift = \"day\")\n\n# Display the first few rows to check the result\nhead(fish_survey_11)\n\n\n  ObjectID                             GlobalID         CreationDate\n1     2114 dd4a5c43-d9b6-473c-b2b3-af38471d133e 8/20/2024 6:43:20 PM\n2     2115 00c2ea5e-eaa1-4941-9493-1adf5bce46bc 8/20/2024 6:43:24 PM\n3     2116 f0d7dc91-fe79-4891-994f-0ddfca3614d3 8/20/2024 6:43:27 PM\n4     2117 a25b7934-f398-45b2-be8b-5d8ad0da1e33 8/20/2024 6:43:30 PM\n5     2118 9287dd3b-9467-40ce-ba4c-c892ce58722b 8/20/2024 6:43:34 PM\n6     2119 8d8801d8-ec2e-41d5-a6c5-008df12aeba8 8/20/2024 6:43:37 PM\n                            Creator            EditDate\n1 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:27:06 PM\n2 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:27:27 PM\n3 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:27:59 PM\n4 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:28:31 PM\n5 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:29:18 PM\n6 jpilchik@contractor.usgs.gov_USGS 9/6/2024 2:29:54 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 09:10       NA  Riffle   Center\n2 jpilchik@contractor.usgs.gov_USGS     NA 09:39       NA  Riffle     Left\n3 jpilchik@contractor.usgs.gov_USGS     NA 09:54       NA  Riffle    Right\n4 jpilchik@contractor.usgs.gov_USGS     NA 10:40       NA  Riffle   Center\n5 jpilchik@contractor.usgs.gov_USGS     NA 11:03       NA  Riffle     Left\n6 jpilchik@contractor.usgs.gov_USGS     NA 11:41       NA     Run   Center\n  substrate cover        shade             Notes amthID undhID dryuID\n1        NA    NA Fully shaded                       19     NA     NA\n2        NA    NA Fully shaded                       20     NA     NA\n3        NA    NA Fully shaded                       14     NA     NA\n4        NA    NA Fully shaded                       18     NA     NA\n5        NA    NA Fully shaded                       62     NA     NA\n6        NA    NA Fully shaded Recollected alive     60     NA     NA\n  habitatExtra signal       substrateExtra       date brookName         x\n1                  NA                 Rock 2024-08-20  AMETHYST -72.46090\n2                  NA              Boulder 2024-08-20    HARRIS -72.46016\n3                  NA            Rock,Sand 2024-08-20    BUFFAM -72.46000\n4                  NA Rock,Boulder,Granule 2024-08-20    BUFFAM -72.45993\n5 Woody_debris     NA         Boulder,Rock 2024-08-20    HARRIS -72.45784\n6                  NA            Rock,Sand 2024-08-20    BUFFAM -72.45856\n         y        dateTime_EST shift\n1 42.38157 2024-08-20 09:10:00   day\n2 42.38116 2024-08-20 09:39:00   day\n3 42.38126 2024-08-20 09:54:00   day\n4 42.38124 2024-08-20 10:40:00   day\n5 42.38062 2024-08-20 11:03:00   day\n6 42.38206 2024-08-20 11:41:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_11, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey data\nfish_survey_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTrackingData/Fish Survey Week 12.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nfish_survey_12$date &lt;- as.Date(fish_survey_12$date, \n                               format = \"%m/%d/%Y\")\n\n# Combine the date and time into a DateTime column\nfish_survey_12$dateTime_EST &lt;- as.POSIXct(paste(fish_survey_12$date, \n                                                fish_survey_12$time), \n                                          format=\"%Y-%m-%d %H:%M\",\n                                          tz = \"EST\")\n\n# Add Shift column\n# All shifts in week 12 were day shifts\nfish_survey_12 &lt;- fish_survey_12 %&gt;%\n  mutate(shift = \"day\")\n\n# Display the first few rows to check the result\nhead(fish_survey_12)\n\n\n  ObjectID                             GlobalID         CreationDate\n1     2138 c005d5be-a2a2-4620-b78f-2a8dcd8b8a20 8/27/2024 5:53:28 PM\n2     2139 5a9197f1-6f45-4c15-be8a-83f520a60fd4 8/27/2024 5:54:59 PM\n3     2140 c21e0b19-3ed1-4961-8f16-f1f58cf3949c 8/27/2024 5:55:06 PM\n4     2141 fdfdec83-b7fe-4c6b-b9ed-f678e7700058 8/29/2024 5:35:15 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/29/2024 6:57:37 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/29/2024 6:57:27 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/29/2024 6:57:54 PM\n4 jpilchik@contractor.usgs.gov_USGS 8/30/2024 3:59:02 PM\n                             Editor dckyID  time location habitat position\n1 jpilchik@contractor.usgs.gov_USGS     NA 09:41       NA    Pool    Right\n2 jpilchik@contractor.usgs.gov_USGS     NA 10:32       NA    Pool   Center\n3 jpilchik@contractor.usgs.gov_USGS     NA 12:19       NA    Pool   Center\n4 jpilchik@contractor.usgs.gov_USGS     NA 11:11       NA     Run   Center\n  substrate cover         shade\n1        NA    NA  Fully shaded\n2        NA    NA Mostly shaded\n3        NA    NA Mostly shaded\n4        NA    NA  Fully shaded\n                                                                                                         Notes\n1                                                                             Unsuccessful at finding shed tag\n2                                                                             Unsuccessful at finding shed tag\n3                        Unsuccessful at finding shed tag. It is most likely located in a hole under this rock\n4 Fish found with scarring at Dickey that indicates it was potentially tagged. Unknown which fish it could be.\n  amthID undhID dryuID habitatExtra signal              substrateExtra\n1     NA     45     NA           NA     NA                   Sand,Rock\n2     NA     44     NA           NA     NA                   Sand,Rock\n3     NA     35     NA           NA     NA Boulder,Rock,Granule,Pebble\n4     NA     NA     NA           NA     NA                 Rock,Pebble\n        date brookName         x        y        dateTime_EST shift\n1 2024-08-27        NA -72.32730 42.44535 2024-08-27 09:41:00   day\n2 2024-08-27        NA -72.32805 42.44492 2024-08-27 10:32:00   day\n3 2024-08-27        NA -72.32929 42.44359 2024-08-27 12:19:00   day\n4 2024-08-29        NA -72.36866 42.44182 2024-08-29 11:11:00   day\n\n\nCode\n# Write new fish survey csv\nwrite.csv(fish_survey_12, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_12.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define file names\nfish_file_names &lt;- c(\"fish_survey_1.csv\", \"fish_survey_2.csv\", \"fish_survey_3.csv\", \"fish_survey_4.csv\", \n                     \"fish_survey_5.csv\", \"fish_survey_6.csv\", \"fish_survey_7.csv\", \"fish_survey_8.csv\", \n                     \"fish_survey_9.csv\", \"fish_survey_10.csv\", \"fish_survey_11.csv\", \"fish_survey_12.csv\")\n\n# Define a lookup table for stream names\nstream_name_lookup &lt;- data.frame(\n  abbreviation = c(\"dcky\", \"amth\", \"undh\", \"dryu\"),  # List all abbreviations\n  full_name = c(\"DICKEY\", \"AMETHYST\", \"UNDERHILL\", \"DRY UPPER\")  # Corresponding full names\n)\n\n# Create an empty list to store the processed datasets\nprocessed_fish_data_list &lt;- list()\n\n# Loop through each fish survey file\nfor (file_name in fish_file_names) {\n  # Read in the fish survey data\n  raw_tracking_data &lt;- read.csv(file_name)\n  \n  # Step 1: Process the data\n  tracking_data &lt;- raw_tracking_data %&gt;%\n    \n    # Step 2: Select specific columns\n    select(dateTime_EST, shift, dckyID, amthID, undhID, dryuID, signal, habitat, habitatExtra, position, substrate, substrateExtra, shade, x, y, Notes, brookName) %&gt;%\n    \n    # Step 3: Pivot longer to create 'river' and 'tagID' columns\n    pivot_longer(\n      cols = c(dckyID, amthID, undhID, dryuID),  # Columns to combine\n      names_to = \"river\",                        # Create a new column 'river' from column names\n      values_to = \"tagID\",                       # Combine the tag IDs into a new column 'tagID'\n      values_drop_na = FALSE                     # Ensure NA values are retained\n    ) %&gt;%\n    \n    # Step 4: Create a new 'riverName' column and extract the river name and ID number\n    mutate(\n      riverName = river,                                    # Copy the river name\n      #tagID = as.numeric(gsub(\"[^0-9]\", \"\", tagID)),       # Extract the numeric part as tagID\n      tagID = ifelse(is.na(tagID), NA, as.numeric(tagID)),  # Convert tagID to numeric, keep NA values\n      river = gsub(\"ID\", \"\", river)                         # Remove 'ID' to keep only the river name\n    ) %&gt;%\n    \n    # Step 5: Join with the lookup table to replace abbreviations with full names\n    left_join(stream_name_lookup, by = c(\"river\" = \"abbreviation\")) %&gt;%\n    mutate(\n      river = coalesce(full_name, river)  # Replace Brook with full_name, if available\n    ) %&gt;%\n    select(-full_name) %&gt;%  # Remove the full_name column as it's no longer needed\n    \n    # Step 6: Combine the river and brookName logic\n    mutate(\n      river = ifelse(brookName %in% c(\"BUFFAM\", \"HARRIS\"), brookName, river)  # Override river with brookName if Buffam or Harris\n    ) %&gt;%\n    \n    # Step 7: Rename columns\n    rename(\n      fishNotes = Notes,\n      lon = x,\n      lat = y,\n      trackedTime_EST = dateTime_EST,\n      power = signal\n    ) %&gt;%\n    \n    ##############################################################\n    \n    # Step 8: Filter data to keep only rows where lat &gt; 1\n    filter(lat &gt; 1, !is.na(tagID)) %&gt;%\n    \n    # Step _: Filter data to keep rows with lat &gt; 1 or lat is NA\n    #filter(lat &gt; 1 | is.na(lat)) %&gt;%\n    \n    #############################################################\n    \n    # Step _: Remove unnecessary columns\n    #select(-c(riverName, brookName)) %&gt;%\n    \n    # Step 9: Select specific columns\n    select(trackedTime_EST, river, shift, tagID, power, habitat, habitatExtra, position, substrate, substrateExtra, shade, lon, lat, fishNotes) %&gt;%\n    \n    #############################################################\n    \n    # Step 10: Add a source column\n    mutate(source = \"iPad\")\n  \n  # Store the processed data in the list\n  processed_fish_data_list[[file_name]] &lt;- tracking_data\n  \n  # Overwrite the original file with the processed data\n  write.csv(tracking_data, file_name, row.names = FALSE)\n}\n\n# Display the first few rows of each processed dataset\nfor (i in 1:length(processed_fish_data_list)) {\n  cat(\"\\nData for\", fish_file_names[i], \":\\n\")\n  print(head(processed_fish_data_list[[i]]))\n}\n\n\n\nData for fish_survey_1.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river    shift tagID power habitat habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 2024-06-11 05:57:00 AMETHYST day      59    NA Riffle  \"\"           Center  \n2 2024-06-11 06:08:00 AMETHYST day      60    NA Riffle  \"\"           Center  \n3 2024-06-11 06:15:00 BUFFAM   day      19    NA Riffle  \"\"           Center  \n4 2024-06-11 06:19:00 HARRIS   day      20    NA Run     \"\"           Left    \n5 2024-06-11 06:28:00 HARRIS   day      57    NA Run     \"\"           Left    \n6 2024-06-11 06:34:00 HARRIS   day      12    NA Glide   \"\"           Center  \n# ℹ 7 more variables: substrate &lt;chr&gt;, substrateExtra &lt;lgl&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_2.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river  shift tagID power habitat habitatExtra    position\n  &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;           &lt;chr&gt;   \n1 2024-06-17 11:33:00 DICKEY day      31    NA Pool    \"\"              Center  \n2 2024-06-17 11:57:00 DICKEY day      46    NA Run     \"\"              Right   \n3 2024-06-17 11:59:00 DICKEY day      29    NA Riffle  \"Woody_debris\"  Left    \n4 2024-06-17 12:10:00 DICKEY day      26    NA Run     \"Undercut_bank\" Right   \n5 2024-06-17 12:47:00 DICKEY day      28    NA Pool    \"\"              Left    \n6 2024-06-17 12:49:00 DICKEY day      37    NA Pool    \"\"              Right   \n# ℹ 7 more variables: substrate &lt;chr&gt;, substrateExtra &lt;lgl&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_3.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river     shift tagID power habitat habitatExtra  position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;   \n1 2024-06-25 05:59:00 DRY UPPER day      55    NA Pool    Woody_debris  Center  \n2 2024-06-25 06:02:00 DRY UPPER day      16    NA Pool    Woody_debris  Right   \n3 2024-06-25 06:07:00 DRY UPPER day      53    NA Pool    Woody_debris  Right   \n4 2024-06-25 06:11:00 DRY UPPER day      22    NA Pool    Root_bundle,… Left    \n5 2024-06-25 06:20:00 DRY UPPER day      21    NA Pool    Woody_debris… Right   \n6 2024-06-25 06:21:00 DRY UPPER day      25    NA Pool    Undercut_ban… Right   \n# ℹ 7 more variables: substrate &lt;chr&gt;, substrateExtra &lt;lgl&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_4.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river     shift tagID power habitat habitatExtra  position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;   \n1 2024-06-30 04:39:00 DRY UPPER day      22    NA Pool    Root_bundle   Left    \n2 2024-06-30 04:42:00 DRY UPPER day      16    NA Pool    Woody_debris  Right   \n3 2024-06-30 04:43:00 DRY UPPER day      55    NA Pool    Woody_debris  Right   \n4 2024-06-30 04:50:00 DRY UPPER day      21    NA Pool    Woody_debris… Right   \n5 2024-06-30 04:51:00 DRY UPPER day      25    NA Pool    Undercut_ban… Right   \n6 2024-06-30 04:51:00 DRY UPPER day      24    NA Pool    Undercut_ban… Right   \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_5.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river     shift tagID power habitat habitatExtra  position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;   \n1 2024-07-09 07:30:00 UNDERHILL day      41    NA Riffle  \"\"            \"Center\"\n2 2024-07-09 07:49:00 UNDERHILL day      40    NA Riffle  \"Woody_debri… \"\"      \n3 2024-07-09 07:57:00 UNDERHILL day      34    NA Riffle  \"\"            \"Center\"\n4 2024-07-09 08:08:00 UNDERHILL day      33    NA Riffle  \"Undercut_ba… \"Right\" \n5 2024-07-09 08:18:00 UNDERHILL day      36    NA Pool    \"\"            \"Center\"\n6 2024-07-09 08:25:00 UNDERHILL day      27    NA Riffle  \"\"            \"Center\"\n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_6.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river  shift tagID power habitat habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 2024-07-16 03:49:00 DICKEY day      31    NA Riffle  \"\"           Center  \n2 2024-07-16 03:58:00 DICKEY day      28    NA Pool    \"\"           Center  \n3 2024-07-16 04:04:00 DICKEY day      26    NA Riffle  \"\"           Center  \n4 2024-07-16 04:05:00 DICKEY day      37    NA Riffle  \"\"           Center  \n5 2024-07-16 05:17:00 DICKEY day      31    NA Riffle  \"\"           Center  \n6 2024-07-16 05:21:00 DICKEY day      28    NA Pool    \"\"           Center  \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_7.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river     shift tagID power habitat  habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 2024-07-23 07:28:00 DRY UPPER day    39.1    NA \"Pool\"   \"Woody_debr… \"Right\" \n2 2024-07-23 07:56:00 DRY UPPER day    46.1    NA \"\"       \"\"           \"\"      \n3 2024-07-23 08:07:00 DRY UPPER day    29.1    NA \"Riffle\" \"\"           \"Left\"  \n4 2024-07-23 08:44:00 DRY UPPER day    30.1    NA \"Pool\"   \"Woody_debr… \"Left\"  \n5 2024-07-23 08:52:00 DRY UPPER day    16      NA \"Pool\"   \"Woody_debr… \"Right\" \n6 2024-07-23 09:06:00 DRY UPPER day    55      NA \"Pool\"   \"Woody_debr… \"\"      \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_8.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river  shift tagID power habitat habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 2024-07-30 04:07:00 DICKEY day      31    NA Riffle  \"\"           Right   \n2 2024-07-30 04:15:00 DICKEY day      26    NA Riffle  \"\"           Center  \n3 2024-07-30 04:16:00 DICKEY day      37    NA Riffle  \"\"           Center  \n4 2024-07-30 04:38:00 DICKEY day      38    NA Run     \"\"           Right   \n5 2024-07-30 04:42:00 DICKEY day      32    NA Pool    \"\"           Left    \n6 2024-07-30 05:25:00 DICKEY day      38    NA Riffle  \"\"           Left    \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_9.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river     shift tagID power habitat  habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 2024-08-05 11:06:00 DRY UPPER day      49   174 \"Pool\"   \"Woody_debr… \"\"      \n2 2024-08-05 11:35:00 DRY UPPER day      47    NA \"\"       \"\"           \"\"      \n3 2024-08-05 11:37:00 DRY UPPER day      47    54 \"\"       \"\"           \"\"      \n4 2024-08-06 07:41:00 UNDERHILL day      33    NA \"Riffle\" \"Woody_debr… \"Center\"\n5 2024-08-06 07:47:00 UNDERHILL day      45    NA \"Pool\"   \"\"           \"Center\"\n6 2024-08-06 07:53:00 UNDERHILL day      44    NA \"Pool\"   \"Woody_debr… \"Center\"\n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_10.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river    shift tagID power habitat habitatExtra   position\n  &lt;chr&gt;               &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;   \n1 2024-08-13 04:25:00 BUFFAM   day      60    NA Run     \"\"             Center  \n2 2024-08-13 04:31:00 BUFFAM   day      18    NA Run     \"\"             Center  \n3 2024-08-13 04:32:00 BUFFAM   day      14    NA Riffle  \"\"             Center  \n4 2024-08-13 04:34:00 HARRIS   day      20    NA Run     \"Woody_debris\" Center  \n5 2024-08-13 04:41:00 AMETHYST day      19    NA Riffle  \"\"             Center  \n6 2024-08-13 05:15:00 BUFFAM   day      60    NA Run     \"\"             Center  \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_11.csv :\n# A tibble: 6 × 15\n  trackedTime_EST     river    shift tagID power habitat habitatExtra   position\n  &lt;chr&gt;               &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;   \n1 2024-08-20 09:10:00 AMETHYST day      19 NA    Riffle  \"\"             Center  \n2 2024-08-20 09:39:00 HARRIS   day      20 NA    Riffle  \"\"             Left    \n3 2024-08-20 09:54:00 BUFFAM   day      14 NA    Riffle  \"\"             Right   \n4 2024-08-20 10:40:00 BUFFAM   day      18 NA    Riffle  \"\"             Center  \n5 2024-08-20 11:03:00 HARRIS   day      62 NA    Riffle  \"Woody_debris\" Left    \n6 2024-08-20 11:41:00 BUFFAM   day      60 NA    Run     \"\"             Center  \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;\n\nData for fish_survey_12.csv :\n# A tibble: 3 × 15\n  trackedTime_EST     river     shift tagID power habitat habitatExtra position\n  &lt;chr&gt;               &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;lgl&gt;        &lt;chr&gt;   \n1 2024-08-27 09:41:00 UNDERHILL day      45 NA    Pool    NA           Right   \n2 2024-08-27 10:32:00 UNDERHILL day      44 NA    Pool    NA           Center  \n3 2024-08-27 12:19:00 UNDERHILL day      35 NA    Pool    NA           Center  \n# ℹ 7 more variables: substrate &lt;lgl&gt;, substrateExtra &lt;chr&gt;, shade &lt;chr&gt;,\n#   lon &lt;dbl&gt;, lat &lt;dbl&gt;, fishNotes &lt;chr&gt;, source &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#making-flow-tracker-file-datasets-by-week",
    "href": "creatingMyDatasheet.html#making-flow-tracker-file-datasets-by-week",
    "title": "2  Creating my Datasheet",
    "section": "2.3 Making Flow Tracker File Datasets by Week",
    "text": "2.3 Making Flow Tracker File Datasets by Week\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_1_directory) {\n  week_1_files &lt;- list.files(path = week_1_directory, recursive = TRUE, full.names = TRUE)\n  return(week_1_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  # Rename columns\n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_1_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week1\"\n\n# Find all files in the week 1 directory\nweek_1_files &lt;- find_files(week_1_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_1 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_1_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_1 &lt;- bind_rows(flow_tracker_1, file_data)\n}\n\n# Standardize site names\nflow_tracker_1 &lt;- flow_tracker_1 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_1 &lt;- flow_tracker_1 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_1)\n\n\n         localEndTime     river totalDischarge\n1 2024-06-11 09:32:26    BUFFAM           1.49\n2 2024-06-11 21:26:53    BUFFAM           0.02\n3 2024-06-13 19:59:00    DICKEY           1.35\n4 2024-06-14 09:57:28 DRY UPPER           0.02\n5 2024-06-14 19:21:39 DRY UPPER           0.65\n6 2024-06-11 10:42:47    HARRIS           0.07\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_1, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_2_directory) {\n  week_2_files &lt;- list.files(path = week_2_directory, recursive = TRUE, full.names = TRUE)\n  return(week_2_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_2_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week2\"\n\n# Find all files in the week 2 directory\nweek_2_files &lt;- find_files(week_2_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_2 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_2_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_2 &lt;- bind_rows(flow_tracker_2, file_data)\n}\n\n# Standardize site names\nflow_tracker_2 &lt;- flow_tracker_2 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_2 &lt;- flow_tracker_2 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_2)\n\n\n         localEndTime     river totalDischarge\n1 2024-06-18 16:48:45    BUFFAM           0.01\n2 2024-06-19 02:07:27    BUFFAM           0.02\n3 2024-06-17 12:35:22    DICKEY           0.03\n4 2024-06-18 02:35:29    DICKEY           1.49\n5 2024-06-19 12:36:08 DRY UPPER           0.02\n6 2024-06-20 00:32:19 DRY UPPER           0.30\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_2, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_3_directory) {\n  week_3_files &lt;- list.files(path = week_3_directory, recursive = TRUE, full.names = TRUE)\n  return(week_3_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_3_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week3\"\n\n# Find all files in the week 3 directory\nweek_3_files &lt;- find_files(week_3_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_3 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_3_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_3 &lt;- bind_rows(flow_tracker_3, file_data)\n}\n\n# Standardize site names\nflow_tracker_3 &lt;- flow_tracker_3 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_3 &lt;- flow_tracker_3 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_3)\n\n\n         localEndTime     river totalDischarge\n1 2024-06-26 10:42:10    BUFFAM           0.02\n2 2024-06-26 17:51:16    BUFFAM           0.02\n3 2024-06-28 09:44:29    DICKEY           0.03\n4 2024-06-28 18:41:46    DICKEY           1.07\n5 2024-06-25 07:21:55 DRY UPPER           0.03\n6 2024-06-25 19:19:38 DRY UPPER           0.57\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_3, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_4_directory) {\n  week_4_files &lt;- list.files(path = week_4_directory, recursive = TRUE, full.names = TRUE)\n  return(week_4_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_4_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week4\"\n\n# Find all files in the week 4 directory\nweek_4_files &lt;- find_files(week_4_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_4 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_4_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_4 &lt;- bind_rows(flow_tracker_4, file_data)\n}\n\n# Standardize site names\nflow_tracker_4 &lt;- flow_tracker_4 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_4 &lt;- flow_tracker_4 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_4)\n\n\n         localEndTime     river totalDischarge\n1 2024-07-02 04:11:20    BUFFAM           0.02\n2 2024-07-02 17:28:34    BUFFAM           0.01\n3 2024-07-01 04:39:46    DICKEY           1.77\n4 2024-07-01 18:42:29    DICKEY           1.34\n5 2024-06-30 05:23:29 DRY UPPER           0.33\n6 2024-06-30 14:19:58 DRY UPPER           0.01\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_4, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_5_directory) {\n  week_5_files &lt;- list.files(path = week_5_directory, recursive = TRUE, full.names = TRUE)\n  return(week_5_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_5_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week5\"\n\n# Find all files in the week 5 directory\nweek_5_files &lt;- find_files(week_5_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_5 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_5_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_5 &lt;- bind_rows(flow_tracker_5, file_data)\n}\n\n# Standardize site names\nflow_tracker_5 &lt;- flow_tracker_5 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_5 &lt;- flow_tracker_5 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_5)\n\n\n         localEndTime     river totalDischarge\n1 2024-07-11 11:21:40    BUFFAM           1.19\n2 2024-07-11 12:00:06    BUFFAM           0.04\n3 2024-07-11 18:15:24    BUFFAM           1.06\n4 2024-07-10 08:31:15    DICKEY           0.07\n5 2024-07-10 18:15:15    DICKEY           2.58\n6 2024-07-12 08:03:32 DRY UPPER           0.00\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_5, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_6_directory) {\n  week_6_files &lt;- list.files(path = week_6_directory, recursive = TRUE, full.names = TRUE)\n  return(week_6_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_6_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week6\"\n\n# Find all files in the week 6 directory\nweek_6_files &lt;- find_files(week_6_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_6 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_6_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_6 &lt;- bind_rows(flow_tracker_6, file_data)\n}\n\n# Standardize site names\nflow_tracker_6 &lt;- flow_tracker_6 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_6 &lt;- flow_tracker_6 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_6)\n\n\n         localEndTime     river totalDischarge\n1 2024-07-17 04:35:30    BUFFAM           1.69\n2 2024-07-17 14:14:36    BUFFAM           1.12\n3 2024-07-16 05:02:37    DICKEY           1.17\n4 2024-07-16 14:29:54    DICKEY          -1.58\n5 2024-07-18 04:41:46 DRY UPPER           1.68\n6 2024-07-18 14:02:49 DRY UPPER           0.60\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_6, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_7_directory) {\n  week_7_files &lt;- list.files(path = week_7_directory, recursive = TRUE, full.names = TRUE)\n  return(week_7_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_7_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week7\"\n\n# Find all files in the week 7 directory\nweek_7_files &lt;- find_files(week_7_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_7 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_7_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_7 &lt;- bind_rows(flow_tracker_7, file_data)\n}\n\n# Standardize site names\nflow_tracker_7 &lt;- flow_tracker_7 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_7 &lt;- flow_tracker_7 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_7)\n\n\n         localEndTime     river totalDischarge\n1 2024-07-25 12:08:40    BUFFAM           0.76\n2 2024-07-25 18:12:05    BUFFAM           0.02\n3 2024-07-24 10:50:19    DICKEY           1.79\n4 2024-07-24 18:21:54    DICKEY           1.65\n5 2024-07-23 08:27:20 DRY UPPER           0.13\n6 2024-07-23 18:09:40 DRY UPPER           0.16\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_7, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_8_directory) {\n  week_8_files &lt;- list.files(path = week_8_directory, recursive = TRUE, full.names = TRUE)\n  return(week_8_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_8_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week8\"\n\n# Find all files in the week 8 directory\nweek_8_files &lt;- find_files(week_8_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_8 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_8_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_8 &lt;- bind_rows(flow_tracker_8, file_data)\n}\n\n# Standardize site names\nflow_tracker_8 &lt;- flow_tracker_8 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_8 &lt;- flow_tracker_8 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_8)\n\n\n         localEndTime     river totalDischarge\n1 2024-07-31 04:44:54    BUFFAM           0.54\n2 2024-07-31 13:43:07    BUFFAM           0.02\n3 2024-07-30 04:50:14    DICKEY           1.13\n4 2024-07-30 13:49:04    DICKEY           0.99\n5 2024-08-02 04:30:04 DRY UPPER           0.14\n6 2024-08-02 16:15:02 DRY UPPER           0.09\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_8, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_9_directory) {\n  week_9_files &lt;- list.files(path = week_9_directory, recursive = TRUE, full.names = TRUE)\n  return(week_9_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_9_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week9\"\n\n# Find all files in the week 9 directory\nweek_9_files &lt;- find_files(week_9_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_9 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_9_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_9 &lt;- bind_rows(flow_tracker_9, file_data)\n}\n\n# Standardize site names\nflow_tracker_9 &lt;- flow_tracker_9 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_9 &lt;- flow_tracker_9 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_9)\n\n\n         localEndTime     river totalDischarge\n1 2024-08-08 08:25:54    BUFFAM           0.06\n2 2024-08-08 17:48:04    BUFFAM          -2.36\n3 2024-08-09 10:56:13    DICKEY           0.14\n4 2024-08-07 08:20:43 DRY UPPER           0.25\n5 2024-08-07 20:19:58 DRY UPPER          -0.09\n6 2024-08-08 09:31:11    HARRIS           5.79\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_9, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_10_directory) {\n  week_10_files &lt;- list.files(path = week_10_directory, recursive = TRUE, full.names = TRUE)\n  return(week_10_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_10_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week10\"\n\n# Find all files in the week 10 directory\nweek_10_files &lt;- find_files(week_10_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_10 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_10_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_10 &lt;- bind_rows(flow_tracker_10, file_data)\n}\n\n# Standardize site names\nflow_tracker_10 &lt;- flow_tracker_10 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_10 &lt;- flow_tracker_10 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_10)\n\n\n         localEndTime     river totalDischarge\n1 2024-08-13 04:57:46    BUFFAM           1.22\n2 2024-08-13 18:18:44    BUFFAM           0.95\n3 2024-08-15 05:32:32    DICKEY           1.69\n4 2024-08-15 15:12:35    DICKEY           1.40\n5 2024-08-16 05:22:45 DRY UPPER           0.15\n6 2024-08-16 14:38:49 DRY UPPER           0.08\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_10, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_11_directory) {\n  week_11_files &lt;- list.files(path = week_11_directory, recursive = TRUE, full.names = TRUE)\n  return(week_11_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_11_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week11\"\n\n# Find all files in the week 11 directory\nweek_11_files &lt;- find_files(week_11_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_11 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_11_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_11 &lt;- bind_rows(flow_tracker_11, file_data)\n}\n\n# Standardize site names\nflow_tracker_11 &lt;- flow_tracker_11 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_11 &lt;- flow_tracker_11 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_11)\n\n\n         localEndTime     river totalDischarge\n1 2024-08-20 11:41:46    BUFFAM           3.53\n2 2024-08-23 13:38:55    BUFFAM           0.82\n3 2024-08-22 09:12:22       DRY           3.65\n4 2024-08-20 09:56:27    HARRIS          13.48\n5 2024-08-23 13:17:11    HARRIS           3.87\n6 2024-08-21 09:25:52 UNDERHILL           1.21\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_11, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_11.csv\",\n          row.names = FALSE)\n\n\n\n\nCode\n# Define a function to search for files\nfind_files &lt;- function(week_12_directory) {\n  week_12_files &lt;- list.files(path = week_12_directory, recursive = TRUE, full.names = TRUE)\n  return(week_12_files)\n}\n\n# Function to extract the required values from a single file and convert only Fahrenheit (°F) to Celsius\nextract_values &lt;- function(file_path) {\n  \n  # Read the csv file\n  df &lt;- read.csv(file_path, header = FALSE, stringsAsFactors = FALSE)\n  colnames(df) &lt;- c(\"Column1\", \"Column2\", \"Column3\")\n  \n  # Extract values\n  local_end_time &lt;- df %&gt;% filter(Column1 == \"Local_End_Time\") %&gt;% select(Column3) %&gt;% pull()\n  site_name &lt;- df %&gt;% filter(Column1 == \"Site_Name\") %&gt;% select(Column3) %&gt;% pull()\n  total_discharge &lt;- df %&gt;% filter(Column1 == \"Total_Discharge\") %&gt;% select(Column3) %&gt;% pull()\n  \n  # Extract the temperature value and unit\n  #mean_temp_value &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column3) %&gt;% pull()\n  #temp_unit &lt;- df %&gt;% filter(Column1 == \"Mean_Temp\") %&gt;% select(Column2) %&gt;% pull()\n\n  # Convert only if the unit is Fahrenheit (\"°F\")\n  #if (temp_unit == \"°F\") {\n    #mean_temp_value &lt;- (as.numeric(mean_temp_value) - 32) * 5 / 9\n  #} else {\n    #mean_temp_value &lt;- as.numeric(mean_temp_value)  # Ensure it's numeric for Celsius values or NA\n  #}\n  \n  # Round values to 2 decimal places\n  #mean_temp_value &lt;- round(mean_temp_value, 2)\n  total_discharge &lt;- round(as.numeric(total_discharge), 2)\n  \n  data.frame(\n    localEndTime = local_end_time,\n    river = site_name,\n    totalDischarge = as.numeric(total_discharge),  # Ensure numeric type\n    #meanTemp = mean_temp_value,  # Already handled as numeric\n    stringsAsFactors = FALSE\n  )\n}\n\nweek_12_directory &lt;- \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/FlowTracker/FlowTrackerFiles/TAMEflow/Week12\"\n\n# Find all files in the week 12 directory\nweek_12_files &lt;- find_files(week_12_directory)\n\n# Initialize the result dataframe with the correct data types\nflow_tracker_12 &lt;- data.frame(\n  localEndTime = character(),\n  river = character(),\n  totalDischarge = numeric(),  # Initialize as numeric\n  #meanTemp = numeric(),  # Initialize as numeric\n  stringsAsFactors = FALSE\n)\n\n# Loop through all files and extract values\nfor (file in week_12_files) {\n  file_data &lt;- extract_values(file)\n  flow_tracker_12 &lt;- bind_rows(flow_tracker_12, file_data)\n}\n\n# Standardize site names\nflow_tracker_12 &lt;- flow_tracker_12 %&gt;%\n  mutate(river = ifelse(grepl(\"buff\", river, ignore.case = TRUE), \"BUFFAM\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dryu\", river, ignore.case = TRUE), \"DRY UPPER\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"harr\", river, ignore.case = TRUE), \"HARRIS\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"undh\", river, ignore.case = TRUE), \"UNDERHILL\", river)) %&gt;%\n  mutate(river = ifelse(grepl(\"dcky\", river, ignore.case = TRUE), \"DICKEY\", river))\n\n#####################################################################################\n\n# Remove rows with repeating Total_Discharge values\nflow_tracker_12 &lt;- flow_tracker_12 %&gt;% \n  distinct(localEndTime, .keep_all = TRUE)\n\n#####################################################################################\n\n# Display the first few rows to check the result\nhead(flow_tracker_12)\n\n\n         localEndTime     river totalDischarge\n1 2024-08-29 10:21:54    DICKEY           0.03\n2 2024-08-27 10:16:23 UNDERHILL           0.03\n\n\nCode\n# Write the final CSV file\nwrite.csv(flow_tracker_12, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_12.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-flow-tracker-files",
    "href": "creatingMyDatasheet.html#preparing-flow-tracker-files",
    "title": "2  Creating my Datasheet",
    "section": "2.4 Preparing Flow Tracker Files",
    "text": "2.4 Preparing Flow Tracker Files\n\n\nCode\n# Read in the flow data\nflow_tracker_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_1.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_1$dateTime_EDT &lt;- as.POSIXct(flow_tracker_1$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"America/New_York\")\n\n# Force the DateTime column from EDT to EST\nflow_tracker_1$dateTime_EST &lt;- as.POSIXct(format(flow_tracker_1$dateTime_EDT, \n                                                  tz = \"EST\", \n                                                  usetz = TRUE), \n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nflow_tracker_1 &lt;- flow_tracker_1 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_1 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_1 &lt;- bind_rows(flow_tracker_1, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_1)\n\n\n         localEndTime     river totalDischarge        dateTime_EDT\n1 2024-06-11 09:32:26    BUFFAM           1.49 2024-06-11 09:32:26\n2 2024-06-11 21:26:53    BUFFAM           0.02 2024-06-11 21:26:53\n3 2024-06-13 19:59:00    DICKEY           1.35 2024-06-13 19:59:00\n4 2024-06-14 09:57:28 DRY UPPER           0.02 2024-06-14 09:57:28\n5 2024-06-14 19:21:39 DRY UPPER           0.65 2024-06-14 19:21:39\n6 2024-06-11 10:42:47    HARRIS           0.07 2024-06-11 10:42:47\n         dateTime_EST shift\n1 2024-06-11 08:32:26   day\n2 2024-06-11 20:26:53 night\n3 2024-06-13 18:59:00 night\n4 2024-06-14 08:57:28   day\n5 2024-06-14 18:21:39 night\n6 2024-06-11 09:42:47   day\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_1, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_2.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_2$dateTime_EST &lt;- as.POSIXct(flow_tracker_2$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 11:00 EST to 17:00 EST\nflow_tracker_2 &lt;- flow_tracker_2 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 10 & hour(dateTime_EST) &lt; 18 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_2 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_2 &lt;- bind_rows(flow_tracker_2, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_2)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-06-18 16:48:45    BUFFAM           0.01 2024-06-18 16:48:45   day\n2 2024-06-19 02:07:27    BUFFAM           0.02 2024-06-19 02:07:27 night\n3 2024-06-17 12:35:22    DICKEY           0.03 2024-06-17 12:35:22   day\n4 2024-06-18 02:35:29    DICKEY           1.49 2024-06-18 02:35:29 night\n5 2024-06-19 12:36:08 DRY UPPER           0.02 2024-06-19 12:36:08   day\n6 2024-06-20 00:32:19 DRY UPPER           0.30 2024-06-20 00:32:19 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_2, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_3.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_3$dateTime_EST &lt;- as.POSIXct(flow_tracker_3$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nflow_tracker_3 &lt;- flow_tracker_3 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_3 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_3 &lt;- bind_rows(flow_tracker_3, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_3)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-06-26 10:42:10    BUFFAM           0.02 2024-06-26 10:42:10   day\n2 2024-06-26 17:51:16    BUFFAM           0.02 2024-06-26 17:51:16 night\n3 2024-06-28 09:44:29    DICKEY           0.03 2024-06-28 09:44:29   day\n4 2024-06-28 18:41:46    DICKEY           1.07 2024-06-28 18:41:46 night\n5 2024-06-25 07:21:55 DRY UPPER           0.03 2024-06-25 07:21:55   day\n6 2024-06-25 19:19:38 DRY UPPER           0.57 2024-06-25 19:19:38 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_3, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_4.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_4$dateTime_EST &lt;- as.POSIXct(flow_tracker_4$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nflow_tracker_4 &lt;- flow_tracker_4 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_4 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_4 &lt;- bind_rows(flow_tracker_4, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_4)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-07-02 04:11:20    BUFFAM           0.02 2024-07-02 04:11:20   day\n2 2024-07-02 17:28:34    BUFFAM           0.01 2024-07-02 17:28:34 night\n3 2024-07-01 04:39:46    DICKEY           1.77 2024-07-01 04:39:46   day\n4 2024-07-01 18:42:29    DICKEY           1.34 2024-07-01 18:42:29 night\n5 2024-06-30 05:23:29 DRY UPPER           0.33 2024-06-30 05:23:29   day\n6 2024-06-30 14:19:58 DRY UPPER           0.01 2024-06-30 14:19:58 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_4, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_5.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_5$dateTime_EST &lt;- as.POSIXct(flow_tracker_5$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nflow_tracker_5 &lt;- flow_tracker_5 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_5 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_5 &lt;- bind_rows(flow_tracker_5, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_5)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-07-11 11:21:40    BUFFAM           1.19 2024-07-11 11:21:40   day\n2 2024-07-11 12:00:06    BUFFAM           0.04 2024-07-11 12:00:06   day\n3 2024-07-11 18:15:24    BUFFAM           1.06 2024-07-11 18:15:24 night\n4 2024-07-10 08:31:15    DICKEY           0.07 2024-07-10 08:31:15   day\n5 2024-07-10 18:15:15    DICKEY           2.58 2024-07-10 18:15:15 night\n6 2024-07-12 08:03:32 DRY UPPER           0.00 2024-07-12 08:03:32   day\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_5, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_6.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_6$dateTime_EST &lt;- as.POSIXct(flow_tracker_6$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nflow_tracker_6 &lt;- flow_tracker_6 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_6 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_6 &lt;- bind_rows(flow_tracker_6, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_6)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-07-17 04:35:30    BUFFAM           1.69 2024-07-17 04:35:30   day\n2 2024-07-17 14:14:36    BUFFAM           1.12 2024-07-17 14:14:36 night\n3 2024-07-16 05:02:37    DICKEY           1.17 2024-07-16 05:02:37   day\n4 2024-07-16 14:29:54    DICKEY          -1.58 2024-07-16 14:29:54 night\n5 2024-07-18 04:41:46 DRY UPPER           1.68 2024-07-18 04:41:46   day\n6 2024-07-18 14:02:49 DRY UPPER           0.60 2024-07-18 14:02:49 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_6, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_7.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_7$dateTime_EST &lt;- as.POSIXct(flow_tracker_7$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nflow_tracker_7 &lt;- flow_tracker_7 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_7 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_7 &lt;- bind_rows(flow_tracker_7, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_7)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-07-25 12:08:40    BUFFAM           0.76 2024-07-25 12:08:40   day\n2 2024-07-25 18:12:05    BUFFAM           0.02 2024-07-25 18:12:05 night\n3 2024-07-24 10:50:19    DICKEY           1.79 2024-07-24 10:50:19   day\n4 2024-07-24 18:21:54    DICKEY           1.65 2024-07-24 18:21:54 night\n5 2024-07-23 08:27:20 DRY UPPER           0.13 2024-07-23 08:27:20   day\n6 2024-07-23 18:09:40 DRY UPPER           0.16 2024-07-23 18:09:40 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_7, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_8.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_8$dateTime_EST &lt;- as.POSIXct(flow_tracker_8$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:30 EST to 9:30 EST\nflow_tracker_8 &lt;- flow_tracker_8 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_8 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_8 &lt;- bind_rows(flow_tracker_8, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_8)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-07-31 04:44:54    BUFFAM           0.54 2024-07-31 04:44:54   day\n2 2024-07-31 13:43:07    BUFFAM           0.02 2024-07-31 13:43:07 night\n3 2024-07-30 04:50:14    DICKEY           1.13 2024-07-30 04:50:14   day\n4 2024-07-30 13:49:04    DICKEY           0.99 2024-07-30 13:49:04 night\n5 2024-08-02 04:30:04 DRY UPPER           0.14 2024-08-02 04:30:04   day\n6 2024-08-02 16:15:02 DRY UPPER           0.09 2024-08-02 16:15:02 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_8, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_9.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_9$dateTime_EST &lt;- as.POSIXct(flow_tracker_9$localEndTime, \n                                          format = \"%Y-%m-%d %H:%M:%S\",\n                                          tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nflow_tracker_9 &lt;- flow_tracker_9 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_9 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_9 &lt;- bind_rows(flow_tracker_9, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_9)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-08-08 08:25:54    BUFFAM           0.06 2024-08-08 08:25:54   day\n2 2024-08-08 17:48:04    BUFFAM          -2.36 2024-08-08 17:48:04 night\n3 2024-08-09 10:56:13    DICKEY           0.14 2024-08-09 10:56:13   day\n4 2024-08-07 08:20:43 DRY UPPER           0.25 2024-08-07 08:20:43   day\n5 2024-08-07 20:19:58 DRY UPPER          -0.09 2024-08-07 20:19:58 night\n6 2024-08-08 09:31:11    HARRIS           5.79 2024-08-08 09:31:11   day\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_9, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_10.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_10$dateTime_EST &lt;- as.POSIXct(flow_tracker_10$localEndTime, \n                                           format = \"%Y-%m-%d %H:%M:%S\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 4:00 EST to 10:00 EST\nflow_tracker_10 &lt;- flow_tracker_10 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 3 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_10 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_10 &lt;- bind_rows(flow_tracker_10, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_10)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-08-13 04:57:46    BUFFAM           1.22 2024-08-13 04:57:46   day\n2 2024-08-13 18:18:44    BUFFAM           0.95 2024-08-13 18:18:44 night\n3 2024-08-15 05:32:32    DICKEY           1.69 2024-08-15 05:32:32   day\n4 2024-08-15 15:12:35    DICKEY           1.40 2024-08-15 15:12:35 night\n5 2024-08-16 05:22:45 DRY UPPER           0.15 2024-08-16 05:22:45   day\n6 2024-08-16 14:38:49 DRY UPPER           0.08 2024-08-16 14:38:49 night\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_10, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_11.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_11$dateTime_EST &lt;- as.POSIXct(flow_tracker_11$localEndTime, \n                                           format = \"%Y-%m-%d %H:%M:%S\",\n                                           tz = \"EST\")\n\n# Add Shift column \n# All shifts in week 11 were day shifts\nflow_tracker_11 &lt;- flow_tracker_11 %&gt;%\n  mutate(shift = \"day\")\n\n# Create rows representing Amethyst brook discharge and temperature by combining Buffam and Harris measurements per shift\namethyst_combined &lt;- flow_tracker_11 %&gt;%\n  filter(river %in% c(\"BUFFAM\", \"HARRIS\")) %&gt;%   # Filter BUFFAM and HARRIS\n  group_by(shift) %&gt;%                            # Group by shift (day/night)\n  summarise(\n    river = \"AMETHYST\",                          # Set river to AMETHYST\n    totalDischarge = sum(totalDischarge, na.rm = TRUE)#, # Sum totalDischarge\n    #meanTemp = mean(meanTemp, na.rm = TRUE)      # Average meanTemp\n  )\n\n# Bind the AMETHYST rows to the original dataset\nflow_tracker_11 &lt;- bind_rows(flow_tracker_11, amethyst_combined)\n\n# Display the first few rows to check the result\nhead(flow_tracker_11)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-08-20 11:41:46    BUFFAM           3.53 2024-08-20 11:41:46   day\n2 2024-08-23 13:38:55    BUFFAM           0.82 2024-08-23 13:38:55   day\n3 2024-08-22 09:12:22       DRY           3.65 2024-08-22 09:12:22   day\n4 2024-08-20 09:56:27    HARRIS          13.48 2024-08-20 09:56:27   day\n5 2024-08-23 13:17:11    HARRIS           3.87 2024-08-23 13:17:11   day\n6 2024-08-21 09:25:52 UNDERHILL           1.21 2024-08-21 09:25:52   day\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_11, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the flow data\nflow_tracker_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_12.csv\")\n\n# Convert the localEndTime column into a DateTime column\nflow_tracker_12$dateTime_EST &lt;- as.POSIXct(flow_tracker_12$localEndTime, \n                                           format = \"%Y-%m-%d %H:%M:%S\",\n                                           tz = \"EST\")\n\n# Add Shift column\n# All shifts in week 12 were day shifts\nflow_tracker_12 &lt;- flow_tracker_12 %&gt;%\n  mutate(shift = \"day\")\n\n# Display the first few rows to check the result\nhead(flow_tracker_12)\n\n\n         localEndTime     river totalDischarge        dateTime_EST shift\n1 2024-08-29 10:21:54    DICKEY           0.03 2024-08-29 10:21:54   day\n2 2024-08-27 10:16:23 UNDERHILL           0.03 2024-08-27 10:16:23   day\n\n\nCode\n# Write new flow csv\nwrite.csv(flow_tracker_12, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_12.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define file names\nflow_file_names &lt;- c(\"flow_tracker_1.csv\", \"flow_tracker_2.csv\", \"flow_tracker_3.csv\", \"flow_tracker_4.csv\", \n                     \"flow_tracker_5.csv\", \"flow_tracker_6.csv\", \"flow_tracker_7.csv\", \"flow_tracker_8.csv\", \n                     \"flow_tracker_9.csv\", \"flow_tracker_10.csv\", \"flow_tracker_11.csv\", \"flow_tracker_12.csv\") \n\n# Create an empty list to store the processed datasets\nprocessed_flow_data_list &lt;- list()\n\n# Loop through each stream survey file\nfor (file_name in flow_file_names) {\n  # Read in the stream survey data\n  raw_flow_data &lt;- read.csv(file_name)\n  \n  # Step 1: Process the data\n  flow_data &lt;- raw_flow_data %&gt;%\n    \n    # Step 2: Select specific columns\n    select(river, totalDischarge, dateTime_EST, shift) %&gt;%\n\n    # Step 3: Rename columns\n    rename(flowTime_EST = dateTime_EST) \n  \n  # Store the processed data in the list\n  processed_flow_data_list[[file_name]] &lt;- flow_data\n  \n  # Overwrite the original file with the processed data\n  write.csv(flow_data, file_name, row.names = FALSE)\n}\n\n# Display the first few rows of each processed dataset\nfor (i in 1:length(processed_flow_data_list)) {\n  cat(\"\\nData for\", flow_file_names[i], \":\\n\")\n  print(head(processed_flow_data_list[[i]]))\n}\n\n\n\nData for flow_tracker_1.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           1.49 2024-06-11 08:32:26   day\n2    BUFFAM           0.02 2024-06-11 20:26:53 night\n3    DICKEY           1.35 2024-06-13 18:59:00 night\n4 DRY UPPER           0.02 2024-06-14 08:57:28   day\n5 DRY UPPER           0.65 2024-06-14 18:21:39 night\n6    HARRIS           0.07 2024-06-11 09:42:47   day\n\nData for flow_tracker_2.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.01 2024-06-18 16:48:45   day\n2    BUFFAM           0.02 2024-06-19 02:07:27 night\n3    DICKEY           0.03 2024-06-17 12:35:22   day\n4    DICKEY           1.49 2024-06-18 02:35:29 night\n5 DRY UPPER           0.02 2024-06-19 12:36:08   day\n6 DRY UPPER           0.30 2024-06-20 00:32:19 night\n\nData for flow_tracker_3.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.02 2024-06-26 10:42:10   day\n2    BUFFAM           0.02 2024-06-26 17:51:16 night\n3    DICKEY           0.03 2024-06-28 09:44:29   day\n4    DICKEY           1.07 2024-06-28 18:41:46 night\n5 DRY UPPER           0.03 2024-06-25 07:21:55   day\n6 DRY UPPER           0.57 2024-06-25 19:19:38 night\n\nData for flow_tracker_4.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.02 2024-07-02 04:11:20   day\n2    BUFFAM           0.01 2024-07-02 17:28:34 night\n3    DICKEY           1.77 2024-07-01 04:39:46   day\n4    DICKEY           1.34 2024-07-01 18:42:29 night\n5 DRY UPPER           0.33 2024-06-30 05:23:29   day\n6 DRY UPPER           0.01 2024-06-30 14:19:58 night\n\nData for flow_tracker_5.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           1.19 2024-07-11 11:21:40   day\n2    BUFFAM           0.04 2024-07-11 12:00:06   day\n3    BUFFAM           1.06 2024-07-11 18:15:24 night\n4    DICKEY           0.07 2024-07-10 08:31:15   day\n5    DICKEY           2.58 2024-07-10 18:15:15 night\n6 DRY UPPER           0.00 2024-07-12 08:03:32   day\n\nData for flow_tracker_6.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           1.69 2024-07-17 04:35:30   day\n2    BUFFAM           1.12 2024-07-17 14:14:36 night\n3    DICKEY           1.17 2024-07-16 05:02:37   day\n4    DICKEY          -1.58 2024-07-16 14:29:54 night\n5 DRY UPPER           1.68 2024-07-18 04:41:46   day\n6 DRY UPPER           0.60 2024-07-18 14:02:49 night\n\nData for flow_tracker_7.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.76 2024-07-25 12:08:40   day\n2    BUFFAM           0.02 2024-07-25 18:12:05 night\n3    DICKEY           1.79 2024-07-24 10:50:19   day\n4    DICKEY           1.65 2024-07-24 18:21:54 night\n5 DRY UPPER           0.13 2024-07-23 08:27:20   day\n6 DRY UPPER           0.16 2024-07-23 18:09:40 night\n\nData for flow_tracker_8.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.54 2024-07-31 04:44:54   day\n2    BUFFAM           0.02 2024-07-31 13:43:07 night\n3    DICKEY           1.13 2024-07-30 04:50:14   day\n4    DICKEY           0.99 2024-07-30 13:49:04 night\n5 DRY UPPER           0.14 2024-08-02 04:30:04   day\n6 DRY UPPER           0.09 2024-08-02 16:15:02 night\n\nData for flow_tracker_9.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           0.06 2024-08-08 08:25:54   day\n2    BUFFAM          -2.36 2024-08-08 17:48:04 night\n3    DICKEY           0.14 2024-08-09 10:56:13   day\n4 DRY UPPER           0.25 2024-08-07 08:20:43   day\n5 DRY UPPER          -0.09 2024-08-07 20:19:58 night\n6    HARRIS           5.79 2024-08-08 09:31:11   day\n\nData for flow_tracker_10.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           1.22 2024-08-13 04:57:46   day\n2    BUFFAM           0.95 2024-08-13 18:18:44 night\n3    DICKEY           1.69 2024-08-15 05:32:32   day\n4    DICKEY           1.40 2024-08-15 15:12:35 night\n5 DRY UPPER           0.15 2024-08-16 05:22:45   day\n6 DRY UPPER           0.08 2024-08-16 14:38:49 night\n\nData for flow_tracker_11.csv :\n      river totalDischarge        flowTime_EST shift\n1    BUFFAM           3.53 2024-08-20 11:41:46   day\n2    BUFFAM           0.82 2024-08-23 13:38:55   day\n3       DRY           3.65 2024-08-22 09:12:22   day\n4    HARRIS          13.48 2024-08-20 09:56:27   day\n5    HARRIS           3.87 2024-08-23 13:17:11   day\n6 UNDERHILL           1.21 2024-08-21 09:25:52   day\n\nData for flow_tracker_12.csv :\n      river totalDischarge        flowTime_EST shift\n1    DICKEY           0.03 2024-08-29 10:21:54   day\n2 UNDERHILL           0.03 2024-08-27 10:16:23   day",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-fish-survey-and-flow-data",
    "href": "creatingMyDatasheet.html#combine-fish-survey-and-flow-data",
    "title": "2  Creating my Datasheet",
    "section": "2.5 Combine fish survey and flow data",
    "text": "2.5 Combine fish survey and flow data\n\n\nCode\n# Read in the fish survey and flow data for week 1\nfish_survey_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_1.csv\")\nflow_tracker_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_1.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_1 &lt;- left_join(fish_survey_1, flow_tracker_1, \n                                by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_1)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-06-11 05:57:00 AMETHYST   day    59    NA  Riffle                Center\n2 2024-06-11 06:08:00 AMETHYST   day    60    NA  Riffle                Center\n3 2024-06-11 06:15:00   BUFFAM   day    19    NA  Riffle                Center\n4 2024-06-11 06:19:00   HARRIS   day    20    NA     Run                  Left\n5 2024-06-11 06:28:00   HARRIS   day    57    NA     Run                  Left\n6 2024-06-11 06:34:00   HARRIS   day    12    NA   Glide                Center\n  substrate substrateExtra         shade       lon      lat fishNotes source\n1      Rock             NA  Fully shaded -72.46038 42.38162             iPad\n2      Rock             NA  Fully shaded -72.46030 42.38136             iPad\n3      Rock             NA  Fully shaded -72.46023 42.38139             iPad\n4    Pebble             NA Mostly shaded -72.46015 42.38095             iPad\n5      Rock             NA Mostly shaded -72.46034 42.38105             iPad\n6      Rock             NA  Fully shaded -72.46009 42.38094             iPad\n  totalDischarge        flowTime_EST\n1           1.56                &lt;NA&gt;\n2           1.56                &lt;NA&gt;\n3           1.49 2024-06-11 08:32:26\n4           0.07 2024-06-11 09:42:47\n5           0.07 2024-06-11 09:42:47\n6           0.07 2024-06-11 09:42:47\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_1, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 2\nfish_survey_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_2.csv\")\nflow_tracker_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_2.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_2 &lt;- left_join(fish_survey_2, flow_tracker_2, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_2)\n\n\n      trackedTime_EST  river shift tagID power habitat  habitatExtra position\n1 2024-06-17 11:33:00 DICKEY   day    31    NA    Pool                 Center\n2 2024-06-17 11:57:00 DICKEY   day    46    NA     Run                  Right\n3 2024-06-17 11:59:00 DICKEY   day    29    NA  Riffle  Woody_debris     Left\n4 2024-06-17 12:10:00 DICKEY   day    26    NA     Run Undercut_bank    Right\n5 2024-06-17 12:47:00 DICKEY   day    28    NA    Pool                   Left\n6 2024-06-17 12:49:00 DICKEY   day    37    NA    Pool                  Right\n  substrate substrateExtra          shade       lon      lat fishNotes source\n1      Rock             NA  Mostly shaded -72.37084 42.44394             iPad\n2    Pebble             NA Lightly shaded -72.37173 42.44421             iPad\n3      Rock             NA   Fully shaded -72.37194 42.44430             iPad\n4      Rock             NA Lightly shaded -72.37344 42.44421             iPad\n5   Boulder             NA  Mostly shaded -72.37040 42.44369             iPad\n6      Rock             NA  Mostly shaded -72.37038 42.44377             iPad\n  totalDischarge        flowTime_EST\n1           0.03 2024-06-17 12:35:22\n2           0.03 2024-06-17 12:35:22\n3           0.03 2024-06-17 12:35:22\n4           0.03 2024-06-17 12:35:22\n5           0.03 2024-06-17 12:35:22\n6           0.03 2024-06-17 12:35:22\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_2, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 3\nfish_survey_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_3.csv\")\nflow_tracker_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_3.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_3 &lt;- left_join(fish_survey_3, flow_tracker_3, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_3)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-25 05:59:00 DRY UPPER   day    55    NA    Pool\n2 2024-06-25 06:02:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-25 06:07:00 DRY UPPER   day    53    NA    Pool\n4 2024-06-25 06:11:00 DRY UPPER   day    22    NA    Pool\n5 2024-06-25 06:20:00 DRY UPPER   day    21    NA    Pool\n6 2024-06-25 06:21:00 DRY UPPER   day    25    NA    Pool\n                habitatExtra position substrate substrateExtra          shade\n1               Woody_debris   Center      Rock             NA  Mostly shaded\n2               Woody_debris    Right       Mud             NA  Mostly shaded\n3               Woody_debris    Right       Mud             NA  Mostly shaded\n4   Root_bundle,Woody_debris     Left       Mud             NA Lightly shaded\n5 Woody_debris,Undercut_bank    Right      Rock             NA  Mostly shaded\n6 Undercut_bank,Woody_debris    Right      Rock             NA  Mostly shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50451 42.66767             iPad           0.03 2024-06-25 07:21:55\n2 -72.50455 42.66774             iPad           0.03 2024-06-25 07:21:55\n3 -72.50451 42.66761             iPad           0.03 2024-06-25 07:21:55\n4 -72.50445 42.66767             iPad           0.03 2024-06-25 07:21:55\n5 -72.50506 42.66704             iPad           0.03 2024-06-25 07:21:55\n6 -72.50507 42.66704             iPad           0.03 2024-06-25 07:21:55\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_3, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 4\nfish_survey_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_4.csv\")\nflow_tracker_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_4.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_4 &lt;- left_join(fish_survey_4, flow_tracker_4, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_4)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-30 04:39:00 DRY UPPER   day    22    NA    Pool\n2 2024-06-30 04:42:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-30 04:43:00 DRY UPPER   day    55    NA    Pool\n4 2024-06-30 04:50:00 DRY UPPER   day    21    NA    Pool\n5 2024-06-30 04:51:00 DRY UPPER   day    25    NA    Pool\n6 2024-06-30 04:51:00 DRY UPPER   day    24    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1                Root_bundle     Left        NA       Rock,Mud         Night\n2               Woody_debris    Right        NA            Mud  Fully shaded\n3               Woody_debris    Right        NA            Mud  Fully shaded\n4 Woody_debris,Undercut_bank    Right        NA            Mud Mostly shaded\n5 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n6 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50457 42.66769             iPad           0.33 2024-06-30 05:23:29\n2 -72.50448 42.66760             iPad           0.33 2024-06-30 05:23:29\n3 -72.50453 42.66762             iPad           0.33 2024-06-30 05:23:29\n4 -72.50514 42.66698             iPad           0.33 2024-06-30 05:23:29\n5 -72.50509 42.66699             iPad           0.33 2024-06-30 05:23:29\n6 -72.50508 42.66702             iPad           0.33 2024-06-30 05:23:29\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_4, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 5\nfish_survey_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_5.csv\")\nflow_tracker_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_5.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_5 &lt;- left_join(fish_survey_5, flow_tracker_5, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_5)\n\n\n      trackedTime_EST     river shift tagID power habitat  habitatExtra\n1 2024-07-09 07:30:00 UNDERHILL   day    41    NA  Riffle              \n2 2024-07-09 07:49:00 UNDERHILL   day    40    NA  Riffle  Woody_debris\n3 2024-07-09 07:57:00 UNDERHILL   day    34    NA  Riffle              \n4 2024-07-09 08:08:00 UNDERHILL   day    33    NA  Riffle Undercut_bank\n5 2024-07-09 08:18:00 UNDERHILL   day    36    NA    Pool              \n6 2024-07-09 08:25:00 UNDERHILL   day    27    NA  Riffle              \n  position substrate   substrateExtra         shade       lon      lat\n1   Center        NA             Rock  Fully shaded -72.32447 42.44488\n2                 NA      Rock,Pebble Mostly shaded -72.32513 42.44510\n3   Center        NA             Rock               -72.32645 42.44537\n4    Right        NA             Rock Mostly shaded -72.32624 42.44533\n5   Center        NA Rock,Pebble,Sand Mostly shaded -72.32752 42.44626\n6   Center        NA             Rock Mostly shaded -72.32780 42.44521\n                                           fishNotes source totalDischarge\n1                                                      iPad           2.78\n2                                                      iPad           2.78\n3                                                      iPad           2.78\n4                                                      iPad           2.78\n5 Moved up from where we thought it might have died.   iPad           2.78\n6                                                      iPad           2.78\n         flowTime_EST\n1 2024-07-09 09:13:28\n2 2024-07-09 09:13:28\n3 2024-07-09 09:13:28\n4 2024-07-09 09:13:28\n5 2024-07-09 09:13:28\n6 2024-07-09 09:13:28\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_5, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 6\nfish_survey_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_6.csv\")\nflow_tracker_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_6.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_6 &lt;- left_join(fish_survey_6, flow_tracker_6, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_6)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-16 03:49:00 DICKEY   day    31    NA  Riffle                Center\n2 2024-07-16 03:58:00 DICKEY   day    28    NA    Pool                Center\n3 2024-07-16 04:04:00 DICKEY   day    26    NA  Riffle                Center\n4 2024-07-16 04:05:00 DICKEY   day    37    NA  Riffle                Center\n5 2024-07-16 05:17:00 DICKEY   day    31    NA  Riffle                Center\n6 2024-07-16 05:21:00 DICKEY   day    28    NA    Pool                Center\n  substrate   substrateExtra        shade       lon      lat fishNotes source\n1        NA             Rock        Night -72.37121 42.44408             iPad\n2        NA         Sand,Mud        Night -72.37056 42.44364             iPad\n3        NA             Rock        Night -72.37030 42.44345             iPad\n4        NA             Rock Fully shaded -72.37018 42.44342             iPad\n5        NA        Rock,Sand Fully shaded -72.37132 42.44393             iPad\n6        NA Rock,Pebble,Sand Fully shaded -72.37059 42.44357             iPad\n  totalDischarge        flowTime_EST\n1           1.17 2024-07-16 05:02:37\n2           1.17 2024-07-16 05:02:37\n3           1.17 2024-07-16 05:02:37\n4           1.17 2024-07-16 05:02:37\n5           1.17 2024-07-16 05:02:37\n6           1.17 2024-07-16 05:02:37\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_6, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 7\nfish_survey_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_7.csv\")\nflow_tracker_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_7.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_7 &lt;- left_join(fish_survey_7, flow_tracker_7, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_7)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-07-23 07:28:00 DRY UPPER   day  39.1    NA    Pool\n2 2024-07-23 07:56:00 DRY UPPER   day  46.1    NA        \n3 2024-07-23 08:07:00 DRY UPPER   day  29.1    NA  Riffle\n4 2024-07-23 08:44:00 DRY UPPER   day  30.1    NA    Pool\n5 2024-07-23 08:52:00 DRY UPPER   day  16.0    NA    Pool\n6 2024-07-23 09:06:00 DRY UPPER   day  55.0    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1               Woody_debris    Right        NA      Rock,Sand Mostly shaded\n2                                            NA                             \n3                                Left        NA                Mostly shaded\n4               Woody_debris     Left        NA            Mud Mostly shaded\n5 Woody_debris,Undercut_bank    Right        NA       Mud,Sand  Fully shaded\n6               Woody_debris                 NA      Rock,Sand Mostly shaded\n        lon      lat                                  fishNotes source\n1 -72.50687 42.66812                                              iPad\n2 -72.50700 42.66827                                       Dead   iPad\n3 -72.50598 42.66837 Very shallow water. Can’t see fish or tag.   iPad\n4 -72.50495 42.66817                                              iPad\n5 -72.50460 42.66775                          Up under cutback.   iPad\n6 -72.50408 42.66603                              Dead have tag   iPad\n  totalDischarge        flowTime_EST\n1           0.13 2024-07-23 08:27:20\n2           0.13 2024-07-23 08:27:20\n3           0.13 2024-07-23 08:27:20\n4           0.13 2024-07-23 08:27:20\n5           0.13 2024-07-23 08:27:20\n6           0.13 2024-07-23 08:27:20\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_7, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 8\nfish_survey_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_8.csv\")\nflow_tracker_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_8.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_8 &lt;- left_join(fish_survey_8, flow_tracker_8, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_8)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-30 04:07:00 DICKEY   day    31    NA  Riffle                 Right\n2 2024-07-30 04:15:00 DICKEY   day    26    NA  Riffle                Center\n3 2024-07-30 04:16:00 DICKEY   day    37    NA  Riffle                Center\n4 2024-07-30 04:38:00 DICKEY   day    38    NA     Run                 Right\n5 2024-07-30 04:42:00 DICKEY   day    32    NA    Pool                  Left\n6 2024-07-30 05:25:00 DICKEY   day    38    NA  Riffle                  Left\n  substrate substrateExtra          shade       lon      lat\n1        NA    Pebble,Rock          Night -72.37116 42.44418\n2        NA    Rock,Pebble          Night -72.37034 42.44352\n3        NA    Rock,Pebble          Night -72.37032 42.44350\n4        NA    Rock,Pebble          Night -72.37335 42.44441\n5        NA         Pebble          Night -72.37354 42.44406\n6        NA    Rock,Pebble Lightly shaded -72.37340 42.44449\n                                               fishNotes source totalDischarge\n1                                                          iPad           1.13\n2                                                          iPad           1.13\n3                                                          iPad           1.13\n4                                                          iPad           1.13\n5 Dead.found on river left side of pool buried n gravel.   iPad           1.13\n6                                           May be dead    iPad           1.13\n         flowTime_EST\n1 2024-07-30 04:50:14\n2 2024-07-30 04:50:14\n3 2024-07-30 04:50:14\n4 2024-07-30 04:50:14\n5 2024-07-30 04:50:14\n6 2024-07-30 04:50:14\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_8, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 9\nfish_survey_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_9.csv\")\nflow_tracker_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_9.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_9 &lt;- left_join(fish_survey_9, flow_tracker_9, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_9)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-08-05 11:06:00 DRY UPPER   day    49   174    Pool\n2 2024-08-05 11:35:00 DRY UPPER   day    47    NA        \n3 2024-08-05 11:37:00 DRY UPPER   day    47    54        \n4 2024-08-06 07:41:00 UNDERHILL   day    33    NA  Riffle\n5 2024-08-06 07:47:00 UNDERHILL   day    45    NA    Pool\n6 2024-08-06 07:53:00 UNDERHILL   day    44    NA    Pool\n                habitatExtra position substrate      substrateExtra\n1 Woody_debris,Undercut_bank                 NA Granule,Pebble,Sand\n2                                            NA                    \n3                                            NA                    \n4               Woody_debris   Center        NA         Pebble,Rock\n5                              Center        NA      Pebble,Granule\n6               Woody_debris   Center        NA           Rock,Sand\n           shade       lon      lat\n1 Lightly shaded -72.50352 42.65114\n2                -72.50353 42.65375\n3                -72.50367 42.65407\n4  Mostly shaded -72.32640 42.44531\n5  Mostly shaded -72.32773 42.44515\n6  Mostly shaded -72.32803 42.44488\n                                                                         fishNotes\n1              Bunch of fish swimming around, moving too much to get a good signal\n2 Lost signal, signal was strongest (74) back at the clearing with the pine trees \n3                                                                                 \n4                                                            Same so as last week.\n5                                                                                 \n6                                                                                 \n  source totalDischarge        flowTime_EST\n1   iPad           0.25 2024-08-07 08:20:43\n2   iPad           0.25 2024-08-07 08:20:43\n3   iPad           0.25 2024-08-07 08:20:43\n4   iPad           0.04 2024-08-06 08:06:36\n5   iPad           0.04 2024-08-06 08:06:36\n6   iPad           0.04 2024-08-06 08:06:36\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_9, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 10\nfish_survey_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_10.csv\")\nflow_tracker_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_10.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_10 &lt;- left_join(fish_survey_10, flow_tracker_10, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_10)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-13 04:25:00   BUFFAM   day    60    NA     Run                Center\n2 2024-08-13 04:31:00   BUFFAM   day    18    NA     Run                Center\n3 2024-08-13 04:32:00   BUFFAM   day    14    NA  Riffle                Center\n4 2024-08-13 04:34:00   HARRIS   day    20    NA     Run Woody_debris   Center\n5 2024-08-13 04:41:00 AMETHYST   day    19    NA  Riffle                Center\n6 2024-08-13 05:15:00   BUFFAM   day    60    NA     Run                Center\n  substrate    substrateExtra        shade       lon      lat fishNotes source\n1        NA         Sand,Rock        Night -72.45838 42.38205             iPad\n2        NA Sand,Boulder,Rock        Night -72.45979 42.38119             iPad\n3        NA      Rock,Boulder        Night -72.46000 42.38136             iPad\n4        NA           Boulder        Night -72.46033 42.38118             iPad\n5        NA              Rock        Night -72.46088 42.38150             iPad\n6        NA         Sand,Rock Fully shaded -72.45866 42.38218             iPad\n  totalDischarge        flowTime_EST\n1           1.22 2024-08-13 04:57:46\n2           1.22 2024-08-13 04:57:46\n3           1.22 2024-08-13 04:57:46\n4           3.16 2024-08-13 06:51:21\n5           4.38                &lt;NA&gt;\n6           1.22 2024-08-13 04:57:46\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_10, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 11\nfish_survey_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_11.csv\")\nflow_tracker_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_11.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_11 &lt;- left_join(fish_survey_11, flow_tracker_11, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_11)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-20 09:10:00 AMETHYST   day    19    NA  Riffle                Center\n2 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n3 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n4 2024-08-20 09:54:00   BUFFAM   day    14    NA  Riffle                 Right\n5 2024-08-20 09:54:00   BUFFAM   day    14    NA  Riffle                 Right\n6 2024-08-20 10:40:00   BUFFAM   day    18    NA  Riffle                Center\n  substrate       substrateExtra        shade       lon      lat fishNotes\n1        NA                 Rock Fully shaded -72.46090 42.38157          \n2        NA              Boulder Fully shaded -72.46016 42.38116          \n3        NA              Boulder Fully shaded -72.46016 42.38116          \n4        NA            Rock,Sand Fully shaded -72.46000 42.38126          \n5        NA            Rock,Sand Fully shaded -72.46000 42.38126          \n6        NA Rock,Boulder,Granule Fully shaded -72.45993 42.38124          \n  source totalDischarge        flowTime_EST\n1   iPad          21.70                &lt;NA&gt;\n2   iPad          13.48 2024-08-20 09:56:27\n3   iPad           3.87 2024-08-23 13:17:11\n4   iPad           3.53 2024-08-20 11:41:46\n5   iPad           0.82 2024-08-23 13:38:55\n6   iPad           3.53 2024-08-20 11:41:46\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_11, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish survey and flow data for week 12\nfish_survey_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_survey_12.csv\")\nflow_tracker_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/flow_tracker_12.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_12 &lt;- left_join(fish_survey_12, flow_tracker_12, by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_12)\n\n\n      trackedTime_EST     river shift tagID power habitat habitatExtra position\n1 2024-08-27 09:41:00 UNDERHILL   day    45    NA    Pool           NA    Right\n2 2024-08-27 10:32:00 UNDERHILL   day    44    NA    Pool           NA   Center\n3 2024-08-27 12:19:00 UNDERHILL   day    35    NA    Pool           NA   Center\n  substrate              substrateExtra         shade       lon      lat\n1        NA                   Sand,Rock  Fully shaded -72.32730 42.44535\n2        NA                   Sand,Rock Mostly shaded -72.32805 42.44492\n3        NA Boulder,Rock,Granule,Pebble Mostly shaded -72.32929 42.44359\n                                                                              fishNotes\n1                                                      Unsuccessful at finding shed tag\n2                                                      Unsuccessful at finding shed tag\n3 Unsuccessful at finding shed tag. It is most likely located in a hole under this rock\n  source totalDischarge        flowTime_EST\n1   iPad           0.03 2024-08-27 10:16:23\n2   iPad           0.03 2024-08-27 10:16:23\n3   iPad           0.03 2024-08-27 10:16:23\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_12, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_12.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-lotek-data-files-for-analysis",
    "href": "creatingMyDatasheet.html#preparing-lotek-data-files-for-analysis",
    "title": "2  Creating my Datasheet",
    "section": "2.6 Preparing lotek data files for analysis",
    "text": "2.6 Preparing lotek data files for analysis\n\n2.6.1 Lotek receiver 000900 data\n\n\nCode\n# ID Only Data ###########################################################\n\n# Read the dataset\nreceiver_000900_raw_data &lt;- read.delim(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt\")\n\n# Rename the single column in the dataset as \"columnOne\"\nnames(receiver_000900_raw_data) &lt;- c(\"columnOne\")\n\n# Detect the start of the row that says \"ID Only Records:\" and create a flag\nreceiver_000900_ID_data &lt;- receiver_000900_raw_data %&gt;% \n  mutate(column2 = ifelse(columnOne == \"ID Only Records:\", 1, 0)) \n\n# Detect the start of row that says \"ID + GPS Positions:\"\nid_gps_row &lt;- which(receiver_000900_raw_data$columnOne == \"ID + GPS Positions:\")\n\n# If \"ID + GPS Positions:\" is found, slice until the row before it\nif(length(id_gps_row) &gt; 0) {\n  id_gps_row &lt;- id_gps_row[1] - 1  # One row before \"ID + GPS Positions:\"\n} else {\n  id_gps_row &lt;- nrow(receiver_000900_raw_data)  # If \"ID + GPS Positions:\" not found, slice till the bottom\n}\n\n# Slice out the ID data by detecting the start and extracting relevant rows\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  slice((which(grepl(1, receiver_000900_ID_data$column2)) + 2) : id_gps_row)\n\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Split the initial columns based on space separation\n  separate(columnOne , \n           c(\"Date\", \"Time\", \"Channel\", \"Tag ID\", \"Antenna\", \"Power\"), \n           extra = \"merge\", \n           sep = \"\\\\s+\")\n  \nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Select the columns for further processing\n  select(\"Date\", \"Time\", \"Tag ID\", \"Power\") \n\n# Combine the date and time into a DateTime column\nreceiver_000900_ID_data$dateTime_EST &lt;- as.POSIXct(paste(receiver_000900_ID_data$Date, \n                                                         receiver_000900_ID_data$Time), \n                                                   format=\"%m/%d/%y %H:%M:%S\",\n                                                   tz = \"EST\")\n  \n#receiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Combine Date and Time columns into a single datetime in mdy_hms format\n  #mutate(dateTime = mdy_hms(paste(Date, Time))) \n  \nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Rename \"Tag ID' column as \"tagID\"\n  rename_with(~ \"tagID\", .cols = `Tag ID`) %&gt;%\n  \n  # Rename \"Date' column as \"date\"\n  rename_with(~ \"date\", .cols = `Date`) %&gt;%\n  \n  # Rename \"Power' column as \"power\"\n  rename_with(~ \"power\", .cols = `Power`)\n  \nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Select the columns for further processing\n  select(\"date\", \"tagID\", \"power\", \"dateTime_EST\") \n\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;%\n  # Clean and format the data\n  mutate(tagID = as.numeric(tagID),\n         power = as.numeric(power),\n         date = mdy(date),\n         source = \"lotek\")\n\n# Define the date range\nstart_date &lt;- ymd(\"2024-06-11\")  \nend_date &lt;- ymd(\"2024-08-29\")   \n\n# Define specific days to filter out based on the non-tracking days on the calendar\ndays_to_exclude &lt;- ymd(c(\"2024-06-21\", \"2024-06-24\", \"2024-07-04\", \"2024-07-05\", \n                         \"2024-07-08\", \"2024-07-15\", \"2024-07-22\", \"2024-07-29\", \n                         \"2024-08-12\",\"2024-08-19\", \"2024-08-28\"))\n  \nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Filter by tagID range\n  filter(tagID &gt; 10 & tagID &lt; 63) %&gt;%\n  \n  # Filter by the date range\n  filter(date &gt;= start_date & date &lt;= end_date) %&gt;%\n  \n  # Filter out the specified days\n  filter(!(date %in% days_to_exclude))\n\n\n# Define the date ranges for different rivers to account for retagging\nriver_date_ranges &lt;- tibble(\n  river = c(\"AMETHYST\", \"UNDERHILL\", \"DICKEY\", \"DICKEY\", \n            \"DRY UPPER\", \"DRY UPPER\"),\n  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, \n                       13, 57, 19, 62, 11, 58, 18), \n                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), \n                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),\n                     c(50, 37, 38, 26, 28, 51, 32, 31),\n                     c(42, 49, 55, 16, 52, 21, 47, 24, \n                       48, 22, 17, 25, 54, 23, 53),\n                     c(29, 30, 46, 39)),\n  start_date = ymd(c(\"2024-06-11\", \"2024-06-11\", \"2024-06-11\", \n                     \"2024-07-18\", \"2024-06-11\", \"2024-07-18\")),\n  end_date = ymd(c(\"2024-08-29\", \"2024-08-29\", \"2024-07-17\", \n                   \"2024-08-29\", \"2024-08-29\", \"2024-08-29\"))\n)\n\n# Function to determine river based on tagID and date\nassign_river &lt;- function(tagID, date) {\n  # Filter the river_date_ranges for matching tagID and date range\n  river_info &lt;- river_date_ranges %&gt;%\n    filter(map_lgl(tagID_range, ~ tagID %in% .) & date &gt;= start_date & date &lt;= end_date)\n  \n  if (nrow(river_info) &gt; 0) {\n    return(river_info$river[1])  # Return the matching river\n  } else {\n    return(\"Unknown\")  # Default for no match\n  }\n}\n\n# Ensure the 'date' column is in Date format\nreceiver_000900_ID_data$date &lt;- ymd(receiver_000900_ID_data$date)\n\n# Apply the function to the data frame\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;%\n  mutate(river = mapply(assign_river, tagID, date))\n\n# Remove rows where river is \"Unknown\"\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;%\n  filter(river != \"Unknown\")\n\nreceiver_000900_ID_data &lt;- receiver_000900_ID_data %&gt;% \n  # Select the columns for the final dataframe\n  select(\"tagID\", \"power\", \"dateTime_EST\", \"river\", \"date\") \n\n# View dataframe\nhead(receiver_000900_ID_data)\n\n\n  tagID power        dateTime_EST     river       date\n1    53    93 2024-06-25 18:53:37 DRY UPPER 2024-06-25\n2    54    72 2024-06-25 18:53:39 DRY UPPER 2024-06-25\n3    23   169 2024-06-25 22:50:34 DRY UPPER 2024-06-25\n4    49   160 2024-06-25 22:50:35 DRY UPPER 2024-06-25\n5    19   107 2024-06-26 05:23:35  AMETHYST 2024-06-26\n6    59   104 2024-06-26 05:23:42  AMETHYST 2024-06-26\n\n\n\n\nCode\n# ID + GPS Data ###########################################################\n\n# Read the dataset\nreceiver_000900_raw_data &lt;- read.delim(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000900/20240903/000900_20240903.txt\")\n\n# Rename the single column in the dataset as \"columnOne\"\nnames(receiver_000900_raw_data) &lt;- c(\"columnOne\")\n\n# Detect the start of the row that says \"ID + GPS Positions:\" and create a flag\nreceiver_000900_GPS_data &lt;- receiver_000900_raw_data %&gt;% \n  mutate(column2 = ifelse(columnOne == \"ID + GPS Positions:\", 1, 0)) \n\n# Detect the start of row that says \"End of Data\" \nend_of_data_row &lt;- which(receiver_000900_raw_data$columnOne == \"End of Data\")\n\n# If \"End of Data\" is found, slice until the row before it\nif(length(end_of_data_row) &gt; 0) {\n  end_of_data_row &lt;- end_of_data_row[1] - 1  # One row before \"End of data\"\n} else {\n  end_of_data_row &lt;- nrow(receiver_000900_raw_data)  # If \"End of data\" not found, slice till the bottom\n}\n\n# Slice out the GPS data by detecting the start and extracting relevant rows\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  slice((which(grepl(1, receiver_000900_GPS_data$column2)) + 2) : end_of_data_row)\n\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Split the initial columns based on space separation\n  separate(columnOne , c(\"Date\", \"Time\", \"Channel\", \"Tag ID\", \"Antenna\", \"Power\"), \n           extra = \"merge\", sep = \"\\\\s+\")\n\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Separate the \"Power\" column into power, latitude, and longitude\n  separate(Power, c(\"power\", \"lat\", \"lon\"), sep = \"\\\\s+\") \n  \nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Select the columns for further processing\n  select(\"Date\", \"Time\", \"Tag ID\", \"power\", \"lon\", \"lat\") \n  \n# Combine the date and time into a DateTime column\nreceiver_000900_GPS_data$dateTime_EST &lt;- as.POSIXct(paste(receiver_000900_GPS_data$Date, \n                                                          receiver_000900_GPS_data$Time), \n                                                    format=\"%m/%d/%y %H:%M:%S\",\n                                                    tz = \"EST\")\n  \nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Rename \"Tag ID' column as \"tagID\"\n  rename_with(~ \"tagID\", .cols = `Tag ID`) %&gt;%\n  \n  # Rename \"Date' column as \"date\"\n  rename_with(~ \"date\", .cols = `Date`) \n  \nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Select the columns for further processing\n  select(\"date\", \"tagID\", \"power\",\"lon\", \"lat\", \"dateTime_EST\") \n\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;%\n  # Clean and format the data\n  mutate(lat = as.numeric(lat), \n         lon = as.numeric(lon),\n         tagID = as.numeric(tagID),\n         power = as.numeric(power),\n         date = mdy(date),\n         source = \"lotek\")\n\n# Define the date range\nstart_date &lt;- ymd(\"2024-06-11\")  \nend_date &lt;- ymd(\"2024-08-29\")   \n\n# Define specific days to filter out based on the non-tracking days on the calendar\ndays_to_exclude &lt;- ymd(c(\"2024-06-21\", \"2024-06-24\", \"2024-07-04\", \"2024-07-05\", \n                         \"2024-07-08\", \"2024-07-15\", \"2024-07-22\", \"2024-07-29\", \n                         \"2024-08-12\",\"2024-08-19\", \"2024-08-28\"))\n  \nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Filter by tagID range\n  filter(tagID &gt; 10 & tagID &lt; 63) %&gt;%\n  \n  # Filter by the date range\n  filter(date &gt;= start_date & date &lt;= end_date) %&gt;%\n  \n  # Filter out the specified days\n  filter(!(date %in% days_to_exclude))\n\n# Define the date ranges for different rivers to account for retagging\nriver_date_ranges &lt;- tibble(\n  river = c(\"AMETHYST\", \"UNDERHILL\", \"DICKEY\", \"DICKEY\", \n            \"DRY UPPER\", \"DRY UPPER\"),\n  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, \n                       13, 57, 19, 62, 11, 58, 18), \n                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), \n                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),\n                     c(50, 37, 38, 26, 28, 51, 32, 31),\n                     c(42, 49, 55, 16, 52, 21, 47, 24, \n                       48, 22, 17, 25, 54, 23, 53),\n                     c(29, 30, 46, 39)),\n  start_date = ymd(c(\"2024-06-11\", \"2024-06-11\", \"2024-06-11\", \"2024-07-18\", \n                         \"2024-06-11\", \"2024-07-18\")),\n  end_date = ymd(c(\"2024-08-29\", \"2024-08-29\", \"2024-07-17\", \"2024-08-29\", \n                       \"2024-08-29\", \"2024-08-29\"))\n)\n\n# Function to determine river based on tagID and date\nassign_river &lt;- function(tagID, date) {\n  # Filter the river_date_ranges for matching tagID and date range\n  river_info &lt;- river_date_ranges %&gt;%\n    filter(map_lgl(tagID_range, ~ tagID %in% .) & date &gt;= start_date & date &lt;= end_date)\n  \n  if (nrow(river_info) &gt; 0) {\n    return(river_info$river[1])  # Return the matching river\n  } else {\n    return(\"Unknown\")  # Default for no match\n  }\n}\n\n# Ensure the 'date' column is in Date format\nreceiver_000900_GPS_data$date &lt;- ymd(receiver_000900_GPS_data$date)\n\n# Apply the function to the data frame\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;%\n  mutate(river = mapply(assign_river, tagID, date))\n\n# Remove rows where river is \"Unknown\"\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;%\n  filter(river != \"Unknown\")\n\nreceiver_000900_GPS_data &lt;- receiver_000900_GPS_data %&gt;% \n  # Select the columns for the final dataframe\n  select(\"tagID\", \"power\",\"lon\", \"lat\", \"dateTime_EST\", \"river\", \"date\")\n\n# View dataframe\nhead(receiver_000900_GPS_data)\n\n\n  tagID power       lon      lat        dateTime_EST     river       date\n1    55    98 -72.50610 42.66795 2024-06-25 05:52:45 DRY UPPER 2024-06-25\n2    16   103 -72.50556 42.66790 2024-06-25 05:53:15 DRY UPPER 2024-06-25\n3    16   109 -72.50526 42.66778 2024-06-25 05:53:35 DRY UPPER 2024-06-25\n4    55   102 -72.50514 42.66778 2024-06-25 05:53:45 DRY UPPER 2024-06-25\n5    53    99 -72.50512 42.66777 2024-06-25 05:53:46 DRY UPPER 2024-06-25\n6    55   121 -72.50498 42.66764 2024-06-25 05:54:05 DRY UPPER 2024-06-25\n\n\n\n\nCode\n# Combine back into one dataframe ###########################################################\n\n# Combine the two final dataframes horizontally \nreceiver_000900_data &lt;- bind_rows(receiver_000900_ID_data, receiver_000900_GPS_data)\n\n# Clean workspace by removing excess variables\nrm(river_date_ranges, receiver_000900_raw_data, receiver_000900_ID_data, receiver_000900_GPS_data)\n\n# View dataframe\nhead(receiver_000900_data)\n\n\n  tagID power        dateTime_EST     river       date lon lat\n1    53    93 2024-06-25 18:53:37 DRY UPPER 2024-06-25  NA  NA\n2    54    72 2024-06-25 18:53:39 DRY UPPER 2024-06-25  NA  NA\n3    23   169 2024-06-25 22:50:34 DRY UPPER 2024-06-25  NA  NA\n4    49   160 2024-06-25 22:50:35 DRY UPPER 2024-06-25  NA  NA\n5    19   107 2024-06-26 05:23:35  AMETHYST 2024-06-26  NA  NA\n6    59   104 2024-06-26 05:23:42  AMETHYST 2024-06-26  NA  NA\n\n\n\n\n2.6.2 Lotek receiver 000517 data\nNo ID+GPS data on this receiver - No combination needed\n\n\nCode\n# ID Only Data ###########################################################\n\n# Read the dataset\nreceiver_000517_raw_data &lt;- read.delim(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawLotekData/000517/20240912/000517_20240912.txt\")\n\n# Rename the single column in the dataset as \"columnOne\"\nnames(receiver_000517_raw_data) &lt;- c(\"columnOne\")\n\n# Detect the start of the row that says \"ID Only Records:\" and create a flag\nreceiver_000517_ID_data &lt;- receiver_000517_raw_data %&gt;% \n  mutate(column2 = ifelse(columnOne == \"ID Only Records:\", 1, 0)) \n\n# Detect the start of row that says \"End of Data\" \nend_of_data_row &lt;- which(receiver_000517_raw_data$columnOne == \"End of Data\")\n\n# If \"End of Data\" is found, slice until the row before it\nif(length(end_of_data_row) &gt; 0) {\n  end_of_data_row &lt;- end_of_data_row[1] - 1  # One row before \"End of data\"\n} else {\n  end_of_data_row &lt;- nrow(receiver_000517_raw_data)  # If \"End of data\" not found, slice till the bottom\n}\n\n# Slice out the data by detecting the start and extracting relevant rows\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  slice((which(grepl(1, receiver_000517_ID_data$column2)) + 2) : end_of_data_row)\n\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Split the initial columns based on space separation\n  separate(columnOne , c(\"Date\", \"Time\", \"Channel\", \"Tag ID\", \"Antenna\", \"Power\"), \n           extra = \"merge\", sep = \"\\\\s+\")\n  \nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Select the columns for further processing\n  select(\"Date\", \"Time\", \"Tag ID\", \"Power\") \n  \n# Combine the date and time into a DateTime column\nreceiver_000517_ID_data$dateTime_EST &lt;- as.POSIXct(paste(receiver_000517_ID_data$Date, \n                                                         receiver_000517_ID_data$Time), \n                                                   format=\"%m/%d/%y %H:%M:%S\",\n                                                   tz = \"EST\") \n  \nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Rename \"Tag ID' column as \"tagID\"\n  rename_with(~ \"tagID\", .cols = `Tag ID`) %&gt;%\n  \n  # Rename \"Date' column as \"date\"\n  rename_with(~ \"date\", .cols = `Date`) %&gt;%\n  \n  # Rename \"Power' column as \"power\"\n  rename_with(~ \"power\", .cols = `Power`)\n  \nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Select the columns for further processing\n  select(\"date\", \"tagID\", \"power\", \"dateTime_EST\") \n\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;%\n  # Clean and format the data\n  mutate(tagID = as.numeric(tagID),\n         power = as.numeric(power),\n         date = mdy(date),\n         source = \"lotek\")\n\n# Define the date range\nstart_date &lt;- ymd(\"2024-06-11\")  \nend_date &lt;- ymd(\"2024-08-29\")   \n\n# Define specific days to filter out based on the non-tracking days on the calendar\ndays_to_exclude &lt;- ymd(c(\"2024-06-21\", \"2024-06-24\", \"2024-07-04\", \"2024-07-05\", \n                         \"2024-07-08\", \"2024-07-15\", \"2024-07-22\", \"2024-07-29\", \n                         \"2024-08-12\",\"2024-08-19\", \"2024-08-28\"))\n  \nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Filter by tagID range\n  filter(tagID &gt; 10 & tagID &lt; 63) %&gt;%\n  \n  # Filter by the date range\n  filter(date &gt;= start_date & date &lt;= end_date) %&gt;%\n  \n  # Filter out the specified days\n  filter(!(date %in% days_to_exclude))\n\n# Define the date ranges for different rivers to account for retagging\nriver_date_ranges &lt;- tibble(\n  river = c(\"AMETHYST\", \"UNDERHILL\", \"DICKEY\", \"DICKEY\", \n            \"DRY UPPER\", \"DRY UPPER\"),\n  tagID_range = list(c(59, 60, 56, 14, 61, 20, 12, 15, \n                       13, 57, 19, 62, 11, 58, 18), \n                     c(41, 43, 40, 44, 33, 34, 45, 35, 27, 36), \n                     c(50, 37, 38, 46, 26, 28, 51, 32, 29, 31),\n                     c(50, 37, 38, 26, 28, 51, 32, 31),\n                     c(42, 49, 55, 16, 52, 21, 47, 24, \n                       48, 22, 17, 25, 54, 23, 53),\n                     c(29, 30, 46, 39)),\n  start_date = ymd(c(\"2024-06-11\", \"2024-06-11\", \"2024-06-11\", \"2024-07-18\", \n                         \"2024-06-11\", \"2024-07-18\")),\n  end_date = ymd(c(\"2024-08-29\", \"2024-08-29\", \"2024-07-17\", \"2024-08-29\", \n                       \"2024-08-29\", \"2024-08-29\"))\n)\n\n# Function to determine river based on tagID and date\nassign_river &lt;- function(tagID, date) {\n  # Filter the river_date_ranges for matching tagID and date range\n  river_info &lt;- river_date_ranges %&gt;%\n    filter(map_lgl(tagID_range, ~ tagID %in% .) & date &gt;= start_date & date &lt;= end_date)\n  \n  if (nrow(river_info) &gt; 0) {\n    return(river_info$river[1])  # Return the matching river\n  } else {\n    return(\"Unknown\")  # Default for no match\n  }\n}\n\n# Ensure the 'date' column is in Date format\nreceiver_000517_ID_data$date &lt;- ymd(receiver_000517_ID_data$date)\n\n# Apply the function to the data frame\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;%\n  mutate(river = mapply(assign_river, tagID, date))\n\n# Remove rows where river is \"Unknown\"\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;%\n  filter(river != \"Unknown\")\n\nreceiver_000517_ID_data &lt;- receiver_000517_ID_data %&gt;% \n  # Select the columns for the final dataframe\n  select(\"tagID\", \"power\", \"dateTime_EST\", \"river\", \"date\") \n\n# Clean workspace by removing excess variables\nrm(receiver_000517_raw_data, river_date_ranges)\n\n# View dataframe\nhead(receiver_000517_ID_data)\n\n\n  tagID power        dateTime_EST     river       date\n1    33   178 2024-08-01 12:50:02 UNDERHILL 2024-08-01\n2    33   190 2024-08-01 12:50:22 UNDERHILL 2024-08-01\n3    33   170 2024-08-01 12:50:42 UNDERHILL 2024-08-01\n4    33   175 2024-08-01 12:51:02 UNDERHILL 2024-08-01\n5    33   166 2024-08-01 12:51:22 UNDERHILL 2024-08-01\n6    33   187 2024-08-01 12:51:42 UNDERHILL 2024-08-01\n\n\n\n\n2.6.3 Combine all data from all receivers\n\n\nCode\n# Combine multiple receivers into one dataframe ########################################\n\n# Combine the two final dataframes horizontally\nreceiver_data_all &lt;- bind_rows(receiver_000900_data, receiver_000517_ID_data)\n\n# Clean workspace by removing excess variables\nrm(receiver_000900_data, receiver_000517_ID_data)\n\n# View dataframe\nhead(receiver_data_all)\n\n\n  tagID power        dateTime_EST     river       date lon lat\n1    53    93 2024-06-25 18:53:37 DRY UPPER 2024-06-25  NA  NA\n2    54    72 2024-06-25 18:53:39 DRY UPPER 2024-06-25  NA  NA\n3    23   169 2024-06-25 22:50:34 DRY UPPER 2024-06-25  NA  NA\n4    49   160 2024-06-25 22:50:35 DRY UPPER 2024-06-25  NA  NA\n5    19   107 2024-06-26 05:23:35  AMETHYST 2024-06-26  NA  NA\n6    59   104 2024-06-26 05:23:42  AMETHYST 2024-06-26  NA  NA\n\n\n\n\n2.6.4 Add day and night shift differentiation into receiver data\n\n\nCode\nreceiver_data_all &lt;- receiver_data_all %&gt;%\n  mutate(\n    shift = case_when(\n      # Define shift for week 1\n      date(dateTime_EST) &gt;= ymd(\"2024-06-11\") & date(dateTime_EST) &lt;= ymd(\"2024-06-14\") &\n      hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n      \n      # Define shift for week 2\n      date(dateTime_EST) &gt;= ymd(\"2024-06-17\") & date(dateTime_EST) &lt;= ymd(\"2024-06-20\") &\n      hour(dateTime_EST) &gt;= 10 & hour(dateTime_EST) &lt; 18 ~ \"day\",\n      \n      # Define shift for week 3\n      date(dateTime_EST) &gt;= ymd(\"2024-06-25\") & date(dateTime_EST) &lt;= ymd(\"2024-06-28\") &\n      hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n      \n      # Define shift for week 4\n      date(dateTime_EST) &gt;= ymd(\"2024-06-30\") & date(dateTime_EST) &lt;= ymd(\"2024-07-03\") &\n      hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n      \n      # Define shift for week 5\n      date(dateTime_EST) &gt;= ymd(\"2024-07-09\") & date(dateTime_EST) &lt;= ymd(\"2024-07-12\") &\n      hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n      \n      # Define shift for week 6\n      date(dateTime_EST) &gt;= ymd(\"2024-07-16\") & date(dateTime_EST) &lt;= ymd(\"2024-07-19\") &\n      hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n      \n      # Define shift for week 7\n      date(dateTime_EST) &gt;= ymd(\"2024-07-23\") & date(dateTime_EST) &lt;= ymd(\"2024-07-26\") &\n      hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n      \n      # Define shift for week 8\n      date(dateTime_EST) &gt;= ymd(\"2024-07-30\") & date(dateTime_EST) &lt;= ymd(\"2024-08-02\") &\n      hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n      \n      # Define shift for supplementary tracking on August 5, 2024\n      date(dateTime_EST) == ymd(\"2024-08-05\") ~ \"day\",\n      \n      # Define shift for week 9\n      date(dateTime_EST) &gt;= ymd(\"2024-08-06\") & date(dateTime_EST) &lt;= ymd(\"2024-08-09\") &\n      hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n      \n      # Define shift for week 10\n      date(dateTime_EST) &gt;= ymd(\"2024-08-13\") & date(dateTime_EST) &lt;= ymd(\"2024-08-16\") &\n      hour(dateTime_EST) &gt;= 3 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n      \n      # Define shift for week 11\n      date(dateTime_EST) &gt;= ymd(\"2024-08-20\") & date(dateTime_EST) &lt;= ymd(\"2024-08-23\") ~ \"day\",\n      \n      # Define shift for week 12\n      date(dateTime_EST) &gt;= ymd(\"2024-08-26\") & date(dateTime_EST) &lt;= ymd(\"2024-08-29\") ~ \"day\",\n      \n      # Default to night shift for all other times\n      TRUE ~ \"night\"\n    )\n  )\n\nreceiver_data_all &lt;- receiver_data_all %&gt;%\n  # Rename column\n  mutate(trackedTime_EST = dateTime_EST,\n         source = \"receiver\")\n\nreceiver_data_all &lt;- receiver_data_all %&gt;% \n  # Select the columns for the final dataframe\n  select(\"date\", \"trackedTime_EST\", \"river\", \"shift\", \"tagID\", \"power\", \"lon\", \"lat\", \"source\")\n\nhead(receiver_data_all)\n\n\n        date     trackedTime_EST     river shift tagID power lon lat   source\n1 2024-06-25 2024-06-25 18:53:37 DRY UPPER night    53    93  NA  NA receiver\n2 2024-06-25 2024-06-25 18:53:39 DRY UPPER night    54    72  NA  NA receiver\n3 2024-06-25 2024-06-25 22:50:34 DRY UPPER night    23   169  NA  NA receiver\n4 2024-06-25 2024-06-25 22:50:35 DRY UPPER night    49   160  NA  NA receiver\n5 2024-06-26 2024-06-26 05:23:35  AMETHYST   day    19   107  NA  NA receiver\n6 2024-06-26 2024-06-26 05:23:42  AMETHYST   day    59   104  NA  NA receiver\n\n\nCode\n# Write the dataframe into a csv\nwrite.csv(receiver_data_all, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_all.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Step 1: Define specific date ranges for each week\nweek_ranges &lt;- data.frame(\n  week_name = c(\"week_1\", \"week_2\", \"week_3\", \"week_4\", \"week_5\", \"week_6\", \"week_7\", \"week_8\", \"week_9\", \"week_10\", \"week_11\", \"week_12\"),  \n  start_date = ymd(c(\"2024-06-11\", \"2024-06-17\", \"2024-06-25\", \"2024-06-30\", \"2024-07-09\", \"2024-07-16\", \"2024-07-23\", \"2024-07-30\", \"2024-08-05\", \"2024-08-13\", \"2024-08-20\", \"2024-08-26\")),\n  end_date = ymd(c(\"2024-06-14\", \"2024-06-20\", \"2024-06-28\", \"2024-07-03\", \"2024-07-12\", \"2024-07-19\", \"2024-07-26\", \"2024-08-02\", \"2024-08-09\", \"2024-08-16\", \"2024-08-23\", \"2024-08-29\"))\n)\n\n# Initialize a counter for naming datasets\ncounter &lt;- 1\n\n# Step 2: Loop through each date range and filter the dataset\nfor (i in 1:nrow(week_ranges)) {\n  # Filter the dataset for each specified date range\n  weekly_receiver_data &lt;- receiver_data_all %&gt;%\n    filter(date &gt;= week_ranges$start_date[i] & date &lt;= week_ranges$end_date[i]) %&gt;%\n    \n    # Remove the 'date' column before saving the CSV\n    select(-date)\n  \n  # Dynamically name each week's data (e.g., receiver_data_1, receiver_data_2, ...)\n  assign(paste0(\"receiver_data_\", counter), weekly_receiver_data)\n  \n  # Optional: Save the dataset to a CSV file\n  file_name &lt;- paste0(\"receiver_data_\", counter, \".csv\")\n  write.csv(weekly_receiver_data, file = file_name, row.names = FALSE)\n  \n  # Display the first few rows of the created datasets\n  cat(\"\\nData for\", file_name, \":\\n\")\n  print(head(weekly_receiver_data))  # Print the first few rows of each weekly dataset\n  \n  # Increment the counter\n  counter &lt;- counter + 1\n}\n\n\n\nData for receiver_data_1.csv :\n[1] trackedTime_EST river           shift           tagID          \n[5] power           lon             lat             source         \n&lt;0 rows&gt; (or 0-length row.names)\n\nData for receiver_data_2.csv :\n[1] trackedTime_EST river           shift           tagID          \n[5] power           lon             lat             source         \n&lt;0 rows&gt; (or 0-length row.names)\n\nData for receiver_data_3.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-06-25 18:53:37 DRY UPPER night    53    93  NA  NA receiver\n2 2024-06-25 18:53:39 DRY UPPER night    54    72  NA  NA receiver\n3 2024-06-25 22:50:34 DRY UPPER night    23   169  NA  NA receiver\n4 2024-06-25 22:50:35 DRY UPPER night    49   160  NA  NA receiver\n5 2024-06-26 05:23:35  AMETHYST   day    19   107  NA  NA receiver\n6 2024-06-26 05:23:42  AMETHYST   day    59   104  NA  NA receiver\n\nData for receiver_data_4.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-06-30 04:16:00  AMETHYST   day    15    16  NA  NA receiver\n2 2024-06-30 04:26:11 DRY UPPER   day    55   109  NA  NA receiver\n3 2024-06-30 04:26:16 DRY UPPER   day    22   114  NA  NA receiver\n4 2024-06-30 04:26:27 DRY UPPER   day    16   106  NA  NA receiver\n5 2024-06-30 04:26:36 DRY UPPER   day    22   123  NA  NA receiver\n6 2024-06-30 04:26:51 DRY UPPER   day    55   105  NA  NA receiver\n\nData for receiver_data_5.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-07-09 09:25:20 UNDERHILL   day    35   118  NA  NA receiver\n2 2024-07-09 10:04:53 UNDERHILL   day    33   188  NA  NA receiver\n3 2024-07-09 12:02:11 UNDERHILL   day    27   132  NA  NA receiver\n4 2024-07-09 12:15:44 UNDERHILL   day    36   152  NA  NA receiver\n5 2024-07-09 17:27:19 UNDERHILL night    41   108  NA  NA receiver\n6 2024-07-09 17:27:39 UNDERHILL night    41   102  NA  NA receiver\n\nData for receiver_data_6.csv :\n      trackedTime_EST  river shift tagID power lon lat   source\n1 2024-07-16 05:10:38 DICKEY   day    37    71  NA  NA receiver\n2 2024-07-16 06:52:51 DICKEY   day    31   132  NA  NA receiver\n3 2024-07-16 08:12:34 DICKEY   day    32    76  NA  NA receiver\n4 2024-07-16 08:12:35 DICKEY   day    38   111  NA  NA receiver\n5 2024-07-16 13:06:08 DICKEY night    31   133  NA  NA receiver\n6 2024-07-16 13:06:28 DICKEY night    31   122  NA  NA receiver\n\nData for receiver_data_7.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-07-23 08:42:36 DRY UPPER   day    16    81  NA  NA receiver\n2 2024-07-23 08:43:36 DRY UPPER   day    16   116  NA  NA receiver\n3 2024-07-23 08:43:56 DRY UPPER   day    16   168  NA  NA receiver\n4 2024-07-23 08:44:36 DRY UPPER   day    16   167  NA  NA receiver\n5 2024-07-23 08:52:16 DRY UPPER   day    16   150  NA  NA receiver\n6 2024-07-23 08:52:36 DRY UPPER   day    16   157  NA  NA receiver\n\nData for receiver_data_8.csv :\n      trackedTime_EST    river shift tagID power lon lat   source\n1 2024-07-30 13:17:03 AMETHYST night    15    24  NA  NA receiver\n2 2024-07-30 15:13:02   DICKEY night    31   202  NA  NA receiver\n3 2024-07-30 15:14:52   DICKEY night    26   159  NA  NA receiver\n4 2024-07-30 15:15:04   DICKEY night    37   170  NA  NA receiver\n5 2024-07-30 16:58:00   DICKEY night    31   202  NA  NA receiver\n6 2024-07-30 17:00:02   DICKEY night    37   145  NA  NA receiver\n\nData for receiver_data_9.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-08-06 08:01:51 UNDERHILL   day    35   180  NA  NA receiver\n2 2024-08-06 08:34:47 UNDERHILL   day    35   121  NA  NA receiver\n3 2024-08-06 08:35:07 UNDERHILL   day    35   170  NA  NA receiver\n4 2024-08-06 08:36:30 UNDERHILL   day    35   207  NA  NA receiver\n5 2024-08-06 08:46:04 UNDERHILL   day    44   123  NA  NA receiver\n6 2024-08-06 08:46:24 UNDERHILL   day    44   156  NA  NA receiver\n\nData for receiver_data_10.csv :\n      trackedTime_EST    river shift tagID power lon lat   source\n1 2024-08-13 04:17:33 AMETHYST   day    18    97  NA  NA receiver\n2 2024-08-13 04:17:40 AMETHYST   day    14   133  NA  NA receiver\n3 2024-08-13 04:17:53 AMETHYST   day    18   101  NA  NA receiver\n4 2024-08-13 04:18:00 AMETHYST   day    14   111  NA  NA receiver\n5 2024-08-13 05:26:57 AMETHYST   day    19   188  NA  NA receiver\n6 2024-08-13 06:04:32 AMETHYST   day    60   197  NA  NA receiver\n\nData for receiver_data_11.csv :\n      trackedTime_EST    river shift tagID power lon lat   source\n1 2024-08-20 08:50:34 AMETHYST   day    20    99  NA  NA receiver\n2 2024-08-20 08:50:46 AMETHYST   day    14   105  NA  NA receiver\n3 2024-08-20 08:50:54 AMETHYST   day    20    87  NA  NA receiver\n4 2024-08-20 08:50:55 AMETHYST   day    18    74  NA  NA receiver\n5 2024-08-20 08:51:07 AMETHYST   day    14    91  NA  NA receiver\n6 2024-08-20 08:51:15 AMETHYST   day    18    78  NA  NA receiver\n\nData for receiver_data_12.csv :\n      trackedTime_EST     river shift tagID power lon lat   source\n1 2024-08-27 09:16:33 DRY UPPER   day    16    39  NA  NA receiver\n2 2024-08-27 09:21:27 UNDERHILL   day    45   120  NA  NA receiver\n3 2024-08-27 09:22:07 UNDERHILL   day    45   139  NA  NA receiver\n4 2024-08-27 09:22:28 UNDERHILL   day    45   171  NA  NA receiver\n5 2024-08-27 09:22:47 UNDERHILL   day    45   205  NA  NA receiver\n6 2024-08-27 09:23:07 UNDERHILL   day    45   168  NA  NA receiver",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-fish-survey-and-receiver-data",
    "href": "creatingMyDatasheet.html#combine-fish-survey-and-receiver-data",
    "title": "2  Creating my Datasheet",
    "section": "2.7 Combine fish survey and receiver data",
    "text": "2.7 Combine fish survey and receiver data\n\n\nCode\n# No receiver data for this week yet #########################\n\n# Read in the fish_flow survey and receiver data for week 1\nfish_flow_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_1.csv\")\nreceiver_data_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_1.csv\")\n\n# Combine the datasets horizontally\n#fish_flow_receiver_1 &lt;- bind_rows(fish_flow_1, receiver_data_1)\n\n# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week\nfish_flow_receiver_1 &lt;- fish_flow_1\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_1)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-06-11 05:57:00 AMETHYST   day    59    NA  Riffle                Center\n2 2024-06-11 06:08:00 AMETHYST   day    60    NA  Riffle                Center\n3 2024-06-11 06:15:00   BUFFAM   day    19    NA  Riffle                Center\n4 2024-06-11 06:19:00   HARRIS   day    20    NA     Run                  Left\n5 2024-06-11 06:28:00   HARRIS   day    57    NA     Run                  Left\n6 2024-06-11 06:34:00   HARRIS   day    12    NA   Glide                Center\n  substrate substrateExtra         shade       lon      lat fishNotes source\n1      Rock             NA  Fully shaded -72.46038 42.38162             iPad\n2      Rock             NA  Fully shaded -72.46030 42.38136             iPad\n3      Rock             NA  Fully shaded -72.46023 42.38139             iPad\n4    Pebble             NA Mostly shaded -72.46015 42.38095             iPad\n5      Rock             NA Mostly shaded -72.46034 42.38105             iPad\n6      Rock             NA  Fully shaded -72.46009 42.38094             iPad\n  totalDischarge        flowTime_EST\n1           1.56                &lt;NA&gt;\n2           1.56                &lt;NA&gt;\n3           1.49 2024-06-11 08:32:26\n4           0.07 2024-06-11 09:42:47\n5           0.07 2024-06-11 09:42:47\n6           0.07 2024-06-11 09:42:47\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_1, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# No receiver data for this week yet #########################\n\n# Read in the fish_flow survey and receiver data for week 2\nfish_flow_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_2.csv\")\nreceiver_data_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_2.csv\")\n\n# Combine the datasets horizontally\n#fish_flow_receiver_2 &lt;- bind_rows(fish_flow_2, receiver_data_2)\n\n# Temporarily rename fish_flow dataset as fish_flow_receiver dataset until there is receiver data available for this week\nfish_flow_receiver_2 &lt;- fish_flow_2\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_2)\n\n\n      trackedTime_EST  river shift tagID power habitat  habitatExtra position\n1 2024-06-17 11:33:00 DICKEY   day    31    NA    Pool                 Center\n2 2024-06-17 11:57:00 DICKEY   day    46    NA     Run                  Right\n3 2024-06-17 11:59:00 DICKEY   day    29    NA  Riffle  Woody_debris     Left\n4 2024-06-17 12:10:00 DICKEY   day    26    NA     Run Undercut_bank    Right\n5 2024-06-17 12:47:00 DICKEY   day    28    NA    Pool                   Left\n6 2024-06-17 12:49:00 DICKEY   day    37    NA    Pool                  Right\n  substrate substrateExtra          shade       lon      lat fishNotes source\n1      Rock             NA  Mostly shaded -72.37084 42.44394             iPad\n2    Pebble             NA Lightly shaded -72.37173 42.44421             iPad\n3      Rock             NA   Fully shaded -72.37194 42.44430             iPad\n4      Rock             NA Lightly shaded -72.37344 42.44421             iPad\n5   Boulder             NA  Mostly shaded -72.37040 42.44369             iPad\n6      Rock             NA  Mostly shaded -72.37038 42.44377             iPad\n  totalDischarge        flowTime_EST\n1           0.03 2024-06-17 12:35:22\n2           0.03 2024-06-17 12:35:22\n3           0.03 2024-06-17 12:35:22\n4           0.03 2024-06-17 12:35:22\n5           0.03 2024-06-17 12:35:22\n6           0.03 2024-06-17 12:35:22\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_2, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 3\nfish_flow_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_3.csv\")\nreceiver_data_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_3.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_3 &lt;- bind_rows(fish_flow_3, receiver_data_3)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_3)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-25 05:59:00 DRY UPPER   day    55    NA    Pool\n2 2024-06-25 06:02:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-25 06:07:00 DRY UPPER   day    53    NA    Pool\n4 2024-06-25 06:11:00 DRY UPPER   day    22    NA    Pool\n5 2024-06-25 06:20:00 DRY UPPER   day    21    NA    Pool\n6 2024-06-25 06:21:00 DRY UPPER   day    25    NA    Pool\n                habitatExtra position substrate substrateExtra          shade\n1               Woody_debris   Center      Rock             NA  Mostly shaded\n2               Woody_debris    Right       Mud             NA  Mostly shaded\n3               Woody_debris    Right       Mud             NA  Mostly shaded\n4   Root_bundle,Woody_debris     Left       Mud             NA Lightly shaded\n5 Woody_debris,Undercut_bank    Right      Rock             NA  Mostly shaded\n6 Undercut_bank,Woody_debris    Right      Rock             NA  Mostly shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50451 42.66767             iPad           0.03 2024-06-25 07:21:55\n2 -72.50455 42.66774             iPad           0.03 2024-06-25 07:21:55\n3 -72.50451 42.66761             iPad           0.03 2024-06-25 07:21:55\n4 -72.50445 42.66767             iPad           0.03 2024-06-25 07:21:55\n5 -72.50506 42.66704             iPad           0.03 2024-06-25 07:21:55\n6 -72.50507 42.66704             iPad           0.03 2024-06-25 07:21:55\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_3, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 4\nfish_flow_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_4.csv\")\nreceiver_data_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_4.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_4 &lt;- bind_rows(fish_flow_4, receiver_data_4)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_4)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-30 04:39:00 DRY UPPER   day    22    NA    Pool\n2 2024-06-30 04:42:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-30 04:43:00 DRY UPPER   day    55    NA    Pool\n4 2024-06-30 04:50:00 DRY UPPER   day    21    NA    Pool\n5 2024-06-30 04:51:00 DRY UPPER   day    25    NA    Pool\n6 2024-06-30 04:51:00 DRY UPPER   day    24    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1                Root_bundle     Left        NA       Rock,Mud         Night\n2               Woody_debris    Right        NA            Mud  Fully shaded\n3               Woody_debris    Right        NA            Mud  Fully shaded\n4 Woody_debris,Undercut_bank    Right        NA            Mud Mostly shaded\n5 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n6 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50457 42.66769             iPad           0.33 2024-06-30 05:23:29\n2 -72.50448 42.66760             iPad           0.33 2024-06-30 05:23:29\n3 -72.50453 42.66762             iPad           0.33 2024-06-30 05:23:29\n4 -72.50514 42.66698             iPad           0.33 2024-06-30 05:23:29\n5 -72.50509 42.66699             iPad           0.33 2024-06-30 05:23:29\n6 -72.50508 42.66702             iPad           0.33 2024-06-30 05:23:29\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_4, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 5\nfish_flow_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_5.csv\")\nreceiver_data_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_5.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_5 &lt;- bind_rows(fish_flow_5, receiver_data_5)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_5)\n\n\n      trackedTime_EST     river shift tagID power habitat  habitatExtra\n1 2024-07-09 07:30:00 UNDERHILL   day    41    NA  Riffle              \n2 2024-07-09 07:49:00 UNDERHILL   day    40    NA  Riffle  Woody_debris\n3 2024-07-09 07:57:00 UNDERHILL   day    34    NA  Riffle              \n4 2024-07-09 08:08:00 UNDERHILL   day    33    NA  Riffle Undercut_bank\n5 2024-07-09 08:18:00 UNDERHILL   day    36    NA    Pool              \n6 2024-07-09 08:25:00 UNDERHILL   day    27    NA  Riffle              \n  position substrate   substrateExtra         shade       lon      lat\n1   Center        NA             Rock  Fully shaded -72.32447 42.44488\n2                 NA      Rock,Pebble Mostly shaded -72.32513 42.44510\n3   Center        NA             Rock               -72.32645 42.44537\n4    Right        NA             Rock Mostly shaded -72.32624 42.44533\n5   Center        NA Rock,Pebble,Sand Mostly shaded -72.32752 42.44626\n6   Center        NA             Rock Mostly shaded -72.32780 42.44521\n                                           fishNotes source totalDischarge\n1                                                      iPad           2.78\n2                                                      iPad           2.78\n3                                                      iPad           2.78\n4                                                      iPad           2.78\n5 Moved up from where we thought it might have died.   iPad           2.78\n6                                                      iPad           2.78\n         flowTime_EST\n1 2024-07-09 09:13:28\n2 2024-07-09 09:13:28\n3 2024-07-09 09:13:28\n4 2024-07-09 09:13:28\n5 2024-07-09 09:13:28\n6 2024-07-09 09:13:28\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_5, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 6\nfish_flow_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_6.csv\")\nreceiver_data_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_6.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_6 &lt;- bind_rows(fish_flow_6, receiver_data_6)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_6)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-16 03:49:00 DICKEY   day    31    NA  Riffle                Center\n2 2024-07-16 03:58:00 DICKEY   day    28    NA    Pool                Center\n3 2024-07-16 04:04:00 DICKEY   day    26    NA  Riffle                Center\n4 2024-07-16 04:05:00 DICKEY   day    37    NA  Riffle                Center\n5 2024-07-16 05:17:00 DICKEY   day    31    NA  Riffle                Center\n6 2024-07-16 05:21:00 DICKEY   day    28    NA    Pool                Center\n  substrate   substrateExtra        shade       lon      lat fishNotes source\n1        NA             Rock        Night -72.37121 42.44408             iPad\n2        NA         Sand,Mud        Night -72.37056 42.44364             iPad\n3        NA             Rock        Night -72.37030 42.44345             iPad\n4        NA             Rock Fully shaded -72.37018 42.44342             iPad\n5        NA        Rock,Sand Fully shaded -72.37132 42.44393             iPad\n6        NA Rock,Pebble,Sand Fully shaded -72.37059 42.44357             iPad\n  totalDischarge        flowTime_EST\n1           1.17 2024-07-16 05:02:37\n2           1.17 2024-07-16 05:02:37\n3           1.17 2024-07-16 05:02:37\n4           1.17 2024-07-16 05:02:37\n5           1.17 2024-07-16 05:02:37\n6           1.17 2024-07-16 05:02:37\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_6, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 7\nfish_flow_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_7.csv\")\nreceiver_data_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_7.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_7 &lt;- bind_rows(fish_flow_7, receiver_data_7)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_7)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-07-23 07:28:00 DRY UPPER   day  39.1    NA    Pool\n2 2024-07-23 07:56:00 DRY UPPER   day  46.1    NA        \n3 2024-07-23 08:07:00 DRY UPPER   day  29.1    NA  Riffle\n4 2024-07-23 08:44:00 DRY UPPER   day  30.1    NA    Pool\n5 2024-07-23 08:52:00 DRY UPPER   day  16.0    NA    Pool\n6 2024-07-23 09:06:00 DRY UPPER   day  55.0    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1               Woody_debris    Right        NA      Rock,Sand Mostly shaded\n2                                            NA                             \n3                                Left        NA                Mostly shaded\n4               Woody_debris     Left        NA            Mud Mostly shaded\n5 Woody_debris,Undercut_bank    Right        NA       Mud,Sand  Fully shaded\n6               Woody_debris                 NA      Rock,Sand Mostly shaded\n        lon      lat                                  fishNotes source\n1 -72.50687 42.66812                                              iPad\n2 -72.50700 42.66827                                       Dead   iPad\n3 -72.50598 42.66837 Very shallow water. Can’t see fish or tag.   iPad\n4 -72.50495 42.66817                                              iPad\n5 -72.50460 42.66775                          Up under cutback.   iPad\n6 -72.50408 42.66603                              Dead have tag   iPad\n  totalDischarge        flowTime_EST\n1           0.13 2024-07-23 08:27:20\n2           0.13 2024-07-23 08:27:20\n3           0.13 2024-07-23 08:27:20\n4           0.13 2024-07-23 08:27:20\n5           0.13 2024-07-23 08:27:20\n6           0.13 2024-07-23 08:27:20\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_7, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 8\nfish_flow_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_8.csv\")\nreceiver_data_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_8.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_8 &lt;- bind_rows(fish_flow_8, receiver_data_8)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_8)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-30 04:07:00 DICKEY   day    31    NA  Riffle                 Right\n2 2024-07-30 04:15:00 DICKEY   day    26    NA  Riffle                Center\n3 2024-07-30 04:16:00 DICKEY   day    37    NA  Riffle                Center\n4 2024-07-30 04:38:00 DICKEY   day    38    NA     Run                 Right\n5 2024-07-30 04:42:00 DICKEY   day    32    NA    Pool                  Left\n6 2024-07-30 05:25:00 DICKEY   day    38    NA  Riffle                  Left\n  substrate substrateExtra          shade       lon      lat\n1        NA    Pebble,Rock          Night -72.37116 42.44418\n2        NA    Rock,Pebble          Night -72.37034 42.44352\n3        NA    Rock,Pebble          Night -72.37032 42.44350\n4        NA    Rock,Pebble          Night -72.37335 42.44441\n5        NA         Pebble          Night -72.37354 42.44406\n6        NA    Rock,Pebble Lightly shaded -72.37340 42.44449\n                                               fishNotes source totalDischarge\n1                                                          iPad           1.13\n2                                                          iPad           1.13\n3                                                          iPad           1.13\n4                                                          iPad           1.13\n5 Dead.found on river left side of pool buried n gravel.   iPad           1.13\n6                                           May be dead    iPad           1.13\n         flowTime_EST\n1 2024-07-30 04:50:14\n2 2024-07-30 04:50:14\n3 2024-07-30 04:50:14\n4 2024-07-30 04:50:14\n5 2024-07-30 04:50:14\n6 2024-07-30 04:50:14\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_8, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 9\nfish_flow_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_9.csv\")\nreceiver_data_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_9.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_9 &lt;- bind_rows(fish_flow_9, receiver_data_9)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_9)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-08-05 11:06:00 DRY UPPER   day    49   174    Pool\n2 2024-08-05 11:35:00 DRY UPPER   day    47    NA        \n3 2024-08-05 11:37:00 DRY UPPER   day    47    54        \n4 2024-08-06 07:41:00 UNDERHILL   day    33    NA  Riffle\n5 2024-08-06 07:47:00 UNDERHILL   day    45    NA    Pool\n6 2024-08-06 07:53:00 UNDERHILL   day    44    NA    Pool\n                habitatExtra position substrate      substrateExtra\n1 Woody_debris,Undercut_bank                 NA Granule,Pebble,Sand\n2                                            NA                    \n3                                            NA                    \n4               Woody_debris   Center        NA         Pebble,Rock\n5                              Center        NA      Pebble,Granule\n6               Woody_debris   Center        NA           Rock,Sand\n           shade       lon      lat\n1 Lightly shaded -72.50352 42.65114\n2                -72.50353 42.65375\n3                -72.50367 42.65407\n4  Mostly shaded -72.32640 42.44531\n5  Mostly shaded -72.32773 42.44515\n6  Mostly shaded -72.32803 42.44488\n                                                                         fishNotes\n1              Bunch of fish swimming around, moving too much to get a good signal\n2 Lost signal, signal was strongest (74) back at the clearing with the pine trees \n3                                                                                 \n4                                                            Same so as last week.\n5                                                                                 \n6                                                                                 \n  source totalDischarge        flowTime_EST\n1   iPad           0.25 2024-08-07 08:20:43\n2   iPad           0.25 2024-08-07 08:20:43\n3   iPad           0.25 2024-08-07 08:20:43\n4   iPad           0.04 2024-08-06 08:06:36\n5   iPad           0.04 2024-08-06 08:06:36\n6   iPad           0.04 2024-08-06 08:06:36\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_9, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 10\nfish_flow_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_10.csv\")\nreceiver_data_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_10.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_10 &lt;- bind_rows(fish_flow_10, receiver_data_10)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_10)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-13 04:25:00   BUFFAM   day    60    NA     Run                Center\n2 2024-08-13 04:31:00   BUFFAM   day    18    NA     Run                Center\n3 2024-08-13 04:32:00   BUFFAM   day    14    NA  Riffle                Center\n4 2024-08-13 04:34:00   HARRIS   day    20    NA     Run Woody_debris   Center\n5 2024-08-13 04:41:00 AMETHYST   day    19    NA  Riffle                Center\n6 2024-08-13 05:15:00   BUFFAM   day    60    NA     Run                Center\n  substrate    substrateExtra        shade       lon      lat fishNotes source\n1        NA         Sand,Rock        Night -72.45838 42.38205             iPad\n2        NA Sand,Boulder,Rock        Night -72.45979 42.38119             iPad\n3        NA      Rock,Boulder        Night -72.46000 42.38136             iPad\n4        NA           Boulder        Night -72.46033 42.38118             iPad\n5        NA              Rock        Night -72.46088 42.38150             iPad\n6        NA         Sand,Rock Fully shaded -72.45866 42.38218             iPad\n  totalDischarge        flowTime_EST\n1           1.22 2024-08-13 04:57:46\n2           1.22 2024-08-13 04:57:46\n3           1.22 2024-08-13 04:57:46\n4           3.16 2024-08-13 06:51:21\n5           4.38                &lt;NA&gt;\n6           1.22 2024-08-13 04:57:46\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_10, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 11\nfish_flow_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_11.csv\")\nreceiver_data_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_11.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_11 &lt;- bind_rows(fish_flow_11, receiver_data_11)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_11)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-20 09:10:00 AMETHYST   day    19    NA  Riffle                Center\n2 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n3 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n4 2024-08-20 09:54:00   BUFFAM   day    14    NA  Riffle                 Right\n5 2024-08-20 09:54:00   BUFFAM   day    14    NA  Riffle                 Right\n6 2024-08-20 10:40:00   BUFFAM   day    18    NA  Riffle                Center\n  substrate       substrateExtra        shade       lon      lat fishNotes\n1        NA                 Rock Fully shaded -72.46090 42.38157          \n2        NA              Boulder Fully shaded -72.46016 42.38116          \n3        NA              Boulder Fully shaded -72.46016 42.38116          \n4        NA            Rock,Sand Fully shaded -72.46000 42.38126          \n5        NA            Rock,Sand Fully shaded -72.46000 42.38126          \n6        NA Rock,Boulder,Granule Fully shaded -72.45993 42.38124          \n  source totalDischarge        flowTime_EST\n1   iPad          21.70                &lt;NA&gt;\n2   iPad          13.48 2024-08-20 09:56:27\n3   iPad           3.87 2024-08-23 13:17:11\n4   iPad           3.53 2024-08-20 11:41:46\n5   iPad           0.82 2024-08-23 13:38:55\n6   iPad           3.53 2024-08-20 11:41:46\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_11, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow survey and receiver data for week 12\nfish_flow_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_12.csv\")\nreceiver_data_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/receiver_data_12.csv\")\n\n# Combine the datasets horizontally\nfish_flow_receiver_12 &lt;- bind_rows(fish_flow_12, receiver_data_12)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_12)\n\n\n      trackedTime_EST     river shift tagID power habitat habitatExtra position\n1 2024-08-27 09:41:00 UNDERHILL   day    45    NA    Pool           NA    Right\n2 2024-08-27 10:32:00 UNDERHILL   day    44    NA    Pool           NA   Center\n3 2024-08-27 12:19:00 UNDERHILL   day    35    NA    Pool           NA   Center\n4 2024-08-27 09:16:33 DRY UPPER   day    16    39    &lt;NA&gt;           NA     &lt;NA&gt;\n5 2024-08-27 09:21:27 UNDERHILL   day    45   120    &lt;NA&gt;           NA     &lt;NA&gt;\n6 2024-08-27 09:22:07 UNDERHILL   day    45   139    &lt;NA&gt;           NA     &lt;NA&gt;\n  substrate              substrateExtra         shade       lon      lat\n1        NA                   Sand,Rock  Fully shaded -72.32730 42.44535\n2        NA                   Sand,Rock Mostly shaded -72.32805 42.44492\n3        NA Boulder,Rock,Granule,Pebble Mostly shaded -72.32929 42.44359\n4        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n5        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n6        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n                                                                              fishNotes\n1                                                      Unsuccessful at finding shed tag\n2                                                      Unsuccessful at finding shed tag\n3 Unsuccessful at finding shed tag. It is most likely located in a hole under this rock\n4                                                                                  &lt;NA&gt;\n5                                                                                  &lt;NA&gt;\n6                                                                                  &lt;NA&gt;\n    source totalDischarge        flowTime_EST\n1     iPad           0.03 2024-08-27 10:16:23\n2     iPad           0.03 2024-08-27 10:16:23\n3     iPad           0.03 2024-08-27 10:16:23\n4 receiver             NA                &lt;NA&gt;\n5 receiver             NA                &lt;NA&gt;\n6 receiver             NA                &lt;NA&gt;\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_12, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_12.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-stream-surveys",
    "href": "creatingMyDatasheet.html#preparing-stream-surveys",
    "title": "2  Creating my Datasheet",
    "section": "2.8 Preparing Stream Surveys",
    "text": "2.8 Preparing Stream Surveys\n\n\nCode\n# Read in the stream survey data\nstream_survey_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 1.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_1$date &lt;- as.Date(stream_survey_1$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_1$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_1$date, \n                                                 stream_survey_1$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nstream_survey_1 &lt;- stream_survey_1 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_1)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       10 194410b8-fad1-4f4a-b9ae-db931320a22a 6/11/2024 9:02:30 PM\n2       11 996e0001-368b-469e-be69-b35706f03225 6/12/2024 5:34:05 AM\n3       12 d39f1e05-fdb2-4ec7-a8d7-cdc09af42fa1 6/12/2024 8:53:37 PM\n4       13 bba7b0ae-0b1a-4d98-a9d9-3e1879fbd191 6/13/2024 4:58:33 AM\n5       14 14ae17cc-97c4-46f0-a402-fe006e67630d 6/13/2024 8:52:46 PM\n6       15 dbbc0edb-a111-4ad3-80ad-4ba1cedeefdd 6/14/2024 5:06:20 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 6/18/2024 7:49:31 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/15/2024 1:21:10 PM\n3 jpilchik@contractor.usgs.gov_USGS 7/15/2024 1:57:10 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/15/2024 1:36:13 PM\n5 jpilchik@contractor.usgs.gov_USGS 7/15/2024 1:14:33 PM\n6 jpilchik@contractor.usgs.gov_USGS 7/15/2024 6:01:58 PM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-06-11 16:01      71\n2 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-06-11 17:13      68\n3 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-06-12 05:25      71\n4 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-06-12 18:55      68\n5 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-06-13 04:17      80\n6 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-06-13 17:47      78\n                       cloud  precip startTime endTime                 iso\n1 Partly cloudy/partly sunny No rain     06:30   12:00 AMTH202406111000EST\n2                     Cloudy No rain     17:14   23:20 AMTH202406111723EST\n3                      Clear No rain     05:26   10:58 UNDH202406120734EST\n4  Mostly sunny/mostly clear No rain     18:55   22:52 UNDH202406121908EST\n5                      Clear No rain     05:35   10:17 DCKY202406130851EST\n6  Mostly sunny/mostly clear No rain     17:48   22:44 DCKY202406131748EST\n  Notes isoTime downstreamGPS downstreamGain upstreamGPS upstreamGain         x\n1    NA   10:00            NA             NA          NA           NA   0.00000\n2    NA   17:23            NA             NA          NA           NA -72.46031\n3    NA   07:34            NA             NA          NA           NA -72.32535\n4    NA   19:08            NA             NA          NA           NA   0.00000\n5    NA   08:51            NA             NA          NA           NA   0.00000\n6    NA   17:48            NA             NA          NA           NA   0.00000\n         y        dateTime_EST shift\n1  0.00000 2024-06-11 06:30:00   day\n2 42.38131 2024-06-11 17:14:00 night\n3 42.44498 2024-06-12 05:26:00   day\n4  0.00000 2024-06-12 18:55:00 night\n5  0.00000 2024-06-13 05:35:00   day\n6  0.00000 2024-06-13 17:48:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_1, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 2.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_2$date &lt;- as.Date(stream_survey_2$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_2$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_2$date, \n                                                 stream_survey_2$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 11:00 EST to 17:00 EST\nstream_survey_2 &lt;- stream_survey_2 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 10 & hour(dateTime_EST) &lt; 18 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_2)\n\n\n  ObjectID                             GlobalID          CreationDate\n1       18 abf3a63a-078e-4b3e-a676-d1f9b5a9cbc6  6/18/2024 2:57:48 AM\n2       19 ce55f5cf-afe7-45e1-826f-56eb864ff94f 6/18/2024 11:22:40 AM\n3       20 15d07f1a-9b82-46f3-a0f6-2c3a908d733d  6/19/2024 3:01:27 AM\n4       21 658180f3-dbd8-436f-af75-81a163a59887 6/19/2024 10:24:55 AM\n5       22 bf046215-97fe-4a1a-9a60-98b4c5f4849d  6/20/2024 3:32:05 AM\n6       23 6e9a6bd8-6d27-401d-8b8c-eacb583d9af6 6/20/2024 10:39:52 AM\n                            Creator              EditDate\n1 jpilchik@contractor.usgs.gov_USGS  7/15/2024 1:39:28 PM\n2 jpilchik@contractor.usgs.gov_USGS 6/18/2024 11:22:40 AM\n3 jpilchik@contractor.usgs.gov_USGS  6/19/2024 3:01:27 AM\n4 jpilchik@contractor.usgs.gov_USGS 6/19/2024 10:24:55 AM\n5 jpilchik@contractor.usgs.gov_USGS  6/20/2024 3:32:05 AM\n6 jpilchik@contractor.usgs.gov_USGS 6/20/2024 10:39:52 AM\n                             Editor          stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-06-17 11:25      79\n2 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-06-17 23:46      65\n3 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-06-18 11:09      87\n4 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-06-18 23:38      70\n5 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-06-19 11:05      90\n6 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-06-19 23:42      78\n                       cloud  precip startTime endTime                 iso\n1 Partly cloudy/partly sunny No rain     11:26   17:00 DCKY202406171330EST\n2                      Clear No rain     23:45   04:55 DCKY202406180137EST\n3                      Clear No rain     11:18   17:00 AMTH202406181622EST\n4                      Clear No rain     23:40   04:33 AMTH202406182348EST\n5                      Clear No rain     11:06   16:00 DRYU202406191125EST\n6                      Clear No rain     23:42   05:07 DRYU202406192346EST\n  Notes isoTime downstreamGPS downstreamGain upstreamGPS upstreamGain         x\n1    NA   13:30            NA             NA          NA           NA -72.37172\n2    NA   01:37            NA             NA          NA           NA -72.37179\n3    NA   16:22            NA             NA          NA           NA -72.46521\n4    NA   23:48            NA             NA          NA           NA -72.46050\n5    NA   11:25            NA             NA          NA           NA -72.50835\n6    NA   23:46            NA             NA          NA           NA -72.50595\n         y        dateTime_EST shift\n1 42.44369 2024-06-17 11:26:00   day\n2 42.44426 2024-06-17 23:45:00 night\n3 42.38022 2024-06-18 11:18:00   day\n4 42.38134 2024-06-18 23:40:00 night\n5 42.66846 2024-06-19 11:06:00   day\n6 42.66847 2024-06-19 23:42:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_2, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 3.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_3$date &lt;- as.Date(stream_survey_3$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_3$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_3$date, \n                                                 stream_survey_3$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 5:00 EST to 11:00 EST\nstream_survey_3 &lt;- stream_survey_3 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 4 & hour(dateTime_EST) &lt; 12 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_3)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       26 e9430b87-ef0c-4960-8ad1-a995995af43c 6/25/2024 9:26:49 PM\n2       27 cd25042b-a084-45e8-aa62-cd2a7c6fd8d5 6/26/2024 4:39:50 AM\n3       28 3661f0c9-d52f-4c69-ba15-13f5fc71e195 6/26/2024 9:01:04 PM\n4       29 372ecdb0-8c48-4efa-81fc-e750f08d230b 6/27/2024 3:54:12 AM\n5       30 6f74a604-be50-4425-b683-084c84de2d1f 6/27/2024 9:01:19 PM\n6       31 eaa32524-f44b-489d-9825-d642aa04e554 6/28/2024 4:54:10 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 6/25/2024 9:26:49 PM\n2 jpilchik@contractor.usgs.gov_USGS 6/26/2024 4:39:50 AM\n3 jpilchik@contractor.usgs.gov_USGS 6/26/2024 9:01:04 PM\n4 jpilchik@contractor.usgs.gov_USGS 6/27/2024 3:54:12 AM\n5 jpilchik@contractor.usgs.gov_USGS 6/27/2024 9:01:19 PM\n6 jpilchik@contractor.usgs.gov_USGS 6/28/2024 4:54:10 AM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS       Dry (DRYU) 2024-06-25 05:43      57\n2 jpilchik@contractor.usgs.gov_USGS       Dry (DRYU) 2024-06-25 17:21      82\n3 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-06-26 05:25      70\n4 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-06-26 17:18      82\n5 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-06-27 05:17      66\n6 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-06-27 17:27      87\n                      cloud  precip startTime endTime                  iso\n1                     Clear No rain     05:44   10:44  DRYU202406250610EST\n2                    Cloudy No rain     17:21   23:05  DRYU202406251745EST\n3 Mostly sunny/mostly clear No rain     05:25   11:06  AMTH202406261101EST\n4                    Cloudy No rain     17:14   21:57  AMTH202406261915EST\n5                    Cloudy No rain     05:18   10:30 UNDH20240627 0807EST\n6                    Cloudy No rain     17:27   22:50  UNDH202406271916EST\n                                                                                                                                    Notes\n1 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n2                                                                                                                                        \n3                                                                                                                                        \n4                                                                                                                                        \n5                                                                                                                                        \n6                                                                                                                                        \n  isoTime                       downstreamGPS downstreamGain\n1   06:10             42.6353974. -72.4967190             65\n2   17:45   Lat: 42.665107 long: 72.5031943 W             75\n3   11:01      42 degrees 23N, 72 degrees 28W             74\n4   19:15  Lat-42.3792386’N Long-72.4633786’W             90\n5   08:07                                                 NA\n6   19:16 Lat: 42.27’N Long: 72.19’W +/-4.8 m             55\n                                                                  upstreamGPS\n1                                                      42.6694251 -72.5074050\n2                        Lat: 42.6683114 degrees N Long: 72.5066514 degrees W\n3                                              42 degrees 23N, 72 degrees 27W\n4 Buffim: lat-42.23’N long-72.28’W Harris: lat-42.3807166’N long-72.4581883’W\n5                                                                            \n6                                        Lat: 42.27’N Long: 72.20’W +/- 4.6 m\n  upstreamGain         x        y        dateTime_EST shift\n1           55   0.00000  0.00000 2024-06-25 05:44:00   day\n2           85   0.00000  0.00000 2024-06-25 17:21:00 night\n3           75   0.00000  0.00000 2024-06-26 05:25:00   day\n4           85 -72.45935 42.38128 2024-06-26 17:14:00 night\n5           NA -72.32505 42.44505 2024-06-27 05:18:00   day\n6           60   0.00000  0.00000 2024-06-27 17:27:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_3, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 4.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_4$date &lt;- as.Date(stream_survey_4$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_4$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_4$date, \n                                                 stream_survey_4$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nstream_survey_4 &lt;- stream_survey_4 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_4)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       34 cee16e3a-308a-4584-a9c4-0fb03105afd7 6/30/2024 2:29:49 PM\n2       35 3bf39ed4-ecb0-4394-8343-8dd7213871e1  7/1/2024 7:03:31 AM\n3       36 b363696b-4c8e-4455-85d4-c7ba7a39db51  7/1/2024 2:28:43 PM\n4       37 c894eaea-07c6-4870-b479-9d90ad9b6899  7/2/2024 6:58:57 AM\n5       38 56e53988-6efe-4ba1-8fe3-52f2556011ca  7/2/2024 3:05:35 PM\n6       39 5608a117-4ffe-4b49-a740-7fdb0912ec52  7/3/2024 7:14:44 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 6/30/2024 2:29:49 PM\n2 jpilchik@contractor.usgs.gov_USGS  7/1/2024 7:03:31 AM\n3 jpilchik@contractor.usgs.gov_USGS  7/1/2024 2:28:43 PM\n4 jpilchik@contractor.usgs.gov_USGS  7/2/2024 6:58:57 AM\n5 jpilchik@contractor.usgs.gov_USGS  7/2/2024 3:05:35 PM\n6 jpilchik@contractor.usgs.gov_USGS  7/8/2024 1:18:23 PM\n                             Editor          stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-06-30 03:56      71\n2 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-06-30 13:33      75\n3 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-01 03:32      59\n4 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-01 13:25      80\n5 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-02 03:22      64\n6 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-02 13:00      82\n                       cloud  precip startTime endTime                 iso\n1                     Cloudy No rain     03:57   08:55 DRYU202406300528EST\n2                     Cloudy No rain     13:34          DRYU20240631428EST\n3                      Clear No rain     03:28   08:37  DCKY20240701445EST\n4 Partly cloudy/partly sunny No rain     13:19   18:47 DCKY202407011412EST\n5                      Clear No rain     03:23         AMTH202407020529EST\n6                      Clear No rain     13:00   18:18  Amth20240701333EST\n                                                      Notes isoTime\n1                                                             05:28\n2                                                             14:28\n3                                                             04:45\n4 38 is way up by hunt road, 29s thermal tag was recovered    14:12\n5                                                             05:29\n6                                                    \\n\\n\\n   13:33\n                         downstreamGPS downstreamGain\n1 Lat: 42.6626558 N Long: 72.5044938 W             85\n2            42.6683792 N 72.5062250 W             74\n3 Lat: 42.4443189 N Long: 72.3720856 W             80\n4              42.4442662   72.3717833             65\n5            42.3792378 N 72.4631544 W             75\n6   Lat:42.3806414 N Long:72.4654265 W             75\n                                                                             upstreamGPS\n1                                                   Lat: 42.6688089 N Long: 72.5073252 W\n2                                                              42.6683792 N 72.5062250 W\n3                                                   Lat: 42.4416066 N Long: 72.3683132 W\n4                                                                42.4408761   72.3676351\n5                                                             42.3807546 N. 72.4584560 W\n6 Harris: Lat- 42.3806381N Long- 72.4586440 W Buffim: Lat-42.3820960 N Long-72.4583184 W\n  upstreamGain         x        y        dateTime_EST shift\n1           90 -72.50618 42.66849 2024-06-30 03:57:00   day\n2           74 -72.50456 42.66771 2024-06-30 13:34:00 night\n3           80 -72.37191 42.44431 2024-07-01 03:28:00   day\n4           70 -72.37122 42.44379 2024-07-01 13:19:00 night\n5           75   0.00000  0.00000 2024-07-02 03:23:00   day\n6           65 -72.45964 42.38119 2024-07-02 13:00:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_4, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 5.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_5$date &lt;- as.Date(stream_survey_5$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_5$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_5$date, \n                                                 stream_survey_5$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nstream_survey_5 &lt;- stream_survey_5 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_5)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       42 6869fc9a-9842-4aa9-83a8-76a3f3a57dba  7/9/2024 9:01:43 PM\n2       43 d85f66d1-d689-4bc4-a718-a9c99af79321 7/10/2024 1:51:21 AM\n3       44 1a44dffa-9703-4dbd-b750-6c73f7244214 7/10/2024 9:00:51 PM\n4       45 98aa054b-02e0-4c15-8917-4210691f10b6 7/11/2024 4:42:52 AM\n5       46 af3a3fdc-6eba-46fe-8048-f8b5c3870a30 7/11/2024 8:57:14 PM\n6       47 e70b72b5-7372-437c-9131-171b7d4cf1ae 7/12/2024 4:30:10 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS  7/9/2024 9:01:43 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/10/2024 1:51:21 AM\n3 jpilchik@contractor.usgs.gov_USGS 7/10/2024 9:00:51 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/11/2024 4:42:52 AM\n5 jpilchik@contractor.usgs.gov_USGS 7/11/2024 8:57:14 PM\n6 jpilchik@contractor.usgs.gov_USGS 7/12/2024 4:30:10 AM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-07-09 07:27      71\n2 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-07-09 18:46      75\n3 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-07-10 07:13      83\n4 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-07-10 17:16      81\n5 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-07-11 12:38      81\n6 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-07-11 17:25      83\n                       cloud        precip startTime endTime\n1                     Cloudy Moderate rain     07:28   12:39\n2              Mostly cloudy Moderate rain     17:30   19:49\n3                     Cloudy       No rain     07:13   12:43\n4 Partly cloudy/partly sunny       No rain     17:16   22:47\n5                     Cloudy     Weak rain     07:43   12:25\n6 Partly cloudy/partly sunny       No rain     17:22   22:37\n                                                            iso\n1                                           UNDH202407090734EST\n2                                           UNDH202407091730EST\n3                                            DCKY20240710749EST\n4                                                              \n5                                            AMTH20240711946EST\n6 BUFF202407112026EST, HARR202407112031EST, AMTH202407112036EST\n                      Notes isoTime                       downstreamGPS\n1                             07:27           42.4445523 N 72.3210041 W\n2 Thunder most of the night   17:30                                    \n3                             07:49           42.4419963.   -72.3735598\n4                             17:16 Lat:42.4439807 N Long: 72.3735109 W\n5                             09:46           42.3791708 N 72.4632400 W\n6                             20:26  Lat: 42.3802241 N Long: 72.4623015\n  downstreamGain                                               upstreamGPS\n1             75                                 42.4436600 W 72.3295537 N\n2             NA                                                          \n3             74                                 42.4373994 N 72.3647180 W\n4             50                       Lat: 42.4422845 N Long:72.3691477 W\n5             75                                 42.3807002 N 72.4582711 W\n6             85 Buffim- Lat: 42.3821137 N Long: 72.4566635 W Harris- Lat:\n  upstreamGain         x        y        dateTime_EST shift\n1           75 -72.32492 42.44495 2024-07-09 07:28:00   day\n2           NA -72.32516 42.44489 2024-07-09 17:30:00 night\n3           74   0.00000  0.00000 2024-07-10 07:13:00   day\n4           80   0.00000  0.00000 2024-07-10 17:16:00 night\n5           75   0.00000  0.00000 2024-07-11 07:43:00   day\n6           85 -72.45936 42.38138 2024-07-11 17:22:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_5, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 6.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_6$date &lt;- as.Date(stream_survey_6$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_6$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_6$date, \n                                                 stream_survey_6$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:00 EST to 9:00 EST\nstream_survey_6 &lt;- stream_survey_6 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 10 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_6)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       50 92649e1a-735a-40a0-b5b0-669692c32274 7/16/2024 2:45:20 PM\n2       51 5ad895f1-b196-4dfd-9e9e-94d03bb7d746 7/17/2024 7:02:22 AM\n3       52 a940133f-af11-4ff8-bc3e-bf1ff15c764b 7/17/2024 3:14:01 PM\n4       53 7159dfaf-5da1-4c60-a16b-74a5a92e08e3 7/18/2024 7:40:51 AM\n5       54 51389fe5-0685-4886-a482-304570f5f6d2 7/18/2024 3:04:41 PM\n6       55 7a8e5449-b58c-41a1-963f-2c9928220baf 7/19/2024 7:01:36 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 7/16/2024 2:45:20 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/17/2024 7:02:22 AM\n3 jpilchik@contractor.usgs.gov_USGS 7/17/2024 3:14:01 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/22/2024 1:54:20 PM\n5 jpilchik@contractor.usgs.gov_USGS 7/22/2024 1:52:02 PM\n6 jpilchik@contractor.usgs.gov_USGS 7/19/2024 7:01:36 AM\n                             Editor          stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-16 03:35      70\n2 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-16 13:12      85\n3 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-17 03:40      74\n4 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-17 13:21      88\n5 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-07-18 03:44      68\n6 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-07-18 12:55      83\n                      cloud  precip startTime endTime\n1                    Cloudy No rain     03:35   08:55\n2 Mostly sunny/mostly clear No rain     13:13   18:08\n3                     Clear No rain     03:44   09:00\n4                     Clear No rain     13:25   16:45\n5             Mostly cloudy No rain     03:45   09:12\n6                     Clear No rain     12:55   18:27\n                                                              iso\n1                                             DCKY202407160347EST\n2                                             DCKY202407161444EST\n3   BUFF202407170440EST, HARR202407170601EST, AMTH202407170611EST\n4 AMTH202407171527EST ,  BUFF02407171527EST , HARR202407171530EST\n5                                             DRYU202407180447EST\n6                                             DRYU202407181425EST\n                                                     Notes isoTime\n1                                                            03:47\n2                                                            14:44\n3                                                            04:40\n4          Had to leave early because of bad thunderstorms   15:27\n5 Walked all the way to lower dry looking for missing fis.   04:47\n6                                                            14:25\n                                                downstreamGPS downstreamGain\n1                                   42.4422631.N 72.3733436 W             70\n2                    Lat: 42.27 +/-7.6 N Long: 72.22 +/-7.6 W             80\n3                                   42.1794043 N 72.4630898 W             75\n4 42.3812014 N 72.4601705 W Harris: 42.3807410 N 72.4587332 W             80\n5                                     42.6586850 N 72.5041881             75\n6                                   42.6626352 N 72.5044535 W             75\n                           upstreamGPS upstreamGain         x        y\n1             42.4374180 N 72.346902 W           75 -72.37124 42.44404\n2       42.4430367 LAT. 72.3700836 LON           80   0.00000  0.00000\n3            42.3807796 N 72.4584831 W           75 -72.45965 42.38116\n4            42.3820773 N 72.4585361 W           80   0.00000  0.00000\n5            42.6691445 N 72.5075889 W           75   0.00000  0.00000\n6 Lat: 42.6691061 N Long: 72.5075635 W           75   0.00000  0.00000\n         dateTime_EST shift\n1 2024-07-16 03:35:00   day\n2 2024-07-16 13:13:00 night\n3 2024-07-17 03:44:00   day\n4 2024-07-17 13:25:00 night\n5 2024-07-18 03:45:00   day\n6 2024-07-18 12:55:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_6, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 7.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_7$date &lt;- as.Date(stream_survey_7$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_7$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_7$date, \n                                                 stream_survey_7$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nstream_survey_7 &lt;- stream_survey_7 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_7)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       58 8d80e210-e334-4e7d-9f9e-e378637bc01f 7/23/2024 9:37:18 PM\n2       59 df7093f9-fe03-4f17-b25f-a5f30cbeb213 7/24/2024 4:01:09 AM\n3       60 8ccd1f89-e854-4804-9f15-9b62eecd96ed 7/24/2024 9:05:36 PM\n4       61 a6b6cd96-6f06-48e7-bec8-2f81884ca2b1 7/25/2024 4:40:41 AM\n5       62 849f9605-680e-4b0c-92ef-efa4612d134d 7/25/2024 9:04:38 PM\n6       63 ad37290a-2764-4280-bb2c-e2c02bee83ef 7/26/2024 4:45:13 AM\n                            Creator              EditDate\n1 jpilchik@contractor.usgs.gov_USGS  7/23/2024 9:37:18 PM\n2 jpilchik@contractor.usgs.gov_USGS  7/24/2024 4:01:09 AM\n3 jpilchik@contractor.usgs.gov_USGS 7/29/2024 12:39:19 PM\n4 jpilchik@contractor.usgs.gov_USGS 7/29/2024 12:35:30 PM\n5 jpilchik@contractor.usgs.gov_USGS 7/29/2024 12:36:38 PM\n6 jpilchik@contractor.usgs.gov_USGS  7/26/2024 4:45:13 AM\n                             Editor          stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-07-23 07:27      83\n2 jpilchik@contractor.usgs.gov_USGS      Dry (DRYU) 2024-07-23 17:23      71\n3 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-24 09:27      78\n4 jpilchik@contractor.usgs.gov_USGS   Dickey (DCKY) 2024-07-24 17:10      75\n5 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-25 07:19      72\n6 jpilchik@contractor.usgs.gov_USGS Amethyst (AMTH) 2024-07-25 17:15      77\n          cloud        precip startTime endTime\n1 Mostly cloudy Moderate rain     07:27   13:24\n2        Cloudy       No rain     17:13   22:43\n3        Cloudy     Weak rain     07:22   12:44\n4        Cloudy       No rain     17:12   22:44\n5 Mostly cloudy       No rain     07:19   12:53\n6        Cloudy       No rain     17:16   22:43\n                                                            iso\n1                                           DRYU202407230833EST\n2                                           DRYU202407231815EST\n3                                           DCKY202407241048EST\n4                                           DCKY202407241830EST\n5 AMTH202407250833EST, HARR202407250833EST, BUFF202407250833EST\n6 HARR202407251920EST, AMTH202407252037EST, BUFF202407251815EST\n                                  Notes isoTime\n1                                         08:33\n2 There were a ton of 999/ error codes.   18:15\n3                                         10:48\n4                                         18:30\n5                                         08:33\n6                                         18:15\n                         downstreamGPS downstreamGain\n1          42.6342708 N , 72.4923600 W             60\n2 Lat:42.6587346 N Long: 72.50041230 W             75\n3            42.4422556 N 72.3734784 W             75\n4 Lat: 42.4439420 N Long: 72.3734095 W             75\n5            42.3811548 N 72.4602750 W             80\n6 Lat: 42.3794408 N Long: 72.4629074 W             75\n                                                                                upstreamGPS\n1                                                                   42.6682103 N 72.5069701\n2                                                      Lat: 42.6688091 N Long: 72.5076269 W\n3                                                                42.4373149 N 72.3546576 W \n4                                                       Lat:42.4429939 N Long: 72.3700608 W\n5                                                                 42.3020057 N 72.4583703 W\n6 Buffim- Lat: 42.3820122 N Long: 72.4584062 W Harris- Lat: 42.3805896 N Long: 72.4587733 W\n  upstreamGain         x        y        dateTime_EST shift\n1           75 -72.50764 42.66884 2024-07-23 07:27:00   day\n2           80   0.00000  0.00000 2024-07-23 17:13:00 night\n3           75 -72.37160 42.44381 2024-07-24 07:22:00   day\n4           75 -72.37159 42.44394 2024-07-24 17:12:00 night\n5           80   0.00000  0.00000 2024-07-25 07:19:00   day\n6           75   0.00000  0.00000 2024-07-25 17:16:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_7, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 8.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_8$date &lt;- as.Date(stream_survey_8$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_8$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_8$date, \n                                                 stream_survey_8$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 3:30 EST to 9:30 EST\nstream_survey_8 &lt;- stream_survey_8 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 2 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_8)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       66 1346e477-c5ec-40de-83f8-eb61532d3beb 7/30/2024 2:43:27 PM\n2       67 85842531-864a-4d9c-bc8c-f307ddf49db8 7/31/2024 7:35:34 AM\n3       68 4299598b-2e8a-4b7b-bb73-21768b48378a 7/31/2024 3:05:02 PM\n4       69 4e6e99bd-b136-43e3-b7bc-1599b46b7592  8/1/2024 7:34:47 AM\n5       70 c812273a-d64a-407d-ad22-a0ce77c6054a  8/1/2024 3:21:53 PM\n6       71 51be0e33-f712-47f0-a9cf-625d20637117  8/2/2024 8:08:35 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 7/30/2024 2:43:27 PM\n2 jpilchik@contractor.usgs.gov_USGS 7/31/2024 7:35:34 AM\n3 jpilchik@contractor.usgs.gov_USGS 8/5/2024 12:43:56 PM\n4 jpilchik@contractor.usgs.gov_USGS  8/1/2024 7:34:47 AM\n5 jpilchik@contractor.usgs.gov_USGS  8/1/2024 3:21:53 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/5/2024 12:43:19 PM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-07-30 03:50      67\n2 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-07-30 12:53      78\n3 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-07-31 04:10      79\n4 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-07-31 13:06      82\n5 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-01 03:50      72\n6 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-01 13:04      87\n                       cloud        precip startTime endTime\n1                     Cloudy       No rain     03:50   08:56\n2                     Cloudy       No rain     12:54   18:24\n3                     Cloudy Moderate rain     03:50   08:06\n4                     Cloudy       No rain     13:01   16:10\n5                      Clear       No rain     03:51   09:27\n6 Partly cloudy/partly sunny       No rain     13:04   18:32\n                                                          iso Notes isoTime\n1                                         DCKY202407300503EST    NA   05:03\n2                                         DCKY202407301355EST    NA   13:55\n3 HARR202407310650EST AMTH202407310658EST BUFF202407310447EST    NA   04:47\n4 AMTH202407311451EST BUFF202407311447EST HARR202407311447EST    NA   14:47\n5                                         UNDH202408010442EST    NA   04:42\n6                                         UNDH202408011308EST    NA   13:08\n                              downstreamGPS downstreamGain\n1                 42.4421397 N 72.3133907 W             70\n2      Lat: 42.4439938 N Long: 72.3734079 W             80\n3                 42.3815085 N 72.4605129 W             70\n4      Lat: 42.3802102 N Long: 72.4625902 W             80\n5 42.4442400 degrees N 72.3233604 degrees W             70\n6      Lat: 42.4444746 N Long: 72.3209563 W             80\n                                                                                upstreamGPS\n1                                                                  42.4373330 N 72.3646411W\n2                                                                 42.4436114 N 72.3703450 W\n3                                                                 42.3807633 N 72.4584379 W\n4 Buffim- Lat: 42.3818780 N Long: 72.4583519 W Harris- Lat: 42.3805731 N Long: 72.4586648 W\n5                                                                 42.4456778 N 72.3323930 W\n6                                                                    42.4455316, 72.3324642\n  upstreamGain         x        y        dateTime_EST shift\n1           70 -72.37105 42.44398 2024-07-30 03:50:00   day\n2           80   0.00000  0.00000 2024-07-30 12:54:00 night\n3           70 -72.45820 42.38193 2024-07-31 03:50:00   day\n4           80 -72.46045 42.38189 2024-07-31 13:01:00 night\n5           70 -72.32501 42.44502 2024-08-01 03:51:00   day\n6           80   0.00000  0.00000 2024-08-01 13:04:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_8, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 9.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_9$date &lt;- as.Date(stream_survey_9$date, \n                                format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_9$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_9$date, \n                                                 stream_survey_9$startTime), \n                                           format=\"%Y-%m-%d %H:%M\",\n                                           tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 7:00 EST to 13:00 EST\nstream_survey_9 &lt;- stream_survey_9 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 6 & hour(dateTime_EST) &lt; 14 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_9)\n\n\n  ObjectID                             GlobalID        CreationDate\n1       74 84a095f0-173b-481a-ad36-7a694fc62817 8/6/2024 6:25:06 PM\n2       75 8dea0b01-0296-492d-94df-d04b0e1cbfe4 8/7/2024 3:57:33 AM\n3       76 b0d49014-c729-4005-8bdb-473fa689f1f9 8/7/2024 5:59:47 PM\n4       77 a337d5fe-7fa6-4a86-a91a-6a4a551d9714 8/8/2024 3:32:39 AM\n5       78 7749d8e8-fa66-489b-90b4-9414eec942cd 8/8/2024 8:28:14 PM\n6       79 487107fc-84cf-4fc1-ae59-e25dfa60e24f 8/9/2024 3:15:51 AM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS  8/6/2024 6:25:06 PM\n2 jpilchik@contractor.usgs.gov_USGS  8/7/2024 3:57:33 AM\n3 jpilchik@contractor.usgs.gov_USGS  8/7/2024 5:59:47 PM\n4 jpilchik@contractor.usgs.gov_USGS  8/8/2024 3:32:39 AM\n5 jpilchik@contractor.usgs.gov_USGS  8/8/2024 8:28:14 PM\n6 jpilchik@contractor.usgs.gov_USGS 8/13/2024 8:37:31 PM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-06 07:20      72\n2 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-06 17:00      73\n3 jpilchik@contractor.usgs.gov_USGS       Dry (DRYU) 2024-08-07 06:59      60\n4 jpilchik@contractor.usgs.gov_USGS       Dry (DRYU) 2024-08-07 17:14      75\n5 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-08 07:32      63\n6 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-08 17:05      73\n                      cloud        precip startTime endTime\n1                    Cloudy     Weak rain     07:25   12:23\n2                    Cloudy     Weak rain     17:59   22:13\n3                    Cloudy     Weak rain     07:19   12:43\n4 Mostly sunny/mostly clear       No rain     17:14   22:12\n5             Mostly cloudy       No rain     07:35   13:34\n6                    Cloudy Moderate rain     17:00   22:17\n                                                          iso\n1                                         UNDH202408060810EST\n2                                         UNDH202408061801EST\n3                                          DRY202408071031EST\n4                                         DRYU202408072002EST\n5  BUFF20240801040EST HARR202408081041EST AMTH202408081045EST\n6 BUFF202408082007EST HARR202408082026EST AMTH202408082013EST\n                                                                                                                  Notes\n1 Found a dead fish, cut it open to make sure it wasn’t a tagged fish and there wasn’t a dead tag inside (no tag found)\n2                                                                                                                      \n3                                                                                                                      \n4                                                                                                                    \\n\n5                                                                                                                      \n6                                                                                                                      \n  isoTime                              downstreamGPS downstreamGain\n1   08:10 42.4442161 degrees N, 72.3234504 degrees W             70\n2   18:01        Lat:42.4442383 N Long: 72.3236331 W             80\n3   10:31 42.6586929 degrees N, 72.5041623 degrees W             70\n4   20:02           Lat 42.6619051.  Lon 72.50446738             80\n5   10:40                   42.3794084 N 72.4628350W             70\n6   20:07              Lat 42.3813265 Lon 72.4609471             80\n                                                                upstreamGPS\n1                                42.4459050 degrees N, 72.3317080 degrees W\n2                                           Lat 42.4436998. Long 72.3297100\n3                                42.6680512 degrees N, 72.5067974 degrees W\n4                                             Lat 42.6684551 Lon 72.5079943\n5                                                 42.3808097 N 72.4584604 W\n6 Buffum lat 42.3821350 Lon 72.4585148 harris lat 42.3813420 Lon 72.4589892\n  upstreamGain         x        y        dateTime_EST shift\n1           70 -72.32503 42.44526 2024-08-06 07:25:00   day\n2           45 -72.32493 42.44484 2024-08-06 17:59:00 night\n3           70   0.00000  0.00000 2024-08-07 07:19:00   day\n4           80 -72.50564 42.66836 2024-08-07 17:14:00 night\n5           70   0.00000  0.00000 2024-08-08 07:35:00   day\n6           80   0.00000  0.00000 2024-08-08 17:00:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_9, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 10.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_10$date &lt;- as.Date(stream_survey_10$date, \n                                 format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_10$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_10$date, \n                                                  stream_survey_10$startTime), \n                                            format=\"%Y-%m-%d %H:%M\",\n                                            tz = \"EST\")\n\n# Add Shift column based on the time ranges\n# Day shifts were from 4:00 EST to 10:00 EST\nstream_survey_10 &lt;- stream_survey_10 %&gt;%\n  mutate(\n    shift = case_when(\n        hour(dateTime_EST) &gt;= 3 & hour(dateTime_EST) &lt; 11 ~ \"day\",\n        TRUE ~ \"night\"  # Any other time is night shift\n    )\n  )\n\n# Display the first few rows to check the result\nhead(stream_survey_10)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       81 7fcbbe73-7c22-4c6e-9e40-844d4102aa1f 8/13/2024 2:23:51 PM\n2       82 986c88d3-f7d1-450a-997e-bfd67a39a8b9 8/14/2024 8:07:54 AM\n3       83 ee287240-dd14-4b5c-993c-666e2de4fd65 8/14/2024 2:38:12 PM\n4       84 beed0318-efdc-4713-a3be-a899684ae7bd 8/15/2024 8:05:58 AM\n5       85 6e03d36e-f517-42e1-a1a0-de8ac8868ff5 8/15/2024 3:16:01 PM\n6       86 21a1ee25-b5dc-4a25-9677-21f72af8d4ea 8/16/2024 8:37:13 AM\n                            Creator              EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/19/2024 12:52:31 PM\n2 jpilchik@contractor.usgs.gov_USGS  8/14/2024 8:07:54 AM\n3 jpilchik@contractor.usgs.gov_USGS 8/19/2024 12:47:14 PM\n4 jpilchik@contractor.usgs.gov_USGS  8/15/2024 8:05:58 AM\n5 jpilchik@contractor.usgs.gov_USGS  8/15/2024 3:16:01 PM\n6 jpilchik@contractor.usgs.gov_USGS  8/16/2024 8:37:13 AM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-13 04:16      63\n2 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-13 13:07      79\n3 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-14 04:07      58\n4 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-14 13:19      79\n5 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-08-15 04:16      60\n6 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-08-15 13:04      80\n                       cloud  precip startTime endTime\n1                      Clear No rain     04:16   09:26\n2 Partly cloudy/partly sunny No rain     13:07   19:02\n3                      Clear No rain     04:08   09:23\n4 Partly cloudy/partly sunny No rain     13:19   18:42\n5                      Clear No rain     04:17   09:27\n6              Mostly cloudy No rain     13:04   16:14\n                                                            iso Notes isoTime\n1   BUFF202408130524EST HARR202408130510EST AMTH202408130516EST    NA   05:10\n2 BUFF202408131516EST, AMTH202408131520EST, HARR202408131523EST    NA   15:16\n3                                           UNDH202408140454EST    NA   04:54\n4                                           UNDH202408141620EST    NA   16:20\n5                                           DCKY202408150535EST    NA   05:35\n6                                           DCKY202408151517EST    NA   15:17\n                         downstreamGPS downstreamGain\n1 Lat: 42.3808032 N Long: 72.4615415 W             80\n2               42.3802433, 72.4651203             75\n3 Lat: 42.4368660 N Long: 72.3214536 W             75\n4               42.4447508, 72.3208196             75\n5  Lat:42.4444510 N Long: 72.3733538 W             80\n6               42.4423240, 72.3733392             75\n                                                upstreamGPS upstreamGain\n1                      Lat: 42.3820586 N Long: 72.4585239 W           80\n2 HARR 42.3803763, 72.4535804;  BUFF 42.3836141, 72.4561609           75\n3                      Lat: 42.4438604 N Long: 72.3296500 W           75\n4                                    42.4435654, 72.3298756           75\n5                      Lat: 42.4435049 N Long: 72.3703123 W           80\n6                                    42.4375408, 72.3650235           75\n          x        y        dateTime_EST shift\n1   0.00000  0.00000 2024-08-13 04:16:00   day\n2   0.00000  0.00000 2024-08-13 13:07:00 night\n3   0.00000  0.00000 2024-08-14 04:08:00   day\n4 -72.32504 42.44505 2024-08-14 13:19:00 night\n5 -72.37136 42.44378 2024-08-15 04:17:00   day\n6   0.00000  0.00000 2024-08-15 13:04:00 night\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_10, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 11.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_11$date &lt;- as.Date(stream_survey_11$date, \n                                 format = \"%m/%d/%Y\")\n\n# Combine the date and start time into a DateTime column\nstream_survey_11$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_11$date, \n                                                  stream_survey_11$startTime), \n                                            format=\"%Y-%m-%d %H:%M\",\n                                            tz = \"EST\")\n\n# Add Shift column \n# All shifts in week 11 were day shifts\nstream_survey_11 &lt;- stream_survey_11 %&gt;%\n  mutate(shift = \"day\")\n\n# Display the first few rows to check the result\nhead(stream_survey_11)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       89 b7de34af-f9e3-47b9-b6a3-bf89b1dc556b 8/20/2024 6:44:07 PM\n2       90 32604089-0f3d-41d6-939b-4cbdf32d8dce 8/21/2024 6:39:18 PM\n3       91 fcde118a-5d63-460a-a477-dd67a4cd688a 8/22/2024 9:50:02 PM\n4       92 20759715-9907-4e3f-b40f-4bf642f461fc 8/23/2024 7:52:09 PM\n                            Creator              EditDate\n1 jpilchik@contractor.usgs.gov_USGS  8/20/2024 6:44:07 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/29/2024 12:11:09 PM\n3 jpilchik@contractor.usgs.gov_USGS 8/29/2024 12:12:20 PM\n4 jpilchik@contractor.usgs.gov_USGS  8/23/2024 7:52:09 PM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-20 09:31      68\n2 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-21 08:25      63\n3 jpilchik@contractor.usgs.gov_USGS       Dry (DRYU) 2024-08-22 07:55      60\n4 jpilchik@contractor.usgs.gov_USGS  Amethyst (AMTH) 2024-08-23 11:15      73\n   cloud  precip startTime endTime\n1 Cloudy No rain     09:00   13:37\n2  Clear No rain     08:25   13:00\n3  Clear No rain     07:55   16:30\n4  Clear No rain     09:00   13:57\n                                                            iso\n1 BUFF202408201044EST, AMTH202408201047EST, HARR202408200947EST\n2                                           UNDH202408210929EST\n3                                           DRYU202408220918EST\n4 BUFF202408231125EST, HARR202408231130EST, AMTH202408231150EST\n                    Notes isoTime downstreamGPS downstreamGain upstreamGPS\n1                           09:47            NA             NA          NA\n2 Day of fish collection    09:29            NA             NA          NA\n3                           09:18            NA             NA          NA\n4                           11:25            NA             NA          NA\n  upstreamGain         x        y        dateTime_EST shift\n1           NA -72.46077 42.38147 2024-08-20 09:00:00   day\n2           NA -72.32425 42.44456 2024-08-21 08:25:00   day\n3           NA -72.50821 42.66856 2024-08-22 07:55:00   day\n4           NA   0.00000  0.00000 2024-08-23 09:00:00   day\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_11, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the stream survey data\nstream_survey_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Stream Survey Week 12.csv\")\n\n# Convert date to remove the incorrect associated time and keep only the date \n# Adjust date into the correct format\nstream_survey_12$date &lt;- as.Date(stream_survey_12$date, \n                                 format = \"%m/%d/%Y\")\n\n# Combining the date and start time into a DateTime column\nstream_survey_12$dateTime_EST &lt;- as.POSIXct(paste(stream_survey_12$date, \n                                                  stream_survey_12$startTime), \n                                            format=\"%Y-%m-%d %H:%M\",\n                                            tz = \"EST\")\n\n# Add Shift column\n# All shifts in week 12 were day shifts\nstream_survey_12 &lt;- stream_survey_12 %&gt;%\n  mutate(shift = \"day\")\n\n# Display the first few rows to check the result\nhead(stream_survey_12)\n\n\n  ObjectID                             GlobalID         CreationDate\n1       93 fe88f142-5937-4bd6-a4fc-71dfd7a6664a 8/29/2024 5:34:57 PM\n2       95 e68186aa-b432-4de7-8357-b010a63d2a90 8/29/2024 5:34:59 PM\n                            Creator             EditDate\n1 jpilchik@contractor.usgs.gov_USGS 8/29/2024 5:34:57 PM\n2 jpilchik@contractor.usgs.gov_USGS 8/29/2024 5:34:59 PM\n                             Editor           stream       date  time airTemp\n1 jpilchik@contractor.usgs.gov_USGS Underhill (UNDH) 2024-08-27 09:25      80\n2 jpilchik@contractor.usgs.gov_USGS    Dickey (DCKY) 2024-08-29 09:34      67\n          cloud  precip startTime endTime                 iso Notes isoTime\n1         Clear No rain     09:04   12:48 UNDH202408271016EST    NA   10:16\n2 Mostly cloudy No rain     09:35   12:00 DCKY202408291022EST    NA   10:22\n  downstreamGPS downstreamGain upstreamGPS upstreamGain         x        y\n1            NA             NA          NA           NA -72.32731 42.44535\n2            NA             NA          NA           NA   0.00000  0.00000\n         dateTime_EST shift\n1 2024-08-27 09:04:00   day\n2 2024-08-29 09:35:00   day\n\n\nCode\n# Write new stream survey csv\nwrite.csv(stream_survey_12, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_12.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Define file names\nstream_file_names &lt;- c(\"stream_survey_1.csv\", \"stream_survey_2.csv\", \"stream_survey_3.csv\", \"stream_survey_4.csv\", \n                       \"stream_survey_5.csv\", \"stream_survey_6.csv\", \"stream_survey_7.csv\", \"stream_survey_8.csv\", \n                       \"stream_survey_9.csv\", \"stream_survey_10.csv\", \"stream_survey_11.csv\", \"stream_survey_12.csv\") \n\n# Define a lookup table for stream names\nstream_name_lookup &lt;- data.frame(\n  abbreviation = c(\"Dickey (DCKY)\", \"Amethyst (AMTH)\", \n                   \"Underhill (UNDH)\", \"Dry (DRYU)\"),  # List all abbreviations\n  full_name = c(\"DICKEY\", \"AMETHYST\", \n                \"UNDERHILL\", \"DRY UPPER\")  # Corresponding full names\n)\n\n# Create an empty list to store the processed datasets\nprocessed_stream_data_list &lt;- list()\n\n# Loop through each stream survey file\nfor (file_name in stream_file_names) {\n  \n  # Read in the stream survey data\n  raw_stream_data &lt;- read.csv(file_name)\n  \n  # Step 1: Process the data\n  stream_data &lt;- raw_stream_data %&gt;%\n    \n    # Step 2: Select specific columns\n    select(stream, airTemp, cloud, precip, startTime, endTime, iso, Notes, \n           isoTime, downstreamGPS, downstreamGain, upstreamGPS, upstreamGain, shift) %&gt;%\n\n    # Step 3: Rename columns\n    rename(\n      streamNotes = Notes,\n      river = stream,\n      startTime_EST = startTime,\n      endTime_EST = endTime,\n      isoID = iso,\n      isoTime_EST = isoTime) %&gt;%\n    \n    # Step 4: Rewrite stream names\n    left_join(stream_name_lookup, by = c(\"river\" = \"abbreviation\")) %&gt;%\n    mutate(\n      river = coalesce(full_name, river)  # Replace Brook with full_name, if available\n    ) %&gt;%\n    select(-full_name)  # Remove the full_name column as it's no longer needed\n  \n  # Store the processed data in the list\n  processed_stream_data_list[[file_name]] &lt;- stream_data\n  \n  # Overwrite the original file with the processed data\n  write.csv(stream_data, file_name, row.names = FALSE)\n}\n\n# Display the first few rows of each processed dataset\nfor (i in 1:length(processed_stream_data_list)) {\n  cat(\"\\nData for\", stream_file_names[i], \":\\n\")\n  print(head(processed_stream_data_list[[i]]))\n}\n\n\n\nData for stream_survey_1.csv :\n      river airTemp                      cloud  precip startTime_EST\n1  AMETHYST      71 Partly cloudy/partly sunny No rain         06:30\n2  AMETHYST      68                     Cloudy No rain         17:14\n3 UNDERHILL      71                      Clear No rain         05:26\n4 UNDERHILL      68  Mostly sunny/mostly clear No rain         18:55\n5    DICKEY      80                      Clear No rain         05:35\n6    DICKEY      78  Mostly sunny/mostly clear No rain         17:48\n  endTime_EST               isoID streamNotes isoTime_EST downstreamGPS\n1       12:00 AMTH202406111000EST          NA       10:00            NA\n2       23:20 AMTH202406111723EST          NA       17:23            NA\n3       10:58 UNDH202406120734EST          NA       07:34            NA\n4       22:52 UNDH202406121908EST          NA       19:08            NA\n5       10:17 DCKY202406130851EST          NA       08:51            NA\n6       22:44 DCKY202406131748EST          NA       17:48            NA\n  downstreamGain upstreamGPS upstreamGain shift\n1             NA          NA           NA   day\n2             NA          NA           NA night\n3             NA          NA           NA   day\n4             NA          NA           NA night\n5             NA          NA           NA   day\n6             NA          NA           NA night\n\nData for stream_survey_2.csv :\n      river airTemp                      cloud  precip startTime_EST\n1    DICKEY      79 Partly cloudy/partly sunny No rain         11:26\n2    DICKEY      65                      Clear No rain         23:45\n3  AMETHYST      87                      Clear No rain         11:18\n4  AMETHYST      70                      Clear No rain         23:40\n5 DRY UPPER      90                      Clear No rain         11:06\n6 DRY UPPER      78                      Clear No rain         23:42\n  endTime_EST               isoID streamNotes isoTime_EST downstreamGPS\n1       17:00 DCKY202406171330EST          NA       13:30            NA\n2       04:55 DCKY202406180137EST          NA       01:37            NA\n3       17:00 AMTH202406181622EST          NA       16:22            NA\n4       04:33 AMTH202406182348EST          NA       23:48            NA\n5       16:00 DRYU202406191125EST          NA       11:25            NA\n6       05:07 DRYU202406192346EST          NA       23:46            NA\n  downstreamGain upstreamGPS upstreamGain shift\n1             NA          NA           NA   day\n2             NA          NA           NA night\n3             NA          NA           NA   day\n4             NA          NA           NA night\n5             NA          NA           NA   day\n6             NA          NA           NA night\n\nData for stream_survey_3.csv :\n      river airTemp                     cloud  precip startTime_EST endTime_EST\n1 DRY UPPER      57                     Clear No rain         05:44       10:44\n2 DRY UPPER      82                    Cloudy No rain         17:21       23:05\n3  AMETHYST      70 Mostly sunny/mostly clear No rain         05:25       11:06\n4  AMETHYST      82                    Cloudy No rain         17:14       21:57\n5 UNDERHILL      66                    Cloudy No rain         05:18       10:30\n6 UNDERHILL      87                    Cloudy No rain         17:27       22:50\n                 isoID\n1  DRYU202406250610EST\n2  DRYU202406251745EST\n3  AMTH202406261101EST\n4  AMTH202406261915EST\n5 UNDH20240627 0807EST\n6  UNDH202406271916EST\n                                                                                                                              streamNotes\n1 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n2                                                                                                                                        \n3                                                                                                                                        \n4                                                                                                                                        \n5                                                                                                                                        \n6                                                                                                                                        \n  isoTime_EST                       downstreamGPS downstreamGain\n1       06:10             42.6353974. -72.4967190             65\n2       17:45   Lat: 42.665107 long: 72.5031943 W             75\n3       11:01      42 degrees 23N, 72 degrees 28W             74\n4       19:15  Lat-42.3792386’N Long-72.4633786’W             90\n5       08:07                                                 NA\n6       19:16 Lat: 42.27’N Long: 72.19’W +/-4.8 m             55\n                                                                  upstreamGPS\n1                                                      42.6694251 -72.5074050\n2                        Lat: 42.6683114 degrees N Long: 72.5066514 degrees W\n3                                              42 degrees 23N, 72 degrees 27W\n4 Buffim: lat-42.23’N long-72.28’W Harris: lat-42.3807166’N long-72.4581883’W\n5                                                                            \n6                                        Lat: 42.27’N Long: 72.20’W +/- 4.6 m\n  upstreamGain shift\n1           55   day\n2           85 night\n3           75   day\n4           85 night\n5           NA   day\n6           60 night\n\nData for stream_survey_4.csv :\n      river airTemp                      cloud  precip startTime_EST\n1 DRY UPPER      71                     Cloudy No rain         03:57\n2 DRY UPPER      75                     Cloudy No rain         13:34\n3    DICKEY      59                      Clear No rain         03:28\n4    DICKEY      80 Partly cloudy/partly sunny No rain         13:19\n5  AMETHYST      64                      Clear No rain         03:23\n6  AMETHYST      82                      Clear No rain         13:00\n  endTime_EST               isoID\n1       08:55 DRYU202406300528EST\n2              DRYU20240631428EST\n3       08:37  DCKY20240701445EST\n4       18:47 DCKY202407011412EST\n5             AMTH202407020529EST\n6       18:18  Amth20240701333EST\n                                                streamNotes isoTime_EST\n1                                                                 05:28\n2                                                                 14:28\n3                                                                 04:45\n4 38 is way up by hunt road, 29s thermal tag was recovered        14:12\n5                                                                 05:29\n6                                                    \\n\\n\\n       13:33\n                         downstreamGPS downstreamGain\n1 Lat: 42.6626558 N Long: 72.5044938 W             85\n2            42.6683792 N 72.5062250 W             74\n3 Lat: 42.4443189 N Long: 72.3720856 W             80\n4              42.4442662   72.3717833             65\n5            42.3792378 N 72.4631544 W             75\n6   Lat:42.3806414 N Long:72.4654265 W             75\n                                                                             upstreamGPS\n1                                                   Lat: 42.6688089 N Long: 72.5073252 W\n2                                                              42.6683792 N 72.5062250 W\n3                                                   Lat: 42.4416066 N Long: 72.3683132 W\n4                                                                42.4408761   72.3676351\n5                                                             42.3807546 N. 72.4584560 W\n6 Harris: Lat- 42.3806381N Long- 72.4586440 W Buffim: Lat-42.3820960 N Long-72.4583184 W\n  upstreamGain shift\n1           90   day\n2           74 night\n3           80   day\n4           70 night\n5           75   day\n6           65 night\n\nData for stream_survey_5.csv :\n      river airTemp                      cloud        precip startTime_EST\n1 UNDERHILL      71                     Cloudy Moderate rain         07:28\n2 UNDERHILL      75              Mostly cloudy Moderate rain         17:30\n3    DICKEY      83                     Cloudy       No rain         07:13\n4    DICKEY      81 Partly cloudy/partly sunny       No rain         17:16\n5  AMETHYST      81                     Cloudy     Weak rain         07:43\n6  AMETHYST      83 Partly cloudy/partly sunny       No rain         17:22\n  endTime_EST                                                         isoID\n1       12:39                                           UNDH202407090734EST\n2       19:49                                           UNDH202407091730EST\n3       12:43                                            DCKY20240710749EST\n4       22:47                                                              \n5       12:25                                            AMTH20240711946EST\n6       22:37 BUFF202407112026EST, HARR202407112031EST, AMTH202407112036EST\n                streamNotes isoTime_EST                       downstreamGPS\n1                                 07:27           42.4445523 N 72.3210041 W\n2 Thunder most of the night       17:30                                    \n3                                 07:49           42.4419963.   -72.3735598\n4                                 17:16 Lat:42.4439807 N Long: 72.3735109 W\n5                                 09:46           42.3791708 N 72.4632400 W\n6                                 20:26  Lat: 42.3802241 N Long: 72.4623015\n  downstreamGain                                               upstreamGPS\n1             75                                 42.4436600 W 72.3295537 N\n2             NA                                                          \n3             74                                 42.4373994 N 72.3647180 W\n4             50                       Lat: 42.4422845 N Long:72.3691477 W\n5             75                                 42.3807002 N 72.4582711 W\n6             85 Buffim- Lat: 42.3821137 N Long: 72.4566635 W Harris- Lat:\n  upstreamGain shift\n1           75   day\n2           NA night\n3           74   day\n4           80 night\n5           75   day\n6           85 night\n\nData for stream_survey_6.csv :\n      river airTemp                     cloud  precip startTime_EST endTime_EST\n1    DICKEY      70                    Cloudy No rain         03:35       08:55\n2    DICKEY      85 Mostly sunny/mostly clear No rain         13:13       18:08\n3  AMETHYST      74                     Clear No rain         03:44       09:00\n4  AMETHYST      88                     Clear No rain         13:25       16:45\n5 DRY UPPER      68             Mostly cloudy No rain         03:45       09:12\n6 DRY UPPER      83                     Clear No rain         12:55       18:27\n                                                            isoID\n1                                             DCKY202407160347EST\n2                                             DCKY202407161444EST\n3   BUFF202407170440EST, HARR202407170601EST, AMTH202407170611EST\n4 AMTH202407171527EST ,  BUFF02407171527EST , HARR202407171530EST\n5                                             DRYU202407180447EST\n6                                             DRYU202407181425EST\n                                               streamNotes isoTime_EST\n1                                                                03:47\n2                                                                14:44\n3                                                                04:40\n4          Had to leave early because of bad thunderstorms       15:27\n5 Walked all the way to lower dry looking for missing fis.       04:47\n6                                                                14:25\n                                                downstreamGPS downstreamGain\n1                                   42.4422631.N 72.3733436 W             70\n2                    Lat: 42.27 +/-7.6 N Long: 72.22 +/-7.6 W             80\n3                                   42.1794043 N 72.4630898 W             75\n4 42.3812014 N 72.4601705 W Harris: 42.3807410 N 72.4587332 W             80\n5                                     42.6586850 N 72.5041881             75\n6                                   42.6626352 N 72.5044535 W             75\n                           upstreamGPS upstreamGain shift\n1             42.4374180 N 72.346902 W           75   day\n2       42.4430367 LAT. 72.3700836 LON           80 night\n3            42.3807796 N 72.4584831 W           75   day\n4            42.3820773 N 72.4585361 W           80 night\n5            42.6691445 N 72.5075889 W           75   day\n6 Lat: 42.6691061 N Long: 72.5075635 W           75 night\n\nData for stream_survey_7.csv :\n      river airTemp         cloud        precip startTime_EST endTime_EST\n1 DRY UPPER      83 Mostly cloudy Moderate rain         07:27       13:24\n2 DRY UPPER      71        Cloudy       No rain         17:13       22:43\n3    DICKEY      78        Cloudy     Weak rain         07:22       12:44\n4    DICKEY      75        Cloudy       No rain         17:12       22:44\n5  AMETHYST      72 Mostly cloudy       No rain         07:19       12:53\n6  AMETHYST      77        Cloudy       No rain         17:16       22:43\n                                                          isoID\n1                                           DRYU202407230833EST\n2                                           DRYU202407231815EST\n3                                           DCKY202407241048EST\n4                                           DCKY202407241830EST\n5 AMTH202407250833EST, HARR202407250833EST, BUFF202407250833EST\n6 HARR202407251920EST, AMTH202407252037EST, BUFF202407251815EST\n                            streamNotes isoTime_EST\n1                                             08:33\n2 There were a ton of 999/ error codes.       18:15\n3                                             10:48\n4                                             18:30\n5                                             08:33\n6                                             18:15\n                         downstreamGPS downstreamGain\n1          42.6342708 N , 72.4923600 W             60\n2 Lat:42.6587346 N Long: 72.50041230 W             75\n3            42.4422556 N 72.3734784 W             75\n4 Lat: 42.4439420 N Long: 72.3734095 W             75\n5            42.3811548 N 72.4602750 W             80\n6 Lat: 42.3794408 N Long: 72.4629074 W             75\n                                                                                upstreamGPS\n1                                                                   42.6682103 N 72.5069701\n2                                                      Lat: 42.6688091 N Long: 72.5076269 W\n3                                                                42.4373149 N 72.3546576 W \n4                                                       Lat:42.4429939 N Long: 72.3700608 W\n5                                                                 42.3020057 N 72.4583703 W\n6 Buffim- Lat: 42.3820122 N Long: 72.4584062 W Harris- Lat: 42.3805896 N Long: 72.4587733 W\n  upstreamGain shift\n1           75   day\n2           80 night\n3           75   day\n4           75 night\n5           80   day\n6           75 night\n\nData for stream_survey_8.csv :\n      river airTemp                      cloud        precip startTime_EST\n1    DICKEY      67                     Cloudy       No rain         03:50\n2    DICKEY      78                     Cloudy       No rain         12:54\n3  AMETHYST      79                     Cloudy Moderate rain         03:50\n4  AMETHYST      82                     Cloudy       No rain         13:01\n5 UNDERHILL      72                      Clear       No rain         03:51\n6 UNDERHILL      87 Partly cloudy/partly sunny       No rain         13:04\n  endTime_EST                                                       isoID\n1       08:56                                         DCKY202407300503EST\n2       18:24                                         DCKY202407301355EST\n3       08:06 HARR202407310650EST AMTH202407310658EST BUFF202407310447EST\n4       16:10 AMTH202407311451EST BUFF202407311447EST HARR202407311447EST\n5       09:27                                         UNDH202408010442EST\n6       18:32                                         UNDH202408011308EST\n  streamNotes isoTime_EST                             downstreamGPS\n1          NA       05:03                 42.4421397 N 72.3133907 W\n2          NA       13:55      Lat: 42.4439938 N Long: 72.3734079 W\n3          NA       04:47                 42.3815085 N 72.4605129 W\n4          NA       14:47      Lat: 42.3802102 N Long: 72.4625902 W\n5          NA       04:42 42.4442400 degrees N 72.3233604 degrees W\n6          NA       13:08      Lat: 42.4444746 N Long: 72.3209563 W\n  downstreamGain\n1             70\n2             80\n3             70\n4             80\n5             70\n6             80\n                                                                                upstreamGPS\n1                                                                  42.4373330 N 72.3646411W\n2                                                                 42.4436114 N 72.3703450 W\n3                                                                 42.3807633 N 72.4584379 W\n4 Buffim- Lat: 42.3818780 N Long: 72.4583519 W Harris- Lat: 42.3805731 N Long: 72.4586648 W\n5                                                                 42.4456778 N 72.3323930 W\n6                                                                    42.4455316, 72.3324642\n  upstreamGain shift\n1           70   day\n2           80 night\n3           70   day\n4           80 night\n5           70   day\n6           80 night\n\nData for stream_survey_9.csv :\n      river airTemp                     cloud        precip startTime_EST\n1 UNDERHILL      72                    Cloudy     Weak rain         07:25\n2 UNDERHILL      73                    Cloudy     Weak rain         17:59\n3 DRY UPPER      60                    Cloudy     Weak rain         07:19\n4 DRY UPPER      75 Mostly sunny/mostly clear       No rain         17:14\n5  AMETHYST      63             Mostly cloudy       No rain         07:35\n6  AMETHYST      73                    Cloudy Moderate rain         17:00\n  endTime_EST                                                       isoID\n1       12:23                                         UNDH202408060810EST\n2       22:13                                         UNDH202408061801EST\n3       12:43                                          DRY202408071031EST\n4       22:12                                         DRYU202408072002EST\n5       13:34  BUFF20240801040EST HARR202408081041EST AMTH202408081045EST\n6       22:17 BUFF202408082007EST HARR202408082026EST AMTH202408082013EST\n                                                                                                            streamNotes\n1 Found a dead fish, cut it open to make sure it wasn’t a tagged fish and there wasn’t a dead tag inside (no tag found)\n2                                                                                                                      \n3                                                                                                                      \n4                                                                                                                    \\n\n5                                                                                                                      \n6                                                                                                                      \n  isoTime_EST                              downstreamGPS downstreamGain\n1       08:10 42.4442161 degrees N, 72.3234504 degrees W             70\n2       18:01        Lat:42.4442383 N Long: 72.3236331 W             80\n3       10:31 42.6586929 degrees N, 72.5041623 degrees W             70\n4       20:02           Lat 42.6619051.  Lon 72.50446738             80\n5       10:40                   42.3794084 N 72.4628350W             70\n6       20:07              Lat 42.3813265 Lon 72.4609471             80\n                                                                upstreamGPS\n1                                42.4459050 degrees N, 72.3317080 degrees W\n2                                           Lat 42.4436998. Long 72.3297100\n3                                42.6680512 degrees N, 72.5067974 degrees W\n4                                             Lat 42.6684551 Lon 72.5079943\n5                                                 42.3808097 N 72.4584604 W\n6 Buffum lat 42.3821350 Lon 72.4585148 harris lat 42.3813420 Lon 72.4589892\n  upstreamGain shift\n1           70   day\n2           45 night\n3           70   day\n4           80 night\n5           70   day\n6           80 night\n\nData for stream_survey_10.csv :\n      river airTemp                      cloud  precip startTime_EST\n1  AMETHYST      63                      Clear No rain         04:16\n2  AMETHYST      79 Partly cloudy/partly sunny No rain         13:07\n3 UNDERHILL      58                      Clear No rain         04:08\n4 UNDERHILL      79 Partly cloudy/partly sunny No rain         13:19\n5    DICKEY      60                      Clear No rain         04:17\n6    DICKEY      80              Mostly cloudy No rain         13:04\n  endTime_EST                                                         isoID\n1       09:26   BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n2       19:02 BUFF202408131516EST, AMTH202408131520EST, HARR202408131523EST\n3       09:23                                           UNDH202408140454EST\n4       18:42                                           UNDH202408141620EST\n5       09:27                                           DCKY202408150535EST\n6       16:14                                           DCKY202408151517EST\n  streamNotes isoTime_EST                        downstreamGPS downstreamGain\n1          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n2          NA       15:16               42.3802433, 72.4651203             75\n3          NA       04:54 Lat: 42.4368660 N Long: 72.3214536 W             75\n4          NA       16:20               42.4447508, 72.3208196             75\n5          NA       05:35  Lat:42.4444510 N Long: 72.3733538 W             80\n6          NA       15:17               42.4423240, 72.3733392             75\n                                                upstreamGPS upstreamGain shift\n1                      Lat: 42.3820586 N Long: 72.4585239 W           80   day\n2 HARR 42.3803763, 72.4535804;  BUFF 42.3836141, 72.4561609           75 night\n3                      Lat: 42.4438604 N Long: 72.3296500 W           75   day\n4                                    42.4435654, 72.3298756           75 night\n5                      Lat: 42.4435049 N Long: 72.3703123 W           80   day\n6                                    42.4375408, 72.3650235           75 night\n\nData for stream_survey_11.csv :\n      river airTemp  cloud  precip startTime_EST endTime_EST\n1  AMETHYST      68 Cloudy No rain         09:00       13:37\n2 UNDERHILL      63  Clear No rain         08:25       13:00\n3 DRY UPPER      60  Clear No rain         07:55       16:30\n4  AMETHYST      73  Clear No rain         09:00       13:57\n                                                          isoID\n1 BUFF202408201044EST, AMTH202408201047EST, HARR202408200947EST\n2                                           UNDH202408210929EST\n3                                           DRYU202408220918EST\n4 BUFF202408231125EST, HARR202408231130EST, AMTH202408231150EST\n              streamNotes isoTime_EST downstreamGPS downstreamGain upstreamGPS\n1                               09:47            NA             NA          NA\n2 Day of fish collection        09:29            NA             NA          NA\n3                               09:18            NA             NA          NA\n4                               11:25            NA             NA          NA\n  upstreamGain shift\n1           NA   day\n2           NA   day\n3           NA   day\n4           NA   day\n\nData for stream_survey_12.csv :\n      river airTemp         cloud  precip startTime_EST endTime_EST\n1 UNDERHILL      80         Clear No rain         09:04       12:48\n2    DICKEY      67 Mostly cloudy No rain         09:35       12:00\n                isoID streamNotes isoTime_EST downstreamGPS downstreamGain\n1 UNDH202408271016EST          NA       10:16            NA             NA\n2 DCKY202408291022EST          NA       10:22            NA             NA\n  upstreamGPS upstreamGain shift\n1          NA           NA   day\n2          NA           NA   day",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-fish_flow_receiver-and-stream-survey-data",
    "href": "creatingMyDatasheet.html#combine-fish_flow_receiver-and-stream-survey-data",
    "title": "2  Creating my Datasheet",
    "section": "2.9 Combine fish_flow_receiver and stream survey data",
    "text": "2.9 Combine fish_flow_receiver and stream survey data\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 1\nfish_flow_receiver_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_1.csv\")\nstream_survey_1 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_1.csv\")\n\n# Adjust 'river' in fish_flow_receiver survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_1 &lt;- fish_flow_receiver_1 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_1 &lt;- left_join(fish_flow_receiver_1, \n                           stream_survey_1, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_1 &lt;- fish_flow_receiver_stream_1 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_1)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-06-11 05:57:00 AMETHYST   day    59    NA  Riffle                Center\n2 2024-06-11 06:08:00 AMETHYST   day    60    NA  Riffle                Center\n3 2024-06-11 06:15:00   BUFFAM   day    19    NA  Riffle                Center\n4 2024-06-11 06:19:00   HARRIS   day    20    NA     Run                  Left\n5 2024-06-11 06:28:00   HARRIS   day    57    NA     Run                  Left\n6 2024-06-11 06:34:00   HARRIS   day    12    NA   Glide                Center\n  substrate substrateExtra         shade       lon      lat fishNotes source\n1      Rock             NA  Fully shaded -72.46038 42.38162             iPad\n2      Rock             NA  Fully shaded -72.46030 42.38136             iPad\n3      Rock             NA  Fully shaded -72.46023 42.38139             iPad\n4    Pebble             NA Mostly shaded -72.46015 42.38095             iPad\n5      Rock             NA Mostly shaded -72.46034 42.38105             iPad\n6      Rock             NA  Fully shaded -72.46009 42.38094             iPad\n  totalDischarge        flowTime_EST airTemp                      cloud  precip\n1           1.56                &lt;NA&gt;      71 Partly cloudy/partly sunny No rain\n2           1.56                &lt;NA&gt;      71 Partly cloudy/partly sunny No rain\n3           1.49 2024-06-11 08:32:26      71 Partly cloudy/partly sunny No rain\n4           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n5           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n6           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n  startTime_EST endTime_EST               isoID streamNotes isoTime_EST\n1         06:30       12:00 AMTH202406111000EST          NA       10:00\n2         06:30       12:00 AMTH202406111000EST          NA       10:00\n3         06:30       12:00 AMTH202406111000EST          NA       10:00\n4         06:30       12:00 AMTH202406111000EST          NA       10:00\n5         06:30       12:00 AMTH202406111000EST          NA       10:00\n6         06:30       12:00 AMTH202406111000EST          NA       10:00\n  downstreamGPS downstreamGain upstreamGPS upstreamGain\n1            NA             NA          NA           NA\n2            NA             NA          NA           NA\n3            NA             NA          NA           NA\n4            NA             NA          NA           NA\n5            NA             NA          NA           NA\n6            NA             NA          NA           NA\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_1, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_1.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 2\nfish_flow_receiver_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_2.csv\")\nstream_survey_2 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_2.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_2 &lt;- fish_flow_receiver_2 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_2 &lt;- left_join(fish_flow_receiver_2, \n                           stream_survey_2, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_2 &lt;- fish_flow_receiver_stream_2 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_2)\n\n\n      trackedTime_EST  river shift tagID power habitat  habitatExtra position\n1 2024-06-17 11:33:00 DICKEY   day    31    NA    Pool                 Center\n2 2024-06-17 11:57:00 DICKEY   day    46    NA     Run                  Right\n3 2024-06-17 11:59:00 DICKEY   day    29    NA  Riffle  Woody_debris     Left\n4 2024-06-17 12:10:00 DICKEY   day    26    NA     Run Undercut_bank    Right\n5 2024-06-17 12:47:00 DICKEY   day    28    NA    Pool                   Left\n6 2024-06-17 12:49:00 DICKEY   day    37    NA    Pool                  Right\n  substrate substrateExtra          shade       lon      lat fishNotes source\n1      Rock             NA  Mostly shaded -72.37084 42.44394             iPad\n2    Pebble             NA Lightly shaded -72.37173 42.44421             iPad\n3      Rock             NA   Fully shaded -72.37194 42.44430             iPad\n4      Rock             NA Lightly shaded -72.37344 42.44421             iPad\n5   Boulder             NA  Mostly shaded -72.37040 42.44369             iPad\n6      Rock             NA  Mostly shaded -72.37038 42.44377             iPad\n  totalDischarge        flowTime_EST airTemp                      cloud  precip\n1           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n2           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n3           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n4           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n5           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n6           0.03 2024-06-17 12:35:22      79 Partly cloudy/partly sunny No rain\n  startTime_EST endTime_EST               isoID streamNotes isoTime_EST\n1         11:26       17:00 DCKY202406171330EST          NA       13:30\n2         11:26       17:00 DCKY202406171330EST          NA       13:30\n3         11:26       17:00 DCKY202406171330EST          NA       13:30\n4         11:26       17:00 DCKY202406171330EST          NA       13:30\n5         11:26       17:00 DCKY202406171330EST          NA       13:30\n6         11:26       17:00 DCKY202406171330EST          NA       13:30\n  downstreamGPS downstreamGain upstreamGPS upstreamGain\n1            NA             NA          NA           NA\n2            NA             NA          NA           NA\n3            NA             NA          NA           NA\n4            NA             NA          NA           NA\n5            NA             NA          NA           NA\n6            NA             NA          NA           NA\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_2, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_2.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 3\nfish_flow_receiver_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_3.csv\")\nstream_survey_3 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_3.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_3 &lt;- fish_flow_receiver_3 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_3 &lt;- left_join(fish_flow_receiver_3, \n                           stream_survey_3, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_3 &lt;- fish_flow_receiver_stream_3 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_3)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-25 05:59:00 DRY UPPER   day    55    NA    Pool\n2 2024-06-25 06:02:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-25 06:07:00 DRY UPPER   day    53    NA    Pool\n4 2024-06-25 06:11:00 DRY UPPER   day    22    NA    Pool\n5 2024-06-25 06:20:00 DRY UPPER   day    21    NA    Pool\n6 2024-06-25 06:21:00 DRY UPPER   day    25    NA    Pool\n                habitatExtra position substrate substrateExtra          shade\n1               Woody_debris   Center      Rock             NA  Mostly shaded\n2               Woody_debris    Right       Mud             NA  Mostly shaded\n3               Woody_debris    Right       Mud             NA  Mostly shaded\n4   Root_bundle,Woody_debris     Left       Mud             NA Lightly shaded\n5 Woody_debris,Undercut_bank    Right      Rock             NA  Mostly shaded\n6 Undercut_bank,Woody_debris    Right      Rock             NA  Mostly shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50451 42.66767             iPad           0.03 2024-06-25 07:21:55\n2 -72.50455 42.66774             iPad           0.03 2024-06-25 07:21:55\n3 -72.50451 42.66761             iPad           0.03 2024-06-25 07:21:55\n4 -72.50445 42.66767             iPad           0.03 2024-06-25 07:21:55\n5 -72.50506 42.66704             iPad           0.03 2024-06-25 07:21:55\n6 -72.50507 42.66704             iPad           0.03 2024-06-25 07:21:55\n  airTemp cloud  precip startTime_EST endTime_EST               isoID\n1      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n2      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n3      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n4      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n5      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n6      57 Clear No rain         05:44       10:44 DRYU202406250610EST\n                                                                                                                              streamNotes\n1 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n2 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n3 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n4 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n5 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n6 Did not get to the stream on time because the batteries were corroded in the receiver so had to go back to lab and get other receiver. \n  isoTime_EST           downstreamGPS downstreamGain            upstreamGPS\n1       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n2       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n3       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n4       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n5       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n6       06:10 42.6353974. -72.4967190             65 42.6694251 -72.5074050\n  upstreamGain\n1           55\n2           55\n3           55\n4           55\n5           55\n6           55\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_3, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_3.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 4\nfish_flow_receiver_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_4.csv\")\nstream_survey_4 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_4.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_4 &lt;- fish_flow_receiver_4 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_4 &lt;- left_join(fish_flow_receiver_4, \n                           stream_survey_4, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_4 &lt;- fish_flow_receiver_stream_4 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_4)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-06-30 04:39:00 DRY UPPER   day    22    NA    Pool\n2 2024-06-30 04:42:00 DRY UPPER   day    16    NA    Pool\n3 2024-06-30 04:43:00 DRY UPPER   day    55    NA    Pool\n4 2024-06-30 04:50:00 DRY UPPER   day    21    NA    Pool\n5 2024-06-30 04:51:00 DRY UPPER   day    25    NA    Pool\n6 2024-06-30 04:51:00 DRY UPPER   day    24    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1                Root_bundle     Left        NA       Rock,Mud         Night\n2               Woody_debris    Right        NA            Mud  Fully shaded\n3               Woody_debris    Right        NA            Mud  Fully shaded\n4 Woody_debris,Undercut_bank    Right        NA            Mud Mostly shaded\n5 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n6 Undercut_bank,Woody_debris    Right        NA            Mud  Fully shaded\n        lon      lat fishNotes source totalDischarge        flowTime_EST\n1 -72.50457 42.66769             iPad           0.33 2024-06-30 05:23:29\n2 -72.50448 42.66760             iPad           0.33 2024-06-30 05:23:29\n3 -72.50453 42.66762             iPad           0.33 2024-06-30 05:23:29\n4 -72.50514 42.66698             iPad           0.33 2024-06-30 05:23:29\n5 -72.50509 42.66699             iPad           0.33 2024-06-30 05:23:29\n6 -72.50508 42.66702             iPad           0.33 2024-06-30 05:23:29\n  airTemp  cloud  precip startTime_EST endTime_EST               isoID\n1      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n2      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n3      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n4      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n5      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n6      71 Cloudy No rain         03:57       08:55 DRYU202406300528EST\n  streamNotes isoTime_EST                        downstreamGPS downstreamGain\n1                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n2                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n3                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n4                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n5                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n6                   05:28 Lat: 42.6626558 N Long: 72.5044938 W             85\n                           upstreamGPS upstreamGain\n1 Lat: 42.6688089 N Long: 72.5073252 W           90\n2 Lat: 42.6688089 N Long: 72.5073252 W           90\n3 Lat: 42.6688089 N Long: 72.5073252 W           90\n4 Lat: 42.6688089 N Long: 72.5073252 W           90\n5 Lat: 42.6688089 N Long: 72.5073252 W           90\n6 Lat: 42.6688089 N Long: 72.5073252 W           90\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_4, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_4.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 5\nfish_flow_receiver_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_5.csv\")\nstream_survey_5 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_5.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_5 &lt;- fish_flow_receiver_5 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_5 &lt;- left_join(fish_flow_receiver_5, \n                           stream_survey_5, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_5 &lt;- fish_flow_receiver_stream_5 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_5)\n\n\n      trackedTime_EST     river shift tagID power habitat  habitatExtra\n1 2024-07-09 07:30:00 UNDERHILL   day    41    NA  Riffle              \n2 2024-07-09 07:49:00 UNDERHILL   day    40    NA  Riffle  Woody_debris\n3 2024-07-09 07:57:00 UNDERHILL   day    34    NA  Riffle              \n4 2024-07-09 08:08:00 UNDERHILL   day    33    NA  Riffle Undercut_bank\n5 2024-07-09 08:18:00 UNDERHILL   day    36    NA    Pool              \n6 2024-07-09 08:25:00 UNDERHILL   day    27    NA  Riffle              \n  position substrate   substrateExtra         shade       lon      lat\n1   Center        NA             Rock  Fully shaded -72.32447 42.44488\n2                 NA      Rock,Pebble Mostly shaded -72.32513 42.44510\n3   Center        NA             Rock               -72.32645 42.44537\n4    Right        NA             Rock Mostly shaded -72.32624 42.44533\n5   Center        NA Rock,Pebble,Sand Mostly shaded -72.32752 42.44626\n6   Center        NA             Rock Mostly shaded -72.32780 42.44521\n                                           fishNotes source totalDischarge\n1                                                      iPad           2.78\n2                                                      iPad           2.78\n3                                                      iPad           2.78\n4                                                      iPad           2.78\n5 Moved up from where we thought it might have died.   iPad           2.78\n6                                                      iPad           2.78\n         flowTime_EST airTemp  cloud        precip startTime_EST endTime_EST\n1 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n2 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n3 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n4 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n5 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n6 2024-07-09 09:13:28      71 Cloudy Moderate rain         07:28       12:39\n                isoID streamNotes isoTime_EST             downstreamGPS\n1 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n2 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n3 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n4 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n5 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n6 UNDH202407090734EST                   07:27 42.4445523 N 72.3210041 W\n  downstreamGain               upstreamGPS upstreamGain\n1             75 42.4436600 W 72.3295537 N           75\n2             75 42.4436600 W 72.3295537 N           75\n3             75 42.4436600 W 72.3295537 N           75\n4             75 42.4436600 W 72.3295537 N           75\n5             75 42.4436600 W 72.3295537 N           75\n6             75 42.4436600 W 72.3295537 N           75\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_5, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_5.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 6\nfish_flow_receiver_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_6.csv\")\nstream_survey_6 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_6.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_6 &lt;- fish_flow_receiver_6 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_6 &lt;- left_join(fish_flow_receiver_6, \n                           stream_survey_6, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_6 &lt;- fish_flow_receiver_stream_6 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_6)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-16 03:49:00 DICKEY   day    31    NA  Riffle                Center\n2 2024-07-16 03:58:00 DICKEY   day    28    NA    Pool                Center\n3 2024-07-16 04:04:00 DICKEY   day    26    NA  Riffle                Center\n4 2024-07-16 04:05:00 DICKEY   day    37    NA  Riffle                Center\n5 2024-07-16 05:17:00 DICKEY   day    31    NA  Riffle                Center\n6 2024-07-16 05:21:00 DICKEY   day    28    NA    Pool                Center\n  substrate   substrateExtra        shade       lon      lat fishNotes source\n1        NA             Rock        Night -72.37121 42.44408             iPad\n2        NA         Sand,Mud        Night -72.37056 42.44364             iPad\n3        NA             Rock        Night -72.37030 42.44345             iPad\n4        NA             Rock Fully shaded -72.37018 42.44342             iPad\n5        NA        Rock,Sand Fully shaded -72.37132 42.44393             iPad\n6        NA Rock,Pebble,Sand Fully shaded -72.37059 42.44357             iPad\n  totalDischarge        flowTime_EST airTemp  cloud  precip startTime_EST\n1           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n2           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n3           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n4           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n5           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n6           1.17 2024-07-16 05:02:37      70 Cloudy No rain         03:35\n  endTime_EST               isoID streamNotes isoTime_EST\n1       08:55 DCKY202407160347EST                   03:47\n2       08:55 DCKY202407160347EST                   03:47\n3       08:55 DCKY202407160347EST                   03:47\n4       08:55 DCKY202407160347EST                   03:47\n5       08:55 DCKY202407160347EST                   03:47\n6       08:55 DCKY202407160347EST                   03:47\n              downstreamGPS downstreamGain              upstreamGPS\n1 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n2 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n3 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n4 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n5 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n6 42.4422631.N 72.3733436 W             70 42.4374180 N 72.346902 W\n  upstreamGain\n1           75\n2           75\n3           75\n4           75\n5           75\n6           75\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_6, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_6.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 7\nfish_flow_receiver_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_7.csv\")\nstream_survey_7 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_7.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_7 &lt;- fish_flow_receiver_7 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_7 &lt;- left_join(fish_flow_receiver_7, \n                           stream_survey_7, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_7 &lt;- fish_flow_receiver_stream_7 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_7)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-07-23 07:28:00 DRY UPPER   day  39.1    NA    Pool\n2 2024-07-23 07:56:00 DRY UPPER   day  46.1    NA        \n3 2024-07-23 08:07:00 DRY UPPER   day  29.1    NA  Riffle\n4 2024-07-23 08:44:00 DRY UPPER   day  30.1    NA    Pool\n5 2024-07-23 08:52:00 DRY UPPER   day  16.0    NA    Pool\n6 2024-07-23 09:06:00 DRY UPPER   day  55.0    NA    Pool\n                habitatExtra position substrate substrateExtra         shade\n1               Woody_debris    Right        NA      Rock,Sand Mostly shaded\n2                                            NA                             \n3                                Left        NA                Mostly shaded\n4               Woody_debris     Left        NA            Mud Mostly shaded\n5 Woody_debris,Undercut_bank    Right        NA       Mud,Sand  Fully shaded\n6               Woody_debris                 NA      Rock,Sand Mostly shaded\n        lon      lat                                  fishNotes source\n1 -72.50687 42.66812                                              iPad\n2 -72.50700 42.66827                                       Dead   iPad\n3 -72.50598 42.66837 Very shallow water. Can’t see fish or tag.   iPad\n4 -72.50495 42.66817                                              iPad\n5 -72.50460 42.66775                          Up under cutback.   iPad\n6 -72.50408 42.66603                              Dead have tag   iPad\n  totalDischarge        flowTime_EST airTemp         cloud        precip\n1           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n2           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n3           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n4           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n5           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n6           0.13 2024-07-23 08:27:20      83 Mostly cloudy Moderate rain\n  startTime_EST endTime_EST               isoID streamNotes isoTime_EST\n1         07:27       13:24 DRYU202407230833EST                   08:33\n2         07:27       13:24 DRYU202407230833EST                   08:33\n3         07:27       13:24 DRYU202407230833EST                   08:33\n4         07:27       13:24 DRYU202407230833EST                   08:33\n5         07:27       13:24 DRYU202407230833EST                   08:33\n6         07:27       13:24 DRYU202407230833EST                   08:33\n                downstreamGPS downstreamGain             upstreamGPS\n1 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n2 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n3 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n4 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n5 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n6 42.6342708 N , 72.4923600 W             60 42.6682103 N 72.5069701\n  upstreamGain\n1           75\n2           75\n3           75\n4           75\n5           75\n6           75\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_7, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_7.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 8\nfish_flow_receiver_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_8.csv\")\nstream_survey_8 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_8.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_8 &lt;- fish_flow_receiver_8 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_8 &lt;- left_join(fish_flow_receiver_8, \n                           stream_survey_8, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_8 &lt;- fish_flow_receiver_stream_8 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_8)\n\n\n      trackedTime_EST  river shift tagID power habitat habitatExtra position\n1 2024-07-30 04:07:00 DICKEY   day    31    NA  Riffle                 Right\n2 2024-07-30 04:15:00 DICKEY   day    26    NA  Riffle                Center\n3 2024-07-30 04:16:00 DICKEY   day    37    NA  Riffle                Center\n4 2024-07-30 04:38:00 DICKEY   day    38    NA     Run                 Right\n5 2024-07-30 04:42:00 DICKEY   day    32    NA    Pool                  Left\n6 2024-07-30 05:25:00 DICKEY   day    38    NA  Riffle                  Left\n  substrate substrateExtra          shade       lon      lat\n1        NA    Pebble,Rock          Night -72.37116 42.44418\n2        NA    Rock,Pebble          Night -72.37034 42.44352\n3        NA    Rock,Pebble          Night -72.37032 42.44350\n4        NA    Rock,Pebble          Night -72.37335 42.44441\n5        NA         Pebble          Night -72.37354 42.44406\n6        NA    Rock,Pebble Lightly shaded -72.37340 42.44449\n                                               fishNotes source totalDischarge\n1                                                          iPad           1.13\n2                                                          iPad           1.13\n3                                                          iPad           1.13\n4                                                          iPad           1.13\n5 Dead.found on river left side of pool buried n gravel.   iPad           1.13\n6                                           May be dead    iPad           1.13\n         flowTime_EST airTemp  cloud  precip startTime_EST endTime_EST\n1 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n2 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n3 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n4 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n5 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n6 2024-07-30 04:50:14      67 Cloudy No rain         03:50       08:56\n                isoID streamNotes isoTime_EST             downstreamGPS\n1 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n2 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n3 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n4 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n5 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n6 DCKY202407300503EST          NA       05:03 42.4421397 N 72.3133907 W\n  downstreamGain              upstreamGPS upstreamGain\n1             70 42.4373330 N 72.3646411W           70\n2             70 42.4373330 N 72.3646411W           70\n3             70 42.4373330 N 72.3646411W           70\n4             70 42.4373330 N 72.3646411W           70\n5             70 42.4373330 N 72.3646411W           70\n6             70 42.4373330 N 72.3646411W           70\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_8, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_8.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 9\nfish_flow_receiver_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_9.csv\")\nstream_survey_9 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_9.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_9 &lt;- fish_flow_receiver_9 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_9 &lt;- left_join(fish_flow_receiver_9, \n                           stream_survey_9, \n                           by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_9 &lt;- fish_flow_receiver_stream_9 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_9)\n\n\n      trackedTime_EST     river shift tagID power habitat\n1 2024-08-05 11:06:00 DRY UPPER   day    49   174    Pool\n2 2024-08-05 11:35:00 DRY UPPER   day    47    NA        \n3 2024-08-05 11:37:00 DRY UPPER   day    47    54        \n4 2024-08-06 07:41:00 UNDERHILL   day    33    NA  Riffle\n5 2024-08-06 07:47:00 UNDERHILL   day    45    NA    Pool\n6 2024-08-06 07:53:00 UNDERHILL   day    44    NA    Pool\n                habitatExtra position substrate      substrateExtra\n1 Woody_debris,Undercut_bank                 NA Granule,Pebble,Sand\n2                                            NA                    \n3                                            NA                    \n4               Woody_debris   Center        NA         Pebble,Rock\n5                              Center        NA      Pebble,Granule\n6               Woody_debris   Center        NA           Rock,Sand\n           shade       lon      lat\n1 Lightly shaded -72.50352 42.65114\n2                -72.50353 42.65375\n3                -72.50367 42.65407\n4  Mostly shaded -72.32640 42.44531\n5  Mostly shaded -72.32773 42.44515\n6  Mostly shaded -72.32803 42.44488\n                                                                         fishNotes\n1              Bunch of fish swimming around, moving too much to get a good signal\n2 Lost signal, signal was strongest (74) back at the clearing with the pine trees \n3                                                                                 \n4                                                            Same so as last week.\n5                                                                                 \n6                                                                                 \n  source totalDischarge        flowTime_EST airTemp  cloud    precip\n1   iPad           0.25 2024-08-07 08:20:43      60 Cloudy Weak rain\n2   iPad           0.25 2024-08-07 08:20:43      60 Cloudy Weak rain\n3   iPad           0.25 2024-08-07 08:20:43      60 Cloudy Weak rain\n4   iPad           0.04 2024-08-06 08:06:36      72 Cloudy Weak rain\n5   iPad           0.04 2024-08-06 08:06:36      72 Cloudy Weak rain\n6   iPad           0.04 2024-08-06 08:06:36      72 Cloudy Weak rain\n  startTime_EST endTime_EST               isoID\n1         07:19       12:43  DRY202408071031EST\n2         07:19       12:43  DRY202408071031EST\n3         07:19       12:43  DRY202408071031EST\n4         07:25       12:23 UNDH202408060810EST\n5         07:25       12:23 UNDH202408060810EST\n6         07:25       12:23 UNDH202408060810EST\n                                                                                                            streamNotes\n1                                                                                                                      \n2                                                                                                                      \n3                                                                                                                      \n4 Found a dead fish, cut it open to make sure it wasn’t a tagged fish and there wasn’t a dead tag inside (no tag found)\n5 Found a dead fish, cut it open to make sure it wasn’t a tagged fish and there wasn’t a dead tag inside (no tag found)\n6 Found a dead fish, cut it open to make sure it wasn’t a tagged fish and there wasn’t a dead tag inside (no tag found)\n  isoTime_EST                              downstreamGPS downstreamGain\n1       10:31 42.6586929 degrees N, 72.5041623 degrees W             70\n2       10:31 42.6586929 degrees N, 72.5041623 degrees W             70\n3       10:31 42.6586929 degrees N, 72.5041623 degrees W             70\n4       08:10 42.4442161 degrees N, 72.3234504 degrees W             70\n5       08:10 42.4442161 degrees N, 72.3234504 degrees W             70\n6       08:10 42.4442161 degrees N, 72.3234504 degrees W             70\n                                 upstreamGPS upstreamGain\n1 42.6680512 degrees N, 72.5067974 degrees W           70\n2 42.6680512 degrees N, 72.5067974 degrees W           70\n3 42.6680512 degrees N, 72.5067974 degrees W           70\n4 42.4459050 degrees N, 72.3317080 degrees W           70\n5 42.4459050 degrees N, 72.3317080 degrees W           70\n6 42.4459050 degrees N, 72.3317080 degrees W           70\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_9, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_9.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 10\nfish_flow_receiver_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_10.csv\")\nstream_survey_10 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_10.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_10 &lt;- fish_flow_receiver_10 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_10 &lt;- left_join(fish_flow_receiver_10, \n                            stream_survey_10, \n                            by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_10 &lt;- fish_flow_receiver_stream_10 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_10)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-13 04:25:00   BUFFAM   day    60    NA     Run                Center\n2 2024-08-13 04:31:00   BUFFAM   day    18    NA     Run                Center\n3 2024-08-13 04:32:00   BUFFAM   day    14    NA  Riffle                Center\n4 2024-08-13 04:34:00   HARRIS   day    20    NA     Run Woody_debris   Center\n5 2024-08-13 04:41:00 AMETHYST   day    19    NA  Riffle                Center\n6 2024-08-13 05:15:00   BUFFAM   day    60    NA     Run                Center\n  substrate    substrateExtra        shade       lon      lat fishNotes source\n1        NA         Sand,Rock        Night -72.45838 42.38205             iPad\n2        NA Sand,Boulder,Rock        Night -72.45979 42.38119             iPad\n3        NA      Rock,Boulder        Night -72.46000 42.38136             iPad\n4        NA           Boulder        Night -72.46033 42.38118             iPad\n5        NA              Rock        Night -72.46088 42.38150             iPad\n6        NA         Sand,Rock Fully shaded -72.45866 42.38218             iPad\n  totalDischarge        flowTime_EST airTemp cloud  precip startTime_EST\n1           1.22 2024-08-13 04:57:46      63 Clear No rain         04:16\n2           1.22 2024-08-13 04:57:46      63 Clear No rain         04:16\n3           1.22 2024-08-13 04:57:46      63 Clear No rain         04:16\n4           3.16 2024-08-13 06:51:21      63 Clear No rain         04:16\n5           4.38                &lt;NA&gt;      63 Clear No rain         04:16\n6           1.22 2024-08-13 04:57:46      63 Clear No rain         04:16\n  endTime_EST                                                       isoID\n1       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n2       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n3       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n4       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n5       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n6       09:26 BUFF202408130524EST HARR202408130510EST AMTH202408130516EST\n  streamNotes isoTime_EST                        downstreamGPS downstreamGain\n1          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n2          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n3          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n4          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n5          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n6          NA       05:10 Lat: 42.3808032 N Long: 72.4615415 W             80\n                           upstreamGPS upstreamGain\n1 Lat: 42.3820586 N Long: 72.4585239 W           80\n2 Lat: 42.3820586 N Long: 72.4585239 W           80\n3 Lat: 42.3820586 N Long: 72.4585239 W           80\n4 Lat: 42.3820586 N Long: 72.4585239 W           80\n5 Lat: 42.3820586 N Long: 72.4585239 W           80\n6 Lat: 42.3820586 N Long: 72.4585239 W           80\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_10, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_10.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 11\nfish_flow_receiver_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_11.csv\")\nstream_survey_11 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_11.csv\")\n\n# Adjust 'river' in fish survey to handle Buffam and Harris as part of Amethyst\nfish_flow_receiver_11 &lt;- fish_flow_receiver_11 %&gt;%\n  mutate(\n    # Create a new 'riverMatch' column for the join\n    riverMatch = ifelse(river %in% c(\"BUFFAM\", \"HARRIS\"), \"AMETHYST\", river)\n  )\n\n# Perform the join on the 'shift' and the modified 'riverMatch' column in the fish survey\nfish_flow_receiver_stream_11 &lt;- left_join(fish_flow_receiver_11, \n                            stream_survey_11, \n                            by = c(\"shift\", \"riverMatch\" = \"river\"))\n\n# Remove the 'riverMatch' column from the result\nfish_flow_receiver_stream_11 &lt;- fish_flow_receiver_stream_11 %&gt;% \n  select(-riverMatch)\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_11)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-08-20 09:10:00 AMETHYST   day    19    NA  Riffle                Center\n2 2024-08-20 09:10:00 AMETHYST   day    19    NA  Riffle                Center\n3 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n4 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n5 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n6 2024-08-20 09:39:00   HARRIS   day    20    NA  Riffle                  Left\n  substrate substrateExtra        shade       lon      lat fishNotes source\n1        NA           Rock Fully shaded -72.46090 42.38157             iPad\n2        NA           Rock Fully shaded -72.46090 42.38157             iPad\n3        NA        Boulder Fully shaded -72.46016 42.38116             iPad\n4        NA        Boulder Fully shaded -72.46016 42.38116             iPad\n5        NA        Boulder Fully shaded -72.46016 42.38116             iPad\n6        NA        Boulder Fully shaded -72.46016 42.38116             iPad\n  totalDischarge        flowTime_EST airTemp  cloud  precip startTime_EST\n1          21.70                &lt;NA&gt;      68 Cloudy No rain         09:00\n2          21.70                &lt;NA&gt;      73  Clear No rain         09:00\n3          13.48 2024-08-20 09:56:27      68 Cloudy No rain         09:00\n4          13.48 2024-08-20 09:56:27      73  Clear No rain         09:00\n5           3.87 2024-08-23 13:17:11      68 Cloudy No rain         09:00\n6           3.87 2024-08-23 13:17:11      73  Clear No rain         09:00\n  endTime_EST                                                         isoID\n1       13:37 BUFF202408201044EST, AMTH202408201047EST, HARR202408200947EST\n2       13:57 BUFF202408231125EST, HARR202408231130EST, AMTH202408231150EST\n3       13:37 BUFF202408201044EST, AMTH202408201047EST, HARR202408200947EST\n4       13:57 BUFF202408231125EST, HARR202408231130EST, AMTH202408231150EST\n5       13:37 BUFF202408201044EST, AMTH202408201047EST, HARR202408200947EST\n6       13:57 BUFF202408231125EST, HARR202408231130EST, AMTH202408231150EST\n  streamNotes isoTime_EST downstreamGPS downstreamGain upstreamGPS upstreamGain\n1                   09:47            NA             NA          NA           NA\n2                   11:25            NA             NA          NA           NA\n3                   09:47            NA             NA          NA           NA\n4                   11:25            NA             NA          NA           NA\n5                   09:47            NA             NA          NA           NA\n6                   11:25            NA             NA          NA           NA\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_11, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_11.csv\", \n          row.names = FALSE)\n\n\n\n\nCode\n# Read in the fish_flow_receiver and stream survey data for week 12\nfish_flow_receiver_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_12.csv\")\nstream_survey_12 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/stream_survey_12.csv\")\n\n# Combine the datasets by shift and river columns\nfish_flow_receiver_stream_12 &lt;- left_join(fish_flow_receiver_12, \n                            stream_survey_12, \n                            by = c(\"shift\", \"river\"))\n\n# Display the first few rows of the combined data\nhead(fish_flow_receiver_stream_12)\n\n\n      trackedTime_EST     river shift tagID power habitat habitatExtra position\n1 2024-08-27 09:41:00 UNDERHILL   day    45    NA    Pool           NA    Right\n2 2024-08-27 10:32:00 UNDERHILL   day    44    NA    Pool           NA   Center\n3 2024-08-27 12:19:00 UNDERHILL   day    35    NA    Pool           NA   Center\n4 2024-08-27 09:16:33 DRY UPPER   day    16    39    &lt;NA&gt;           NA     &lt;NA&gt;\n5 2024-08-27 09:21:27 UNDERHILL   day    45   120    &lt;NA&gt;           NA     &lt;NA&gt;\n6 2024-08-27 09:22:07 UNDERHILL   day    45   139    &lt;NA&gt;           NA     &lt;NA&gt;\n  substrate              substrateExtra         shade       lon      lat\n1        NA                   Sand,Rock  Fully shaded -72.32730 42.44535\n2        NA                   Sand,Rock Mostly shaded -72.32805 42.44492\n3        NA Boulder,Rock,Granule,Pebble Mostly shaded -72.32929 42.44359\n4        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n5        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n6        NA                        &lt;NA&gt;          &lt;NA&gt;        NA       NA\n                                                                              fishNotes\n1                                                      Unsuccessful at finding shed tag\n2                                                      Unsuccessful at finding shed tag\n3 Unsuccessful at finding shed tag. It is most likely located in a hole under this rock\n4                                                                                  &lt;NA&gt;\n5                                                                                  &lt;NA&gt;\n6                                                                                  &lt;NA&gt;\n    source totalDischarge        flowTime_EST airTemp cloud  precip\n1     iPad           0.03 2024-08-27 10:16:23      80 Clear No rain\n2     iPad           0.03 2024-08-27 10:16:23      80 Clear No rain\n3     iPad           0.03 2024-08-27 10:16:23      80 Clear No rain\n4 receiver             NA                &lt;NA&gt;      NA  &lt;NA&gt;    &lt;NA&gt;\n5 receiver             NA                &lt;NA&gt;      80 Clear No rain\n6 receiver             NA                &lt;NA&gt;      80 Clear No rain\n  startTime_EST endTime_EST               isoID streamNotes isoTime_EST\n1         09:04       12:48 UNDH202408271016EST          NA       10:16\n2         09:04       12:48 UNDH202408271016EST          NA       10:16\n3         09:04       12:48 UNDH202408271016EST          NA       10:16\n4          &lt;NA&gt;        &lt;NA&gt;                &lt;NA&gt;          NA        &lt;NA&gt;\n5         09:04       12:48 UNDH202408271016EST          NA       10:16\n6         09:04       12:48 UNDH202408271016EST          NA       10:16\n  downstreamGPS downstreamGain upstreamGPS upstreamGain\n1            NA             NA          NA           NA\n2            NA             NA          NA           NA\n3            NA             NA          NA           NA\n4            NA             NA          NA           NA\n5            NA             NA          NA           NA\n6            NA             NA          NA           NA\n\n\nCode\n# Save the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_12, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_12.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-all-weekly-datasets",
    "href": "creatingMyDatasheet.html#combine-all-weekly-datasets",
    "title": "2  Creating my Datasheet",
    "section": "2.10 Combine all weekly datasets",
    "text": "2.10 Combine all weekly datasets\n\n\nCode\n# Define file names\nfile_names &lt;- c(\"fish_flow_receiver_stream_1.csv\", \"fish_flow_receiver_stream_2.csv\", \"fish_flow_receiver_stream_3.csv\", \"fish_flow_receiver_stream_4.csv\", \n                \"fish_flow_receiver_stream_5.csv\", \"fish_flow_receiver_stream_6.csv\", \"fish_flow_receiver_stream_7.csv\", \"fish_flow_receiver_stream_8.csv\", \n                \"fish_flow_receiver_stream_9.csv\", \"fish_flow_receiver_stream_10.csv\", \"fish_flow_receiver_stream_11.csv\", \"fish_flow_receiver_stream_12.csv\") \n\n# Create an empty list to store the data from each file\nfull_data_list &lt;- list()\n\n# Loop through each file and read the data into the list\nfor (file_name in file_names) {\n  all_data &lt;- read.csv(file_name, stringsAsFactors = FALSE)\n  full_data_list[[file_name]] &lt;- all_data\n}\n\n# Combine all datasets into a single data frame by stacking rows\nfish_flow_receiver_stream_all &lt;- bind_rows(full_data_list)\n\n# Display the first few rows of the combined dataset\nhead(fish_flow_receiver_stream_all)\n\n\n      trackedTime_EST    river shift tagID power habitat habitatExtra position\n1 2024-06-11 05:57:00 AMETHYST   day    59    NA  Riffle                Center\n2 2024-06-11 06:08:00 AMETHYST   day    60    NA  Riffle                Center\n3 2024-06-11 06:15:00   BUFFAM   day    19    NA  Riffle                Center\n4 2024-06-11 06:19:00   HARRIS   day    20    NA     Run                  Left\n5 2024-06-11 06:28:00   HARRIS   day    57    NA     Run                  Left\n6 2024-06-11 06:34:00   HARRIS   day    12    NA   Glide                Center\n  substrate substrateExtra         shade       lon      lat fishNotes source\n1      Rock           &lt;NA&gt;  Fully shaded -72.46038 42.38162             iPad\n2      Rock           &lt;NA&gt;  Fully shaded -72.46030 42.38136             iPad\n3      Rock           &lt;NA&gt;  Fully shaded -72.46023 42.38139             iPad\n4    Pebble           &lt;NA&gt; Mostly shaded -72.46015 42.38095             iPad\n5      Rock           &lt;NA&gt; Mostly shaded -72.46034 42.38105             iPad\n6      Rock           &lt;NA&gt;  Fully shaded -72.46009 42.38094             iPad\n  totalDischarge        flowTime_EST airTemp                      cloud  precip\n1           1.56                &lt;NA&gt;      71 Partly cloudy/partly sunny No rain\n2           1.56                &lt;NA&gt;      71 Partly cloudy/partly sunny No rain\n3           1.49 2024-06-11 08:32:26      71 Partly cloudy/partly sunny No rain\n4           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n5           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n6           0.07 2024-06-11 09:42:47      71 Partly cloudy/partly sunny No rain\n  startTime_EST endTime_EST               isoID streamNotes isoTime_EST\n1         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n2         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n3         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n4         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n5         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n6         06:30       12:00 AMTH202406111000EST        &lt;NA&gt;       10:00\n  downstreamGPS downstreamGain upstreamGPS upstreamGain\n1          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n2          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n3          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n4          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n5          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n6          &lt;NA&gt;             NA        &lt;NA&gt;           NA\n\n\nCode\n# Write the combined data to a new CSV file\nwrite.csv(fish_flow_receiver_stream_all, \n          \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_all.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-tagging-data",
    "href": "creatingMyDatasheet.html#preparing-tagging-data",
    "title": "2  Creating my Datasheet",
    "section": "2.11 Preparing tagging data",
    "text": "2.11 Preparing tagging data\n\n\nCode\n# Read in the tagging data\ntagging_data &lt;- read_excel(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/taggingData.xlsx\")\n\n# Select specific columns\ntagging_data &lt;- tagging_data %&gt;%\n  select(RIVER, DATE, SECTION, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, GENETICSAM, SEX)\n\n# Rename columns\ntagging_data &lt;- tagging_data %&gt;%\n  rename(\n    river = RIVER,\n    date = DATE,\n    section = SECTION,\n    tagID = RADIOTAG,\n    tempID = TEMPTAG,\n    length = LENGTH,\n    weight = WEIGHT,\n    geneticSam = GENETICSAM,\n    sex = SEX\n    )\n\n# Fix column labels and remove first tag 44 since the fish died and was retagged before the study began\ntagging_data &lt;- tagging_data %&gt;%\n  mutate(river = str_trim(river),\n         date = str_trim(date),\n         section = str_trim(section),\n         tagID = str_trim(tagID),\n         tempID = str_trim(tempID),\n         length = str_trim(length),\n         weight = str_trim(weight),\n         geneticSam = str_trim(geneticSam),\n         sex = str_trim(sex)) %&gt;%\n  filter(!(tagID == \"44\" & date == as.POSIXct(\"2024-06-04\", format=\"%Y-%m-%d\")))\n\n# Write new tagging data csv\nwrite.csv(tagging_data, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-tagging-data-with-fishstreamflowreceiver-data",
    "href": "creatingMyDatasheet.html#combine-tagging-data-with-fishstreamflowreceiver-data",
    "title": "2  Creating my Datasheet",
    "section": "2.12 Combine tagging data with fish/stream/flow/receiver data",
    "text": "2.12 Combine tagging data with fish/stream/flow/receiver data\n\n\nCode\n# Read in the data\ntagging_data = read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tagging_data.csv\")\nfish_flow_receiver_stream_all = read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_all.csv\")\n\n# Create a mapping of radio tag ID to temp tag ID from tagging data\nradio_temp_mapping &lt;- tagging_data %&gt;%\n  select(tagID, tempID) %&gt;%\n  distinct()  # Ensures unique pairings\n\n# Merge this mapping into fish/stream/flow/receiver data\nfish_flow_receiver_stream_all &lt;- fish_flow_receiver_stream_all %&gt;%\n  left_join(radio_temp_mapping, by = \"tagID\")\n\n# Create a new column 'date' with just the date part of 'dateTime'\nfish_flow_receiver_stream_all &lt;- fish_flow_receiver_stream_all %&gt;%\n  mutate(date = as.Date(trackedTime_EST))\n\n# Convert the date column into a matching format as the other dataset\ntagging_data &lt;- tagging_data %&gt;%\n  mutate(date = as.Date(date))\n\n# Combine the datasets by binding rows horizontally\nfish_flow_receiver_stream_tagging_all &lt;- bind_rows(fish_flow_receiver_stream_all, tagging_data)\n\n# Now the combined dataframe should have all tempTagIDs added where appropriate\n\n# Write new tagging data csv\nwrite.csv(fish_flow_receiver_stream_tagging_all, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_tagging_all.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#preparing-collection-data",
    "href": "creatingMyDatasheet.html#preparing-collection-data",
    "title": "2  Creating my Datasheet",
    "section": "2.13 Preparing collection data",
    "text": "2.13 Preparing collection data\n\n\nCode\n# Read in the collection data\ncollection_data &lt;- read_excel(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/collectionData.xlsx\", \n                              range = cell_rows(1:34))\n\n# Select specific columns\ncollection_data &lt;- collection_data %&gt;%\n  select(RIVER, recoveryDate, RADIOTAG, TEMPTAG, LENGTH, WEIGHT, BLOOD, TYPE, COMMENTS)\n\n# Rename columns\ncollection_data &lt;- collection_data %&gt;%\n  rename(\n    river = RIVER,\n    date = recoveryDate,\n    tagID = RADIOTAG,\n    tempID = TEMPTAG,\n    length = LENGTH,\n    weight = WEIGHT,\n    blood = BLOOD,\n    type = TYPE,\n    collectionNotes = COMMENTS\n    )\n\n# Fix column labels\ncollection_data &lt;- collection_data %&gt;%\n  mutate(river = str_trim(river),\n         date = str_trim(date),\n         tagID = str_trim(tagID),\n         tempID = str_trim(tempID),\n         length = str_trim(length),\n         weight = str_trim(weight),\n         blood = str_trim(blood),\n         type = str_trim(type),\n         collectionNotes = str_trim(collectionNotes))\n\n# Write new tagging data csv\nwrite.csv(collection_data, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/collection_data.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "creatingMyDatasheet.html#combine-collection-data-with-fishstreamflowreceivertagging-data",
    "href": "creatingMyDatasheet.html#combine-collection-data-with-fishstreamflowreceivertagging-data",
    "title": "2  Creating my Datasheet",
    "section": "2.14 Combine collection data with fish/stream/flow/receiver/tagging data",
    "text": "2.14 Combine collection data with fish/stream/flow/receiver/tagging data\n\n\nCode\n# Read in the data\ncollection_data = read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/collection_data.csv\")\nfish_flow_receiver_stream_tagging_all = read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/fish_flow_receiver_stream_tagging_all.csv\")\n\n# Convert the date column into a matching format as the other dataset\ncollection_data &lt;- collection_data %&gt;%\n  mutate(date = as.Date(date))\n\n# Convert the date column into a matching format as the other dataset\nfish_flow_receiver_stream_tagging_all &lt;- fish_flow_receiver_stream_tagging_all %&gt;%\n  mutate(date = as.Date(date))\n\n# Combine the datasets by binding rows horizontally\ntracking_data_all &lt;- bind_rows(fish_flow_receiver_stream_tagging_all, collection_data)\n\n# Write new tagging data csv\nwrite.csv(tracking_data_all, \n          file = \"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/tracking_data_all.csv\", \n          row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating my Datasheet</span>"
    ]
  },
  {
    "objectID": "preliminary_data_visualization.html",
    "href": "preliminary_data_visualization.html",
    "title": "3  Preliminary Data Visualization",
    "section": "",
    "text": "3.1 Habitat use",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preliminary Data Visualization</span>"
    ]
  },
  {
    "objectID": "preliminary_data_visualization.html#habitat-use",
    "href": "preliminary_data_visualization.html#habitat-use",
    "title": "3  Preliminary Data Visualization",
    "section": "",
    "text": "3.1.1 Hourly\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\")\n\n# Convert trackedTime_EST to POSIXct\niPad_data &lt;- iPad_data %&gt;%\n  mutate(trackedTime_EST = as.POSIXct(trackedTime_EST, \n                                      format = \"%Y-%m-%d %H:%M:%S\", \n                                      tz = \"EST\"))\n\n# Extract hour\niPad_data &lt;- iPad_data %&gt;%\n  mutate(hour_of_day = format(trackedTime_EST, \"%H\"))  # Keep only hour in HH format\n\n# Group by the hour of day and habitat, and then count occurrences\nhourly_habitat_summary &lt;- iPad_data %&gt;%\n  group_by(hour_of_day, habitat) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop')  # Summing the number of each habitat per hour\n\n# Convert hour_of_day to a numeric type for proper binning and sorting\nhourly_habitat_summary &lt;- hourly_habitat_summary %&gt;%\n  mutate(hour_of_day = as.numeric(hour_of_day))\n\n# Create the histogram with habitat use summed across all days\nsum_habitat_use_hourly &lt;- ggplot(data = hourly_habitat_summary, aes(x = hour_of_day, y = habitat_count, fill = habitat)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use bar plot for summed data\n  scale_x_continuous(breaks = 0:23, labels = sprintf(\"%02d:00\", 0:23)) +  # Set breaks for each hour\n  scale_fill_discrete(name = \"Habitat Use\") +\n  labs(title = \"Summed Habitat Use Over Time (Hourly)\", \n       x = \"Time of Day (Hourly)\", \n       y = \"Total Habitat Use\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels for better visibility\n\n# Print the plot\nprint(sum_habitat_use_hourly)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\")\n\n# Convert trackedTime_EST to POSIXct\niPad_data &lt;- iPad_data %&gt;%\n  mutate(trackedTime_EST = as.POSIXct(trackedTime_EST, \n                                      format = \"%Y-%m-%d %H:%M:%S\", \n                                      tz = \"EST\"))\n\n# Extract the hour of the day and convert to factor\niPad_data &lt;- iPad_data %&gt;%\n  mutate(hour_of_day = factor(format(trackedTime_EST, \"%H\"), \n                              levels = sprintf(\"%02d\", 0:23)))  # Ensures leading zeros\n\n# Group by hour and habitat, calculate total observations and proportions\nhourly_habitat_summary_scaled &lt;- iPad_data %&gt;%\n  group_by(hour_of_day, habitat) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop') %&gt;%\n  group_by(hour_of_day) %&gt;%\n  mutate(total_observations = sum(habitat_count),  # Total observations for the hour\n         habitat_proportion = habitat_count / total_observations)  # Proportion of each habitat\n\n# Create the bar plot with proportional habitat use over hours (summed across all days)\nprop_habitat_use_hourly &lt;- ggplot(data = hourly_habitat_summary_scaled, aes(x = hour_of_day, y = habitat_proportion, fill = habitat)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use bar plot for proportional data\n  scale_x_discrete(name = \"Time of Day (Hourly)\", labels = sprintf(\"%02d:00\", 0:23)) +  # Display hour of day on the x-axis\n  scale_fill_discrete(name = \"Habitat Use\") +\n  labs(title = \"Proportional Habitat Use Over Time (Hourly)\", \n       x = \"Hour of Day\", \n       y = \"Proportional Habitat Use\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels for better visibility\n\n# Print the plot\nprint(prop_habitat_use_hourly)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Arrange the plots into a 2x1 grid\ngrid.arrange(sum_habitat_use_hourly, prop_habitat_use_hourly, nrow = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking//radio_tracking_2024/plots/habitat_use_hourly.png\",\n       arrangeGrob(sum_habitat_use_hourly, prop_habitat_use_hourly, nrow = 1, ncol = 2), \n       width = 20, height = 12)  # Adjust width and height as needed\n\n\n\n\n3.1.2 Daily\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\")\n\n# Convert trackedTime_EST to POSIXct\niPad_data &lt;- iPad_data %&gt;%\n  mutate(trackedTime_EST = as.POSIXct(trackedTime_EST, \n                                      format = \"%Y-%m-%d %H:%M:%S\", \n                                      tz = \"EST\"))  # Adjust the format and timezone as needed\n\n# Extract the date component\niPad_data &lt;- iPad_data %&gt;%\n  mutate(date_only = as.Date(trackedTime_EST))  # Extract only the date\n\n# Group by date and habitat, then count occurrences\ndaily_habitat_summary &lt;- iPad_data %&gt;%\n  group_by(date_only, habitat) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop')  # Summing the number of each habitat per date\n\n# Create the bar plot with habitat use over time (dates)\nsum_habitat_use_daily &lt;- ggplot(data = daily_habitat_summary, aes(x = date_only, y = habitat_count, fill = habitat)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use bar plot for summed data\n  scale_x_date(date_labels = \"%Y-%m-%d\", date_breaks = \"1 week\") +  # Show labels every week\n  scale_fill_discrete(name = \"Habitat Use\") +\n  labs(title = \"Summed Habitat Use Over Time (Daily)\", \n       x = \"Date\", \n       y = \"Total Habitat Use\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels for better visibility\n\n# Print the plot\nprint(sum_habitat_use_daily)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\")\n\n# Convert trackedTime_EST to POSIXct\niPad_data &lt;- iPad_data %&gt;%\n  mutate(trackedTime_EST = as.POSIXct(trackedTime_EST, \n                                      format = \"%Y-%m-%d %H:%M:%S\", \n                                      tz = \"EST\"))\n\n# Extract the date component\niPad_data &lt;- iPad_data %&gt;%\n  mutate(date_only = as.Date(trackedTime_EST))\n\n# Group by date and habitat, calculate total observations and proportions\ndaily_habitat_summary_scaled &lt;- iPad_data %&gt;%\n  group_by(date_only, habitat) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop') %&gt;%\n  group_by(date_only) %&gt;%\n  mutate(total_observations = sum(habitat_count),  # Total observations for the day\n         habitat_proportion = habitat_count / total_observations)  # Proportion of each habitat\n\n# Create the bar plot with proportional habitat use over time (dates)\nprop_habitat_use_daily &lt;- ggplot(data = daily_habitat_summary_scaled, aes(x = date_only, y = habitat_proportion, fill = habitat)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use bar plot for proportional data\n  scale_x_date(date_labels = \"%Y-%m-%d\", date_breaks = \"1 week\") +  # Show labels every week\n  scale_fill_discrete(name = \"Habitat Use\") +\n  labs(title = \"Proportional Habitat Use Over Time (Daily)\", \n       x = \"Date\", \n       y = \"Proportional Habitat Use\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels for better visibility\n\n# Print the plot\nprint(prop_habitat_use_daily)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Arrange the plots into a 2x1 grid\ngrid.arrange(sum_habitat_use_daily, prop_habitat_use_daily, nrow = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking//radio_tracking_2024/plots/habitat_use_daily.png\",\n       arrangeGrob(sum_habitat_use_daily, prop_habitat_use_daily, nrow = 1, ncol = 2), \n       width = 20, height = 12)  # Adjust width and height as needed\n\n\n\n\n3.1.3 Flow\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats, and filter out NA in totalDischarge\nfiltered_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\" & !is.na(totalDischarge))\n\n# Create the histogram with habitat use over flow conditions\nggplot(data = filtered_data, aes(x = totalDischarge, fill = habitat)) +\n  geom_histogram(binwidth = 0.5, position = \"stack\", stat = \"count\") +  # Adjust binwidth as needed\n  scale_x_continuous(limits = c(-7, 22)) +  # Set x-axis limits\n  scale_fill_discrete(name = \"Habitat Use\") +\n  labs(title = \"Habitat Use Across Different Flow Conditions\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels if necessary\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\" & !is.na(totalDischarge))\n\n# Group by habitat and total discharge to get summed habitat use\nsummed_habitat_use &lt;- iPad_data %&gt;%\n  group_by(habitat, totalDischarge) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop')  # Summing the number of each habitat per total discharge\n\n# Create the line graph for summed habitat use\nggplot(data = summed_habitat_use, aes(x = totalDischarge, y = habitat_count, color = habitat, group = habitat)) +\n  geom_line() +  # Line for habitat use\n  geom_point() +  # Points for each observation\n  labs(title = \"Summed Habitat Use by Total Discharge\",\n       x = \"Total Discharge\",\n       y = \"Total Habitat Use\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\" & !is.na(totalDischarge))\n\n# Group by habitat and total discharge to get proportional habitat use\nproportional_habitat_use &lt;- iPad_data %&gt;%\n  group_by(habitat, totalDischarge) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop') %&gt;%\n  group_by(totalDischarge) %&gt;%\n  mutate(total_observations = sum(habitat_count),  # Total observations for the discharge level\n         habitat_proportion = habitat_count / total_observations)  # Proportion of each habitat\n\n# Create the line graph for proportional habitat use\nggplot(data = proportional_habitat_use, aes(x = totalDischarge, y = habitat_proportion, color = habitat, group = habitat)) +\n  geom_line() +  # Line for habitat proportion\n  geom_point() +  # Points for each observation\n  labs(title = \"Proportional Habitat Use by Total Discharge\",\n       x = \"Total Discharge\",\n       y = \"Proportion of Habitat Use\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to only include 'iPad' as source and remove NA or blank habitats\niPad_data &lt;- tracking_data_all %&gt;%\n  filter(source == \"iPad\" & !is.na(habitat) & habitat != \"\" & !is.na(totalDischarge))\n\n# Group by habitat and total discharge to get proportional habitat use\nproportional_habitat_use &lt;- iPad_data %&gt;%\n  group_by(habitat, totalDischarge) %&gt;%\n  summarise(habitat_count = n(), .groups = 'drop') %&gt;%\n  group_by(totalDischarge) %&gt;%\n  mutate(total_observations = sum(habitat_count),  # Total observations for the discharge level\n         habitat_proportion = habitat_count / total_observations)  # Proportion of each habitat\n\n# Create the smoothed line graph for proportional habitat use\nggplot(data = proportional_habitat_use, aes(x = totalDischarge, y = habitat_proportion, color = habitat, group = habitat)) +\n  geom_smooth(se = TRUE, method = \"loess\") +  # Use LOESS smoothing\n  geom_point(alpha = 0.5) +  # Add points for each observation\n  labs(title = \"Smoothed Proportional Habitat Use by Total Discharge\",\n       x = \"Total Discharge\",\n       y = \"Proportion of Habitat Use\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preliminary Data Visualization</span>"
    ]
  },
  {
    "objectID": "preliminary_data_visualization.html#growth-rates",
    "href": "preliminary_data_visualization.html#growth-rates",
    "title": "3  Preliminary Data Visualization",
    "section": "3.2 Growth rates",
    "text": "3.2 Growth rates\n\n\nCode\n# Filter for fish that have exactly two length measurements using tagID and length\nfish_with_two_lengths &lt;- tracking_data_all %&gt;%\n  filter(!is.na(tagID)) %&gt;%  # Ensure there are valid (non-NA) tagID values\n  group_by(tagID) %&gt;%\n  filter(!is.na(length)) %&gt;%  # Ensure there are valid (non-NA) length values\n  filter(n() == 2) # Only keep fish with exactly two length measurements\n\n# Ensure tagID is treated as a categorical variable\nfish_with_two_lengths$tagID &lt;- as.factor(fish_with_two_lengths$tagID)\n\n# Plot the growth figure using length\nlength_gr &lt;- ggplot(fish_with_two_lengths, aes(x = date, y = length, group = tagID)) +\n  geom_point(aes(color = tagID), size = 3) +  # Add points for initial and final sizes, and color points by tagID\n  geom_line(aes(color = tagID)) +  # Add lines connecting the points for each fish and color lines by tagID\n  labs(x = \"Date\", y = \"Length (mm)\", title = \"Fish Growth Over Time\") +\n  theme_minimal()\n\n# Print the plot\nprint(length_gr)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for fish that have exactly two weight measurements using tagID and length\nfish_with_two_weights &lt;- tracking_data_all %&gt;%\n  filter(!is.na(tagID)) %&gt;%  # Ensure there are valid (non-NA) tagID values\n  group_by(tagID) %&gt;%\n  filter(!is.na(weight)) %&gt;%  # Ensure there are valid (non-NA) weight values\n  filter(n() == 2) # Only keep fish with exactly two weight measurements\n\n# Ensure tagID is treated as a categorical variable\nfish_with_two_weights$tagID &lt;- as.factor(fish_with_two_weights$tagID)\n\n# Plot the growth figure using length\nweight_gr &lt;- ggplot(fish_with_two_weights, aes(x = date, y = weight, group = tagID)) +\n  geom_point(aes(color = tagID), size = 3) +  # Add points for initial and final sizes, and color points by tagID\n  geom_line(aes(color = tagID)) +  # Add lines connecting the points for each fish and color lines by tagID\n  labs(x = \"Date\", y = \"Weight (g)\", title = \"Fish Growth Over Time\") +\n  theme_minimal()\n\n# Print the plot\nprint(weight_gr)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Arrange the plots into a 2x1 grid\ngrid.arrange(length_gr, weight_gr, nrow = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking//radio_tracking_2024/plots/growth_rate.png\",\n       arrangeGrob(length_gr, weight_gr, nrow = 1, ncol = 2), \n       width = 20, height = 12)  # Adjust width and height as needed",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preliminary Data Visualization</span>"
    ]
  },
  {
    "objectID": "preliminary_data_visualization.html#tag-recovery",
    "href": "preliminary_data_visualization.html#tag-recovery",
    "title": "3  Preliminary Data Visualization",
    "section": "3.3 Tag recovery",
    "text": "3.3 Tag recovery\n\n\nCode\n# Read the Excel file and specify the range or skip rows until the second table\ncollection_summary &lt;- read_excel(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/taggingData/collectionData.xlsx\", range = cell_rows(38:45))\n\n# Assuming 'collection_summary' has \"Category\", \"Type\", and \"Percentage\"\n# Filter out the first row (which is the \"total\")\ncollection_summary &lt;- collection_summary %&gt;%\n  slice(-1)  # This removes the first row\n\n# Calculate the rounded percentage for each category\ncollection_summary &lt;- collection_summary %&gt;%\n  mutate(rounded_percentage = round(Percentage, 1))  # Round to 1 decimal place\n\n# Define custom colors\ncustom_colors &lt;- c(\"Tag (Radio + Temp)\" = \"#FF69B4\",  # Replace with actual category names and desired colors\n                   \"Tag (Radio Only)\" = \"#97FFFF\",\n                   \"Fish (Radio + Temp)\" = \"#FFD700\",\n                   \"Fish (Radio Only)\" = \"#B23AEE\",\n                   \"Fish (Shed Tag)\" = \"#98FB98\",\n                   \"Unrecovered\" = \"#436EEE\"\n                   )\n\n# Assuming your filtered data has \"Category\", \"Percentage\", and \"Type\" columns\n# You can select only \"Category\" and \"Percentage\" for the pie chart\ntag_recovery &lt;- ggplot(collection_summary, aes(x = \"\", y = Percentage, fill = Category)) +\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  #theme_void() +   # Removes axis labels and ticks\n  labs(title = \"Summary of Tag Recovery\", x = NULL, y = NULL) +  # Set x and y labels to NULL\n  geom_text(aes(label = paste0(rounded_percentage, \"%\")), \n            position = position_stack(vjust = 0.5), \n            size = 4) + # Adjust size as needed\n  scale_fill_manual(values = custom_colors) + # Apply custom colors\n  theme(\n    plot.background = element_rect(fill = \"white\", color = NA),  # Set plot background to white\n    panel.background = element_rect(fill = \"white\", color = NA), # Set panel background to white\n    panel.grid = element_blank(),  # Remove grid lines\n    axis.text.x = element_blank(),  # Hide x-axis text\n    axis.ticks = element_blank()     # Hide x-axis ticks\n  )\n\n# Print the plot\nprint(tag_recovery)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking//radio_tracking_2024/plots/tag_recovery.png\",\n       plot = tag_recovery)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preliminary Data Visualization</span>"
    ]
  },
  {
    "objectID": "preliminary_data_visualization.html#temp-tags",
    "href": "preliminary_data_visualization.html#temp-tags",
    "title": "3  Preliminary Data Visualization",
    "section": "3.4 Temp tags",
    "text": "3.4 Temp tags\n\n\nCode\n# Read the Excel file\ntag16_323 &lt;- read_excel(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTempTagData/16_323.xlsx\")\n\n# Rename columns\ntag16_323 &lt;- tag16_323 %&gt;%\n  rename(dateTime = `Date & Time`, temp = `Temperature(°C)`)\n\n# Separate dateTime into date and time columns\ntag16_323 &lt;- tag16_323 %&gt;%\n  separate(dateTime, into = c(\"date\", \"time\"), sep = \" \") %&gt;%\n  mutate(date = as.Date(date, format = \"%Y-%m-%d\"),\n         time = as.POSIXct(time, format = \"%H:%M:%S\", tz = \"EST\"))  # Use `POSIXct` for time manipulation\n\n# Adjust time from EDT to EST by subtracting 1 hour\ntag16_323 &lt;- tag16_323 %&gt;%\n  mutate(time = time - hours(1))\n\n# Combine date and adjusted time back into a single dateTime column\ntag16_323 &lt;- tag16_323 %&gt;%\n  mutate(dateTime = as.POSIXct(paste(date, format(time, \"%H:%M:%S\")), format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n\n# Define the start time as the first day of tracking at Dry Upper\nstart_datetime &lt;- as.POSIXct(\"2024-06-14 00:00:00\", tz = \"EST\")\n\n# Define the last known alive point as a POSIXct object\nlast_alive_datetime &lt;- as.POSIXct(\"2024-08-22 09:00:00\", tz = \"EST\")\n\n# Filter dataset up to and including the last known alive point\ntag16_323 &lt;- tag16_323 %&gt;%\n  filter(dateTime &gt;= start_datetime & dateTime &lt;= last_alive_datetime)\n\n# Filter to only the needed columns going forward\ntag16_323 &lt;- tag16_323 %&gt;%\n    select(temp, dateTime)\n\n# Ensure dateTime is POSIXct and temp is numeric\ntag16_323 &lt;- tag16_323 %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, tz = \"EST\"),\n         temp = as.numeric(temp))\n\n# Set a common color gradient across all plots (10 to 25 degrees Celsius)\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the temperature data\ntag16Plot &lt;- ggplot(tag16_323, aes(x = dateTime, y = temp, color = temp)) +\n  geom_line() +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +  # Set colors for low and high temperatures\n  labs(title = \"Fish 16's Internal Temperature Over Time in Dry Upper\", \n       x = \"DateTime\", y = \"Internal Fish Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25)  # Set y-axis limits\n\n# View plot\ntag16Plot\n\n\n\n\n\n\n\n\n\n\n\nCode\n#######################################################\n# Prepare data for Dry 6/5/2024 through 9/5/2024\n#######################################################\n\n# Read the file\ndryDepth0605_0905 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/DU Sec 5 21350753 2024-09-05 17_06_55 EDT (Data EDT).csv\")\n\n# Get the column names\nnames(dryDepth0605_0905)\n\n\n[1] \"X.\"                 \"Date.Time..EDT.\"    \"Temperature.....C.\"\n[4] \"Host.Connected\"     \"End.of.File\"       \n\n\nCode\n# Rename columns\ndryDepth0605_0905 &lt;- dryDepth0605_0905 %&gt;%\n  rename(dateTime = `Date.Time..EDT.`, \n         temp = `Temperature.....C.`)\n\n# Convert character dateTime to POSIXct format in EDT\ndryDepth0605_0905 &lt;- dryDepth0605_0905 %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, format = \"%m/%d/%Y %H:%M:%S\", tz = \"America/New_York\"))\n\n# Forcefully convert POSIXct dateTime to EST (without DST adjustments)\ndryDepth0605_0905 &lt;- dryDepth0605_0905 %&gt;%\n  mutate(dateTime = format(dateTime, tz = \"EST\", usetz = TRUE))\n\n#######################################################\n# Filter data to tracking dates only\n#######################################################\n\n# Define the start time as the first day of tracking at Dry Upper\nstart_datetime &lt;- as.POSIXct(\"2024-06-14 00:00:00\")\n\n# Define the last known alive point for tag 16 as a POSIXct object\nlast_alive_datetime &lt;- as.POSIXct(\"2024-08-22 09:00:00\")\n\n# Filter dataset up to and including the last known alive point\ndryDepth &lt;- dryDepth0605_0905 %&gt;%\n  filter(dateTime &gt;= start_datetime & dateTime &lt;= last_alive_datetime)\n\n# Filter to only the needed columns going forward\ndryDepth &lt;- dryDepth %&gt;%\n    select(temp, dateTime)\n\n# Ensure dateTime is POSIXct and temp is numeric\ndryDepth &lt;- dryDepth %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, tz = \"EST\"),\n         temp = as.numeric(temp))\n\n#######################################################\n# Plot\n#######################################################\n\n# Set a common color gradient across all plots (10 to 25 degrees Celsius)\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the temperature data\ndryDepthPlot &lt;- ggplot(dryDepth, aes(x = dateTime, y = temp, color = temp)) +\n  geom_line() +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +  # Set colors for low and high temperatures\n  labs(title = \"Depth Logger Temperature Over Time in Dry Upper\", \n       x = \"DateTime\", y = \"Water Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25)  # Set y-axis limits\n\n# View plot\ndryDepthPlot\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Combine the underhill plots vertically\ndryPlot &lt;- tag16Plot / dryDepthPlot\n\n# Display the combined plot\ndryPlot\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Add a column to each dataset to indicate its source\ndryDepth &lt;- dryDepth %&gt;%\n  mutate(source = \"logger\")\n\ntag16_323 &lt;- tag16_323 %&gt;%\n  mutate(source = \"tag\")\n\n# Combine datasets\ndryData &lt;- bind_rows(dryDepth, tag16_323)\n\n# Set common color gradient limits\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the combined data\ndryPlot &lt;- ggplot() +\n  # Plot data from tag16_323 with a color gradient\n  geom_line(data = tag16_323, aes(x = dateTime, y = temp, color = temp), size = 1) +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +\n  \n  # Plot data from dryDepth with a fixed color (e.g., black)\n  geom_line(data = dryDepth, aes(x = dateTime, y = temp), color = \"black\", size = 1) +\n  \n  # Add labels and themes\n  labs(title = \"Temperature Over Time for Tag 16 and an Dry Upper Logger\", \n       x = \"DateTime\", y = \"Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25) # Adjust y-axis limits as needed\n\n# Print the plot\nprint(dryPlot)\n\n\n\n\n\n\n\n\n\n\n\nCode\n#######################################################\n# Prepare data for Underhill radio tag 33, temp tag 305\n#######################################################\n\n# Read the Excel file\ntag33_305 &lt;- read_excel(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/rawTempTagData/33_305.xlsx\")\n\n# Rename columns\ntag33_305 &lt;- tag33_305 %&gt;%\n  rename(dateTime = `Date & Time`, temp = `Temperature(°C)`)\n\n# Separate dateTime into date and time columns\ntag33_305 &lt;- tag33_305 %&gt;%\n  separate(dateTime, into = c(\"date\", \"time\"), sep = \" \") %&gt;%\n  mutate(date = as.Date(date, format = \"%Y-%m-%d\"),\n         time = as.POSIXct(time, format = \"%H:%M:%S\", tz = \"EST\"))  # Use `POSIXct` for time manipulation\n\n# Adjust time from EDT to EST by subtracting 1 hour\ntag33_305 &lt;- tag33_305 %&gt;%\n  mutate(time = time - hours(1))\n\n# Combine date and adjusted time back into a single dateTime column\ntag33_305 &lt;- tag33_305 %&gt;%\n  mutate(dateTime = as.POSIXct(paste(date, format(time, \"%H:%M:%S\")), format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n\n#######################################################\n# Filter data to tracking dates only\n#######################################################\n\n# Define the start time as the first day of tracking at Underhill\nstart_datetime &lt;- as.POSIXct(\"2024-06-12 00:00:00\", tz = \"EST\")\n  \n# Define the last known alive point as a POSIXct object\nlast_alive_datetime &lt;- as.POSIXct(\"2024-08-21 08:30:00\", tz = \"EST\")\n\n# Filter dataset up to and including the last known alive point\ntag33_305 &lt;- tag33_305 %&gt;%\n  filter(dateTime &gt;= start_datetime & dateTime &lt;= last_alive_datetime)\n\n# Filter to only the needed columns going forward\ntag33_305 &lt;- tag33_305 %&gt;%\n    select(temp, dateTime)\n\n# Ensure dateTime is POSIXct and temp is numeric\ntag33_305 &lt;- tag33_305 %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, tz = \"EST\"),\n         temp = as.numeric(temp))\n\n#######################################################\n# Plot\n#######################################################\n\n# Set a common color gradient across all plots (10 to 25 degrees Celsius)\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the temperature data\ntag33Plot &lt;- ggplot(tag33_305, aes(x = dateTime, y = temp, color = temp)) +\n  geom_line() +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +  # Set colors for low and high temperatures\n  labs(title = \"Fish 33's Internal Temperature Over Time in Underhill\", \n       x = \"DateTime\", y = \"Internal Fish Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25)  # Set y-axis limits\n\n# View plot\ntag33Plot\n\n\n\n\n\n\n\n\n\n\n\nCode\n#######################################################\n# Prepare data for Underhill 8/1/2024 through 9/5/2024\n#######################################################\n\n# Read the file\nunderhillDepth0801_0905 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Underhill_Depth_20240801_to_20240905.csv\")\n\n# Get the column names\nnames(underhillDepth0801_0905)\n\n\n[1] \"X.\"                                                  \n[2] \"Date.Time..GMT.04.00\"                                \n[3] \"Abs.Pres..kPa..LGR.S.N..21340801..SEN.S.N..21340801.\"\n[4] \"Temp...C..LGR.S.N..21340801..SEN.S.N..21340801.\"     \n\n\nCode\n# Rename columns\nunderhillDepth0801_0905 &lt;- underhillDepth0801_0905 %&gt;%\n  rename(dateTime = `Date.Time..GMT.04.00`, \n         temp = `Temp...C..LGR.S.N..21340801..SEN.S.N..21340801.`)\n\n# Convert character dateTime to POSIXct format in GMT\nunderhillDepth0801_0905 &lt;- underhillDepth0801_0905 %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, format = \"%m/%d/%y %H:%M\", tz = \"GMT\"))\n\n# Forcefully convert POSIXct dateTime to EST (without DST adjustments)\nunderhillDepth0801_0905 &lt;- underhillDepth0801_0905 %&gt;%\n  mutate(dateTime = format(dateTime, tz = \"EST\", usetz = TRUE))\n\n# Filter to only the needed columns going forward\nunderhillDepth0801_0905 &lt;- underhillDepth0801_0905 %&gt;%\n    select(temp, dateTime)\n\n#######################################################\n# Prepare data for Underhill 6/4/2024 through 8/1/2024\n#######################################################\n\n# Read the file, skip the first row, and use the second row as headers\nunderhillDepth0604_0801 &lt;- read.csv(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/Underhill_Depth_USGS__20240604_to_20240801_21340801.csv\", skip = 1, header = TRUE)\n\n# Get the column names\nnames(underhillDepth0604_0801)\n\n\n[1] \"X.\"                                                  \n[2] \"Date.Time..GMT.04.00\"                                \n[3] \"Abs.Pres..psi..LGR.S.N..21340801..SEN.S.N..21340801.\"\n[4] \"Temp...F..LGR.S.N..21340801..SEN.S.N..21340801.\"     \n[5] \"Coupler.Detached..LGR.S.N..21340801.\"                \n[6] \"Coupler.Attached..LGR.S.N..21340801.\"                \n[7] \"Host.Connected..LGR.S.N..21340801.\"                  \n[8] \"Stopped..LGR.S.N..21340801.\"                         \n[9] \"End.Of.File..LGR.S.N..21340801.\"                     \n\n\nCode\n# Rename columns\nunderhillDepth0604_0801 &lt;- underhillDepth0604_0801 %&gt;%\n  rename(dateTime = `Date.Time..GMT.04.00`, \n         temp = `Temp...F..LGR.S.N..21340801..SEN.S.N..21340801.`)\n\n# Convert character dateTime to POSIXct format in GMT\nunderhillDepth0604_0801 &lt;- underhillDepth0604_0801 %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, format = \"%m/%d/%y %H:%M\", tz = \"GMT\"))\n\n# Forcefully convert POSIXct dateTime to EST (without DST adjustments)\nunderhillDepth0604_0801 &lt;- underhillDepth0604_0801 %&gt;%\n  mutate(dateTime = format(dateTime, tz = \"EST\", usetz = TRUE))\n\n# Filter to only the needed columns going forward\nunderhillDepth0604_0801 &lt;- underhillDepth0604_0801 %&gt;%\n    select(temp, dateTime)\n\n# Convert from fahrenheit into celsius\nunderhillDepth0604_0801 &lt;- underhillDepth0604_0801 %&gt;%\n  mutate(temp = (temp - 32) * 5 / 9)\n\n#######################################################\n# Combine both Underhill datasets\n#######################################################\n\n# Combine the two final dataframes horizontally\nunderhillDepth &lt;- bind_rows(underhillDepth0604_0801, underhillDepth0801_0905)\n\n#######################################################\n# Filter data to tracking dates only\n#######################################################\n\n# Define the start time as the first day of tracking at Dry Upper\nstart_datetime &lt;- as.POSIXct(\"2024-06-12 00:00:00\")\n\n# Define the last known alive point for tag 33 as a POSIXct object\nlast_alive_datetime &lt;- as.POSIXct(\"2024-08-21 08:30:00\")\n\n# Filter dataset up to and including the last known alive point\nunderhillDepth &lt;- underhillDepth %&gt;%\n  filter(dateTime &gt;= start_datetime & dateTime &lt;= last_alive_datetime)\n\n# Ensure dateTime is POSIXct and temp is numeric\nunderhillDepth &lt;- underhillDepth %&gt;%\n  mutate(dateTime = as.POSIXct(dateTime, tz = \"EST\"),\n         temp = as.numeric(temp))\n\n#######################################################\n# Plot\n#######################################################\n\n# Set a common color gradient across all plots (10 to 25 degrees Celsius)\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the temperature data\nunderhillDepthPlot &lt;- ggplot(underhillDepth, aes(x = dateTime, y = temp, color = temp)) +\n  geom_line() +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +  # Set colors for low and high temperatures\n  labs(title = \"Depth Logger Temperature Over Time in Underhill\", \n       x = \"DateTime\", y = \"Water Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25) # Set y-axis limits\n\n# View plot\nunderhillDepthPlot\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Combine the underhill plots vertically\nunderhillPlot &lt;- tag33Plot / underhillDepthPlot\n\n# Display the combined plot\nunderhillPlot\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Add a column to each dataset to indicate its source\nunderhillDepth &lt;- underhillDepth %&gt;%\n  mutate(source = \"logger\")\n\ntag33_305 &lt;- tag33_305 %&gt;%\n  mutate(source = \"tag\")\n\n# Combine datasets\nunderhillData &lt;- bind_rows(underhillDepth, tag33_305)\n\n# Set common color gradient limits\ncolorMin &lt;- 10\ncolorMax &lt;- 25\n\n# Plot the combined data\nunderhillPlot &lt;- ggplot() +\n  # Plot data from tag33_305 with a color gradient\n  geom_line(data = tag33_305, aes(x = dateTime, y = temp, color = temp), size = 1) +\n  scale_color_gradient(low = \"blue\", high = \"red\", limits = c(colorMin, colorMax)) +\n  \n  # Plot data from underhillDepth with a fixed color (e.g., black)\n  geom_line(data = underhillDepth, aes(x = dateTime, y = temp), color = \"black\", size = 1) +\n  \n  # Add labels and themes\n  labs(title = \"Temperature Over Time for Tag 33 and an Underhill Logger\", \n       x = \"DateTime\", y = \"Temperature (°C)\") +\n  theme_minimal() +\n  ylim(10, 25) # Adjust y-axis limits as needed\n\n# Print the plot\nprint(underhillPlot)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Arrange the plots into a 2x1 grid\ngrid.arrange(dryPlot, underhillPlot, nrow = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/plots/dry_underhill.png\",\n       arrangeGrob(dryPlot, underhillPlot, nrow = 1, ncol = 2), \n       width = 20, height = 12)  # Adjust width and height as needed\n\n\n\n\nCode\n# Arrange the plots into a 2x2 grid\ngrid.arrange(tag16Plot, tag33Plot, dryDepthPlot, underhillDepthPlot, nrow = 2, ncol = 2)\n\n\n\n\n\n\n\n\n\nCode\n# Save the enlarged plot\nggsave(\"C:/Users/jpilchik/OneDrive - DOI/Documents/My study plan/Tagging/Tracking/radio_tracking_2024/plots/fish_16_33.png\",\n       arrangeGrob(tag16Plot, tag33Plot, dryDepthPlot, underhillDepthPlot, nrow = 2, ncol = 2), \n       width = 12, height = 12)  # Adjust width and height as needed",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preliminary Data Visualization</span>"
    ]
  }
]